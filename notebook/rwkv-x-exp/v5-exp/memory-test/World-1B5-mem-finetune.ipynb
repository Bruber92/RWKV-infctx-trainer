{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RWKV World Memory Finetune (Memory Finetune)\n",
    "\n",
    "This takes an existing RWKV world model, and finetune them specifically for the memory repeat task of various sizes.\n",
    "This test is used as an approximation of testing the model token memory size in the \"worse case scenerio\"\n",
    "\n",
    "- Using randomized data, so prior learning does not help, nor is it possible to compress the data\n",
    "- Using a variety of token lengths, to avoid overfitting to a single length\n",
    "- Based on the pretrained model (rwkv world)\n",
    "- This process does \"destroy the model\" but it helps quantify the model limits\n",
    "\n",
    "In practise however, the model may show \"attention range\" longer then what is benchmarked, as natural text is highly compressible. Unlike the pure randomized data that was being tested here.\n",
    "\n",
    "This runner has been optimized to run on 8 x 24GB vram nodes, you should allocate atleast 500GB disk space.\n",
    "\n",
    "> This project assumes you have the rwkv-infctx conda env setup, and you are executing in that environment - see the main README.md for the conda env setup steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure your environment settings\n",
    "(!Important: you will need to rerun the below cell, if you restart your kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEEPSPEED_STRAT: deepspeed_stage_1\n",
      "ENABLE_WANDB: True\n",
      "GPU_DEVICES: auto\n",
      "NOTEBOOK_DIR: /home/recursal/RWKV-infctx-trainer/notebook/rwkv-x-exp/v5-exp/memory-test\n",
      "TRAINER_DIR: /home/recursal/RWKV-infctx-trainer/RWKV-v5\n",
      "PROJECT_DIR: /home/recursal/RWKV-infctx-trainer\n"
     ]
    }
   ],
   "source": [
    "DEEPSPEED_STRAT=\"deepspeed_stage_1\"\n",
    "GPU_DEVICES=\"auto\"\n",
    "ENABLE_WANDB=True\n",
    "WANDB_PREFIX=\"[8x4090] RWKV-v5-1B5-World\"\n",
    "\n",
    "print(\"DEEPSPEED_STRAT:\", DEEPSPEED_STRAT)\n",
    "print(\"ENABLE_WANDB:\", ENABLE_WANDB)\n",
    "print(\"GPU_DEVICES:\", GPU_DEVICES)\n",
    "\n",
    "if ENABLE_WANDB:\n",
    "    WANDB_MODE=\"online\"\n",
    "else:\n",
    "    WANDB_MODE=\"disabled\"\n",
    "\n",
    "# The model sizing\n",
    "MODEL_NAME=\"RWKV-v5-1B5-world.pth\"\n",
    "MODEL_URL=\"https://huggingface.co/BlinkDL/rwkv-5-world/resolve/main/RWKV-5-World-1B5-v2-20231025-ctx4096.pth?download=true\"\n",
    "\n",
    "# Computing the notebook, and various paths\n",
    "import os\n",
    "NOTEBOOK_DIR=os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PROJECT_DIR=os.path.abspath(os.path.join(NOTEBOOK_DIR, \"../../../../\"))\n",
    "TRAINER_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v5/\"))\n",
    "MEMORY_SCRIPT_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./notebook/util-scripts/memory_script\"))\n",
    "\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"TRAINER_DIR:\", TRAINER_DIR)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the pretrained model\n",
    "(if you want to skip the the basemodel train + instruct tune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘RWKV-v5-1B5-world.pth’ already there; not retrieving.\n"
     ]
    }
   ],
   "source": [
    "# Lets wget the model files\n",
    "!cd \"{PROJECT_DIR}\" && mkdir -p \"{PROJECT_DIR}/model\"\n",
    "!cd \"{PROJECT_DIR}/model\" && \\\n",
    "    wget -O \"{MODEL_NAME}\" -nc \"{MODEL_URL}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune 1 : Dataset preperation\n",
    "\n",
    "Stage 1, handles total context size of 2048. Meaning it will be tuned for memory task of 1 to approximately 1024 tokens of size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rwkv in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (0.8.22)\n",
      "Requirement already satisfied: asyncio in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (3.4.3)\n",
      "Requirement already satisfied: aiocsv in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (1.2.5)\n",
      "Requirement already satisfied: aiofiles in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (23.2.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from rwkv) (0.15.0)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from tokenizers>=0.13.2->rwkv) (0.20.2)\n",
      "Requirement already satisfied: filelock in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->rwkv) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->rwkv) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->rwkv) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->rwkv) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->rwkv) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->rwkv) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->rwkv) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->rwkv) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->rwkv) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->rwkv) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->rwkv) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "# Folder and eval pip setup\n",
    "!cp -r \"{MEMORY_SCRIPT_DIR}/\" \"{NOTEBOOK_DIR}/\"\n",
    "!python3 -m pip install rwkv asyncio aiocsv aiofiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Generating word reptition dataset ##\n",
      "Generated JSONL file with - 5 max words, 500 samples - at ./dataset/gen-word-5-count.jsonl\n",
      "Generated JSONL file with - 15 max words, 500 samples - at ./dataset/gen-word-15-count.jsonl\n",
      "Generated JSONL file with - 2 max words, 300 samples - at ./dataset/word-2-count.jsonl\n",
      "Generated JSONL file with - 10 max words, 500 samples - at ./dataset/gen-word-10-count.jsonl\n",
      "Generated JSONL file with - 25 max words, 500 samples - at ./dataset/gen-word-25-count.jsonl\n",
      "Generated JSONL file with - 35 max words, 500 samples - at ./dataset/gen-word-35-count.jsonl\n",
      "Generated JSONL file with - 50 max words, 500 samples - at ./dataset/gen-word-50-count.jsonl\n",
      "Generated JSONL file with - 125 max words, 125 samples - at ./dataset/gen-word-125-count.jsonl\n",
      "Generated JSONL file with - 140 max words, 125 samples - at ./dataset/gen-word-140-count.jsonl\n",
      "Generated JSONL file with - 65 max words, 500 samples - at ./dataset/gen-word-65-count.jsonl\n",
      "Generated JSONL file with - 20 max words, 500 samples - at ./dataset/gen-word-20-count.jsonl\n",
      "Generated JSONL file with - 105 max words, 125 samples - at ./dataset/gen-word-105-count.jsonl\n",
      "Generated JSONL file with - 180 max words, 125 samples - at ./dataset/gen-word-180-count.jsonl\n",
      "Generated JSONL file with - 4 max words, 1000 samples - at ./dataset/word-2-count.jsonl\n",
      "Generated JSONL file with - 160 max words, 125 samples - at ./dataset/gen-word-160-count.jsonl\n",
      "Generated JSONL file with - 165 max words, 125 samples - at ./dataset/gen-word-165-count.jsonl\n",
      "Generated JSONL file with - 175 max words, 125 samples - at ./dataset/gen-word-175-count.jsonl\n",
      "Generated JSONL file with - 220 max words, 100 samples - at ./dataset/gen-word-220-count.jsonl\n",
      "Generated JSONL file with - 30 max words, 500 samples - at ./dataset/gen-word-30-count.jsonl\n",
      "Generated JSONL file with - 40 max words, 500 samples - at ./dataset/gen-word-40-count.jsonl\n",
      "Generated JSONL file with - 110 max words, 125 samples - at ./dataset/gen-word-110-count.jsonl\n",
      "Generated JSONL file with - 55 max words, 500 samples - at ./dataset/gen-word-55-count.jsonl\n",
      "Generated JSONL file with - 245 max words, 100 samples - at ./dataset/gen-word-245-count.jsonl\n",
      "Generated JSONL file with - 130 max words, 125 samples - at ./dataset/gen-word-130-count.jsonl\n",
      "Generated JSONL file with - 115 max words, 125 samples - at ./dataset/gen-word-115-count.jsonl\n",
      "Generated JSONL file with - 45 max words, 500 samples - at ./dataset/gen-word-45-count.jsonl\n",
      "Generated JSONL file with - 285 max words, 100 samples - at ./dataset/gen-word-285-count.jsonl\n",
      "Generated JSONL file with - 120 max words, 125 samples - at ./dataset/gen-word-120-count.jsonl\n",
      "Generated JSONL file with - 205 max words, 100 samples - at ./dataset/gen-word-205-count.jsonl\n",
      "Generated JSONL file with - 150 max words, 125 samples - at ./dataset/gen-word-150-count.jsonl\n",
      "Generated JSONL file with - 170 max words, 125 samples - at ./dataset/gen-word-170-count.jsonl\n",
      "Generated JSONL file with - 145 max words, 125 samples - at ./dataset/gen-word-145-count.jsonl\n",
      "Generated JSONL file with - 70 max words, 500 samples - at ./dataset/gen-word-70-count.jsonl\n",
      "Generated JSONL file with - 75 max words, 500 samples - at ./dataset/gen-word-75-count.jsonl\n",
      "Generated JSONL file with - 135 max words, 125 samples - at ./dataset/gen-word-135-count.jsonl\n",
      "Generated JSONL file with - 295 max words, 100 samples - at ./dataset/gen-word-295-count.jsonl\n",
      "Generated JSONL file with - 155 max words, 125 samples - at ./dataset/gen-word-155-count.jsonl\n",
      "Generated JSONL file with - 60 max words, 500 samples - at ./dataset/gen-word-60-count.jsonl\n",
      "Generated JSONL file with - 360 max words, 100 samples - at ./dataset/gen-word-360-count.jsonl\n",
      "Generated JSONL file with - 185 max words, 125 samples - at ./dataset/gen-word-185-count.jsonl\n",
      "Generated JSONL file with - 85 max words, 500 samples - at ./dataset/gen-word-85-count.jsonl\n",
      "Generated JSONL file with - 210 max words, 100 samples - at ./dataset/gen-word-210-count.jsonl\n",
      "Generated JSONL file with - 190 max words, 125 samples - at ./dataset/gen-word-190-count.jsonl\n",
      "Generated JSONL file with - 215 max words, 100 samples - at ./dataset/gen-word-215-count.jsonl\n",
      "Generated JSONL file with - 200 max words, 125 samples - at ./dataset/gen-word-200-count.jsonl\n",
      "Generated JSONL file with - 90 max words, 500 samples - at ./dataset/gen-word-90-count.jsonl\n",
      "Generated JSONL file with - 235 max words, 100 samples - at ./dataset/gen-word-235-count.jsonl\n",
      "Generated JSONL file with - 290 max words, 100 samples - at ./dataset/gen-word-290-count.jsonl\n",
      "Generated JSONL file with - 80 max words, 500 samples - at ./dataset/gen-word-80-count.jsonl\n",
      "Generated JSONL file with - 95 max words, 500 samples - at ./dataset/gen-word-95-count.jsonl\n",
      "Generated JSONL file with - 305 max words, 100 samples - at ./dataset/gen-word-305-count.jsonl\n",
      "Generated JSONL file with - 265 max words, 100 samples - at ./dataset/gen-word-265-count.jsonl\n",
      "Generated JSONL file with - 250 max words, 100 samples - at ./dataset/gen-word-250-count.jsonl\n",
      "Generated JSONL file with - 355 max words, 100 samples - at ./dataset/gen-word-355-count.jsonl\n",
      "Generated JSONL file with - 340 max words, 100 samples - at ./dataset/gen-word-340-count.jsonl\n",
      "Generated JSONL file with - 195 max words, 125 samples - at ./dataset/gen-word-195-count.jsonl\n",
      "Generated JSONL file with - 225 max words, 100 samples - at ./dataset/gen-word-225-count.jsonl\n",
      "Generated JSONL file with - 270 max words, 100 samples - at ./dataset/gen-word-270-count.jsonl\n",
      "Generated JSONL file with - 365 max words, 100 samples - at ./dataset/gen-word-365-count.jsonl\n",
      "Generated JSONL file with - 230 max words, 100 samples - at ./dataset/gen-word-230-count.jsonl\n",
      "Generated JSONL file with - 255 max words, 100 samples - at ./dataset/gen-word-255-count.jsonl\n",
      "Generated JSONL file with - 260 max words, 100 samples - at ./dataset/gen-word-260-count.jsonl\n",
      "Generated JSONL file with - 100 max words, 500 samples - at ./dataset/gen-word-100-count.jsonl\n",
      "Generated JSONL file with - 300 max words, 100 samples - at ./dataset/gen-word-300-count.jsonl\n",
      "Generated JSONL file with - 240 max words, 100 samples - at ./dataset/gen-word-240-count.jsonl\n",
      "Generated JSONL file with - 275 max words, 100 samples - at ./dataset/gen-word-275-count.jsonl\n",
      "Generated JSONL file with - 280 max words, 100 samples - at ./dataset/gen-word-280-count.jsonl\n",
      "Generated JSONL file with - 310 max words, 100 samples - at ./dataset/gen-word-310-count.jsonl\n",
      "Generated JSONL file with - 315 max words, 100 samples - at ./dataset/gen-word-315-count.jsonl\n",
      "Generated JSONL file with - 350 max words, 100 samples - at ./dataset/gen-word-350-count.jsonl\n",
      "Generated JSONL file with - 370 max words, 100 samples - at ./dataset/gen-word-370-count.jsonl\n",
      "Generated JSONL file with - 420 max words, 100 samples - at ./dataset/gen-word-420-count.jsonl\n",
      "Generated JSONL file with - 650 max words, 100 samples - at ./dataset/gen-word-650-count.jsonl\n",
      "Generated JSONL file with - 320 max words, 100 samples - at ./dataset/gen-word-320-count.jsonl\n",
      "Generated JSONL file with - 455 max words, 100 samples - at ./dataset/gen-word-455-count.jsonl\n",
      "Generated JSONL file with - 390 max words, 100 samples - at ./dataset/gen-word-390-count.jsonl\n",
      "Generated JSONL file with - 400 max words, 100 samples - at ./dataset/gen-word-400-count.jsonl\n",
      "Generated JSONL file with - 540 max words, 100 samples - at ./dataset/gen-word-540-count.jsonl\n",
      "Generated JSONL file with - 395 max words, 100 samples - at ./dataset/gen-word-395-count.jsonl\n",
      "Generated JSONL file with - 700 max words, 100 samples - at ./dataset/gen-word-700-count.jsonl\n",
      "Generated JSONL file with - 645 max words, 100 samples - at ./dataset/gen-word-645-count.jsonl\n",
      "Generated JSONL file with - 375 max words, 100 samples - at ./dataset/gen-word-375-count.jsonl\n",
      "Generated JSONL file with - 380 max words, 100 samples - at ./dataset/gen-word-380-count.jsonl\n",
      "Generated JSONL file with - 655 max words, 100 samples - at ./dataset/gen-word-655-count.jsonl\n",
      "Generated JSONL file with - 485 max words, 100 samples - at ./dataset/gen-word-485-count.jsonl\n",
      "Generated JSONL file with - 660 max words, 100 samples - at ./dataset/gen-word-660-count.jsonl\n",
      "Generated JSONL file with - 675 max words, 100 samples - at ./dataset/gen-word-675-count.jsonl\n",
      "Generated JSONL file with - 690 max words, 100 samples - at ./dataset/gen-word-690-count.jsonl\n",
      "Generated JSONL file with - 560 max words, 100 samples - at ./dataset/gen-word-560-count.jsonl\n",
      "Generated JSONL file with - 760 max words, 100 samples - at ./dataset/gen-word-760-count.jsonl\n",
      "Generated JSONL file with - 605 max words, 100 samples - at ./dataset/gen-word-605-count.jsonl\n",
      "Generated JSONL file with - 430 max words, 100 samples - at ./dataset/gen-word-430-count.jsonl\n",
      "Generated JSONL file with - 550 max words, 100 samples - at ./dataset/gen-word-550-count.jsonl\n",
      "Generated JSONL file with - 815 max words, 100 samples - at ./dataset/gen-word-815-count.jsonl\n",
      "Generated JSONL file with - 715 max words, 100 samples - at ./dataset/gen-word-715-count.jsonl\n",
      "Generated JSONL file with - 495 max words, 100 samples - at ./dataset/gen-word-495-count.jsonl\n",
      "Generated JSONL file with - 795 max words, 100 samples - at ./dataset/gen-word-795-count.jsonl\n",
      "Generated JSONL file with - 465 max words, 100 samples - at ./dataset/gen-word-465-count.jsonl\n",
      "Generated JSONL file with - 840 max words, 100 samples - at ./dataset/gen-word-840-count.jsonl\n",
      "Generated JSONL file with - 330 max words, 100 samples - at ./dataset/gen-word-330-count.jsonl\n",
      "Generated JSONL file with - 545 max words, 100 samples - at ./dataset/gen-word-545-count.jsonl\n",
      "Generated JSONL file with - 335 max words, 100 samples - at ./dataset/gen-word-335-count.jsonl\n",
      "Generated JSONL file with - 830 max words, 100 samples - at ./dataset/gen-word-830-count.jsonl\n",
      "Generated JSONL file with - 525 max words, 100 samples - at ./dataset/gen-word-525-count.jsonl\n",
      "Generated a single JSONL file with 1348 samples (100 token repeat) - 200 max words - at ./dataset/shuffle-word-200-count.jsonl\n",
      "Generated JSONL file with - 425 max words, 100 samples - at ./dataset/gen-word-425-count.jsonl\n",
      "Generated a single JSONL file with 705 samples (100 token repeat) - 365 max words - at ./dataset/shuffle-word-365-count.jsonl\n",
      "Generated JSONL file with - 765 max words, 100 samples - at ./dataset/gen-word-765-count.jsonl\n",
      "Generated JSONL file with - 725 max words, 100 samples - at ./dataset/gen-word-725-count.jsonl\n",
      "Generated JSONL file with - 325 max words, 100 samples - at ./dataset/gen-word-325-count.jsonl\n",
      "Generated JSONL file with - 435 max words, 100 samples - at ./dataset/gen-word-435-count.jsonl\n",
      "Generated JSONL file with - 640 max words, 100 samples - at ./dataset/gen-word-640-count.jsonl\n",
      "Generated JSONL file with - 755 max words, 100 samples - at ./dataset/gen-word-755-count.jsonl\n",
      "Generated JSONL file with - 475 max words, 100 samples - at ./dataset/gen-word-475-count.jsonl\n",
      "Generated JSONL file with - 695 max words, 100 samples - at ./dataset/gen-word-695-count.jsonl\n",
      "Generated JSONL file with - 535 max words, 100 samples - at ./dataset/gen-word-535-count.jsonl\n",
      "Generated JSONL file with - 575 max words, 100 samples - at ./dataset/gen-word-575-count.jsonl\n",
      "Generated JSONL file with - 590 max words, 100 samples - at ./dataset/gen-word-590-count.jsonl\n",
      "Generated a single JSONL file with 703 samples (100 token repeat) - 355 max words - at ./dataset/shuffle-word-355-count.jsonl\n",
      "Generated JSONL file with - 345 max words, 100 samples - at ./dataset/gen-word-345-count.jsonl\n",
      "Generated a single JSONL file with 4426 samples (100 token repeat) - 60 max words - at ./dataset/shuffle-word-60-count.jsonl\n",
      "Generated JSONL file with - 490 max words, 100 samples - at ./dataset/gen-word-490-count.jsonl\n",
      "Generated JSONL file with - 670 max words, 100 samples - at ./dataset/gen-word-670-count.jsonl\n",
      "Generated a single JSONL file with 588 samples (100 token repeat) - 490 max words - at ./dataset/shuffle-word-490-count.jsonl\n",
      "Generated a single JSONL file with 401 samples (100 token repeat) - 660 max words - at ./dataset/shuffle-word-660-count.jsonl\n",
      "Generated JSONL file with - 800 max words, 100 samples - at ./dataset/gen-word-800-count.jsonl\n",
      "Generated JSONL file with - 530 max words, 100 samples - at ./dataset/gen-word-530-count.jsonl\n",
      "Generated JSONL file with - 925 max words, 100 samples - at ./dataset/gen-word-925-count.jsonl\n",
      "Generated JSONL file with - 785 max words, 100 samples - at ./dataset/gen-word-785-count.jsonl\n",
      "Generated JSONL file with - 385 max words, 100 samples - at ./dataset/gen-word-385-count.jsonl\n",
      "Generated JSONL file with - 685 max words, 100 samples - at ./dataset/gen-word-685-count.jsonl\n",
      "Generated JSONL file with - 500 max words, 100 samples - at ./dataset/gen-word-500-count.jsonl\n",
      "Generated a single JSONL file with 705 samples (100 token repeat) - 340 max words - at ./dataset/shuffle-word-340-count.jsonl\n",
      "Generated JSONL file with - 585 max words, 100 samples - at ./dataset/gen-word-585-count.jsonl\n",
      "Generated a single JSONL file with 405 samples (100 token repeat) - 685 max words - at ./dataset/shuffle-word-685-count.jsonl\n",
      "Generated a single JSONL file with 3125 samples (100 token repeat) - 85 max words - at ./dataset/shuffle-word-85-count.jsonl\n",
      "Generated JSONL file with - 845 max words, 100 samples - at ./dataset/gen-word-845-count.jsonl\n",
      "Generated a single JSONL file with 1370 samples (100 token repeat) - 185 max words - at ./dataset/shuffle-word-185-count.jsonl\n",
      "Generated JSONL file with - 860 max words, 100 samples - at ./dataset/gen-word-860-count.jsonl\n",
      "Generated JSONL file with - 625 max words, 100 samples - at ./dataset/gen-word-625-count.jsonl\n",
      "Generated a single JSONL file with 3761 samples (100 token repeat) - 70 max words - at ./dataset/shuffle-word-70-count.jsonl\n",
      "Generated JSONL file with - 750 max words, 100 samples - at ./dataset/gen-word-750-count.jsonl\n",
      "Generated a single JSONL file with 3542 samples (100 token repeat) - 75 max words - at ./dataset/shuffle-word-75-count.jsonl\n",
      "Generated a single JSONL file with 405 samples (100 token repeat) - 680 max words - at ./dataset/shuffle-word-680-count.jsonl\n",
      "Generated JSONL file with - 450 max words, 100 samples - at ./dataset/gen-word-450-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 540 max words - at ./dataset/shuffle-word-540-count.jsonl\n",
      "Generated a single JSONL file with 315 samples (100 token repeat) - 830 max words - at ./dataset/shuffle-word-830-count.jsonl\n",
      "Generated JSONL file with - 665 max words, 100 samples - at ./dataset/gen-word-665-count.jsonl\n",
      "Generated a single JSONL file with 706 samples (100 token repeat) - 345 max words - at ./dataset/shuffle-word-345-count.jsonl\n",
      "Generated JSONL file with - 710 max words, 100 samples - at ./dataset/gen-word-710-count.jsonl\n",
      "Generated JSONL file with - 600 max words, 100 samples - at ./dataset/gen-word-600-count.jsonl\n",
      "Generated JSONL file with - 880 max words, 100 samples - at ./dataset/gen-word-880-count.jsonl\n",
      "Generated JSONL file with - 680 max words, 100 samples - at ./dataset/gen-word-680-count.jsonl\n",
      "Generated JSONL file with - 730 max words, 100 samples - at ./dataset/gen-word-730-count.jsonl\n",
      "Generated a single JSONL file with 398 samples (100 token repeat) - 755 max words - at ./dataset/shuffle-word-755-count.jsonl\n",
      "Generated JSONL file with - 580 max words, 100 samples - at ./dataset/gen-word-580-count.jsonl\n",
      "Generated JSONL file with - 805 max words, 100 samples - at ./dataset/gen-word-805-count.jsonl\n",
      "Generated JSONL file with - 735 max words, 100 samples - at ./dataset/gen-word-735-count.jsonl\n",
      "Generated a single JSONL file with 399 samples (100 token repeat) - 785 max words - at ./dataset/shuffle-word-785-count.jsonl\n",
      "Generated JSONL file with - 775 max words, 100 samples - at ./dataset/gen-word-775-count.jsonl\n",
      "Generated JSONL file with - 705 max words, 100 samples - at ./dataset/gen-word-705-count.jsonl\n",
      "Generated JSONL file with - 610 max words, 100 samples - at ./dataset/gen-word-610-count.jsonl\n",
      "Generated JSONL file with - 770 max words, 100 samples - at ./dataset/gen-word-770-count.jsonl\n",
      "Generated a single JSONL file with 4071 samples (100 token repeat) - 65 max words - at ./dataset/shuffle-word-65-count.jsonl\n",
      "Generated JSONL file with - 780 max words, 100 samples - at ./dataset/gen-word-780-count.jsonl\n",
      "Generated JSONL file with - 825 max words, 100 samples - at ./dataset/gen-word-825-count.jsonl\n",
      "Generated JSONL file with - 885 max words, 100 samples - at ./dataset/gen-word-885-count.jsonl\n",
      "Generated JSONL file with - 740 max words, 100 samples - at ./dataset/gen-word-740-count.jsonl\n",
      "Generated JSONL file with - 915 max words, 100 samples - at ./dataset/gen-word-915-count.jsonl\n",
      "Generated JSONL file with - 855 max words, 100 samples - at ./dataset/gen-word-855-count.jsonl\n",
      "Generated a single JSONL file with 908 samples (100 token repeat) - 295 max words - at ./dataset/shuffle-word-295-count.jsonl\n",
      "Generated JSONL file with - 720 max words, 100 samples - at ./dataset/gen-word-720-count.jsonl\n",
      "Generated JSONL file with - 790 max words, 100 samples - at ./dataset/gen-word-790-count.jsonl\n",
      "Generated a single JSONL file with 403 samples (100 token repeat) - 690 max words - at ./dataset/shuffle-word-690-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 930 max words - at ./dataset/shuffle-word-930-count.jsonl\n",
      "Generated a single JSONL file with 1362 samples (100 token repeat) - 190 max words - at ./dataset/shuffle-word-190-count.jsonl\n",
      "Generated JSONL file with - 920 max words, 100 samples - at ./dataset/gen-word-920-count.jsonl\n",
      "Generated JSONL file with - 895 max words, 100 samples - at ./dataset/gen-word-895-count.jsonl\n",
      "Generated a single JSONL file with 400 samples (100 token repeat) - 800 max words - at ./dataset/shuffle-word-800-count.jsonl\n",
      "Generated a single JSONL file with 314 samples (100 token repeat) - 820 max words - at ./dataset/shuffle-word-820-count.jsonl\n",
      "Generated JSONL file with - 460 max words, 100 samples - at ./dataset/gen-word-460-count.jsonl\n",
      "Generated a single JSONL file with 581 samples (100 token repeat) - 500 max words - at ./dataset/shuffle-word-500-count.jsonl\n",
      "Generated a single JSONL file with 915 samples (100 token repeat) - 300 max words - at ./dataset/shuffle-word-300-count.jsonl\n",
      "Generated a single JSONL file with 1910 samples (100 token repeat) - 115 max words - at ./dataset/shuffle-word-115-count.jsonl\n",
      "Generated JSONL file with - 975 max words, 100 samples - at ./dataset/gen-word-975-count.jsonl\n",
      "Generated JSONL file with - 835 max words, 100 samples - at ./dataset/gen-word-835-count.jsonl\n",
      "Generated a single JSONL file with 316 samples (100 token repeat) - 865 max words - at ./dataset/shuffle-word-865-count.jsonl\n",
      "Generated JSONL file with - 810 max words, 100 samples - at ./dataset/gen-word-810-count.jsonl\n",
      "Generated a single JSONL file with 402 samples (100 token repeat) - 670 max words - at ./dataset/shuffle-word-670-count.jsonl\n",
      "Generated JSONL file with - 630 max words, 100 samples - at ./dataset/gen-word-630-count.jsonl\n",
      "Generated a single JSONL file with 322 samples (100 token repeat) - 890 max words - at ./dataset/shuffle-word-890-count.jsonl\n",
      "Generated JSONL file with - 445 max words, 100 samples - at ./dataset/gen-word-445-count.jsonl\n",
      "Generated JSONL file with - 850 max words, 100 samples - at ./dataset/gen-word-850-count.jsonl\n",
      "Generated a single JSONL file with 711 samples (100 token repeat) - 315 max words - at ./dataset/shuffle-word-315-count.jsonl\n",
      "Generated a single JSONL file with 703 samples (100 token repeat) - 385 max words - at ./dataset/shuffle-word-385-count.jsonl\n",
      "Generated a single JSONL file with 2807 samples (100 token repeat) - 95 max words - at ./dataset/shuffle-word-95-count.jsonl\n",
      "Generated JSONL file with - 875 max words, 100 samples - at ./dataset/gen-word-875-count.jsonl\n",
      "Generated a single JSONL file with 1725 samples (100 token repeat) - 130 max words - at ./dataset/shuffle-word-130-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 925 max words - at ./dataset/shuffle-word-925-count.jsonl\n",
      "Generated JSONL file with - 865 max words, 100 samples - at ./dataset/gen-word-865-count.jsonl\n",
      "Generated JSONL file with - 470 max words, 100 samples - at ./dataset/gen-word-470-count.jsonl\n",
      "Generated JSONL file with - 905 max words, 100 samples - at ./dataset/gen-word-905-count.jsonl\n",
      "Generated a single JSONL file with 399 samples (100 token repeat) - 725 max words - at ./dataset/shuffle-word-725-count.jsonl\n",
      "Generated a single JSONL file with 403 samples (100 token repeat) - 665 max words - at ./dataset/shuffle-word-665-count.jsonl\n",
      "Generated JSONL file with - 820 max words, 100 samples - at ./dataset/gen-word-820-count.jsonl\n",
      "Generated a single JSONL file with 249 samples (100 token repeat) - 1210 max words - at ./dataset/shuffle-word-1210-count.jsonl\n",
      "Generated a single JSONL file with 314 samples (100 token repeat) - 815 max words - at ./dataset/shuffle-word-815-count.jsonl\n",
      "Generated JSONL file with - 1170 max words, 100 samples - at ./dataset/gen-word-1170-count.jsonl\n",
      "Generated JSONL file with - 410 max words, 100 samples - at ./dataset/gen-word-410-count.jsonl\n",
      "Generated JSONL file with - 930 max words, 100 samples - at ./dataset/gen-word-930-count.jsonl\n",
      "Generated JSONL file with - 440 max words, 100 samples - at ./dataset/gen-word-440-count.jsonl\n",
      "Generated JSONL file with - 1130 max words, 100 samples - at ./dataset/gen-word-1130-count.jsonl\n",
      "Generated JSONL file with - 900 max words, 100 samples - at ./dataset/gen-word-900-count.jsonl\n",
      "Generated a single JSONL file with 404 samples (100 token repeat) - 655 max words - at ./dataset/shuffle-word-655-count.jsonl\n",
      "Generated a single JSONL file with 398 samples (100 token repeat) - 750 max words - at ./dataset/shuffle-word-750-count.jsonl\n",
      "Generated JSONL file with - 480 max words, 100 samples - at ./dataset/gen-word-480-count.jsonl\n",
      "Generated JSONL file with - 870 max words, 100 samples - at ./dataset/gen-word-870-count.jsonl\n",
      "Generated JSONL file with - 910 max words, 100 samples - at ./dataset/gen-word-910-count.jsonl\n",
      "Generated a single JSONL file with 316 samples (100 token repeat) - 870 max words - at ./dataset/shuffle-word-870-count.jsonl\n",
      "Generated JSONL file with - 510 max words, 100 samples - at ./dataset/gen-word-510-count.jsonl\n",
      "Generated JSONL file with - 1015 max words, 100 samples - at ./dataset/gen-word-1015-count.jsonl\n",
      "Generated JSONL file with - 1155 max words, 100 samples - at ./dataset/gen-word-1155-count.jsonl\n",
      "Generated JSONL file with - 405 max words, 100 samples - at ./dataset/gen-word-405-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 910 max words - at ./dataset/shuffle-word-910-count.jsonl\n",
      "Generated JSONL file with - 520 max words, 100 samples - at ./dataset/gen-word-520-count.jsonl\n",
      "Generated a single JSONL file with 704 samples (100 token repeat) - 335 max words - at ./dataset/shuffle-word-335-count.jsonl\n",
      "Generated JSONL file with - 1150 max words, 100 samples - at ./dataset/gen-word-1150-count.jsonl\n",
      "Generated JSONL file with - 415 max words, 100 samples - at ./dataset/gen-word-415-count.jsonl\n",
      "Generated JSONL file with - 515 max words, 100 samples - at ./dataset/gen-word-515-count.jsonl\n",
      "Generated JSONL file with - 890 max words, 100 samples - at ./dataset/gen-word-890-count.jsonl\n",
      "Generated a single JSONL file with 400 samples (100 token repeat) - 780 max words - at ./dataset/shuffle-word-780-count.jsonl\n",
      "Generated JSONL file with - 1350 max words, 100 samples - at ./dataset/gen-word-1350-count.jsonl\n",
      "Generated a single JSONL file with 915 samples (100 token repeat) - 265 max words - at ./dataset/shuffle-word-265-count.jsonl\n",
      "Generated a single JSONL file with 702 samples (100 token repeat) - 330 max words - at ./dataset/shuffle-word-330-count.jsonl\n",
      "Generated a single JSONL file with 917 samples (100 token repeat) - 270 max words - at ./dataset/shuffle-word-270-count.jsonl\n",
      "Generated a single JSONL file with 5246 samples (100 token repeat) - 50 max words - at ./dataset/shuffle-word-50-count.jsonl\n",
      "Generated a single JSONL file with 724 samples (100 token repeat) - 310 max words - at ./dataset/shuffle-word-310-count.jsonl\n",
      "Generated JSONL file with - 1260 max words, 100 samples - at ./dataset/gen-word-1260-count.jsonl\n",
      "Generated a single JSONL file with 318 samples (100 token repeat) - 885 max words - at ./dataset/shuffle-word-885-count.jsonl\n",
      "Generated a single JSONL file with 709 samples (100 token repeat) - 320 max words - at ./dataset/shuffle-word-320-count.jsonl\n",
      "Generated JSONL file with - 570 max words, 100 samples - at ./dataset/gen-word-570-count.jsonl\n",
      "Generated a single JSONL file with 318 samples (100 token repeat) - 850 max words - at ./dataset/shuffle-word-850-count.jsonl\n",
      "Generated JSONL file with - 615 max words, 100 samples - at ./dataset/gen-word-615-count.jsonl\n",
      "Generated a single JSONL file with 590 samples (100 token repeat) - 455 max words - at ./dataset/shuffle-word-455-count.jsonl\n",
      "Generated a single JSONL file with 732 samples (100 token repeat) - 305 max words - at ./dataset/shuffle-word-305-count.jsonl\n",
      "Generated a single JSONL file with 576 samples (100 token repeat) - 460 max words - at ./dataset/shuffle-word-460-count.jsonl\n",
      "Generated a single JSONL file with 403 samples (100 token repeat) - 700 max words - at ./dataset/shuffle-word-700-count.jsonl\n",
      "Generated JSONL file with - 1095 max words, 100 samples - at ./dataset/gen-word-1095-count.jsonl\n",
      "Generated a single JSONL file with 4840 samples (100 token repeat) - 55 max words - at ./dataset/shuffle-word-55-count.jsonl\n",
      "Generated JSONL file with - 565 max words, 100 samples - at ./dataset/gen-word-565-count.jsonl\n",
      "Generated a single JSONL file with 398 samples (100 token repeat) - 795 max words - at ./dataset/shuffle-word-795-count.jsonl\n",
      "Generated JSONL file with - 505 max words, 100 samples - at ./dataset/gen-word-505-count.jsonl\n",
      "Generated a single JSONL file with 204 samples (100 token repeat) - 1345 max words - at ./dataset/shuffle-word-1345-count.jsonl\n",
      "Generated JSONL file with - 1115 max words, 100 samples - at ./dataset/gen-word-1115-count.jsonl\n",
      "Generated JSONL file with - 620 max words, 100 samples - at ./dataset/gen-word-620-count.jsonl\n",
      "Generated JSONL file with - 1000 max words, 100 samples - at ./dataset/gen-word-1000-count.jsonl\n",
      "Generated a single JSONL file with 320 samples (100 token repeat) - 840 max words - at ./dataset/shuffle-word-840-count.jsonl\n",
      "Generated a single JSONL file with 201 samples (100 token repeat) - 1355 max words - at ./dataset/shuffle-word-1355-count.jsonl\n",
      "Generated a single JSONL file with 398 samples (100 token repeat) - 720 max words - at ./dataset/shuffle-word-720-count.jsonl\n",
      "Generated JSONL file with - 1025 max words, 100 samples - at ./dataset/gen-word-1025-count.jsonl\n",
      "Generated a single JSONL file with 1022 samples (100 token repeat) - 215 max words - at ./dataset/shuffle-word-215-count.jsonl\n",
      "Generated JSONL file with - 1420 max words, 100 samples - at ./dataset/gen-word-1420-count.jsonl\n",
      "Generated JSONL file with - 1345 max words, 100 samples - at ./dataset/gen-word-1345-count.jsonl\n",
      "Generated JSONL file with - 1490 max words, 100 samples - at ./dataset/gen-word-1490-count.jsonl\n",
      "Generated a single JSONL file with 401 samples (100 token repeat) - 620 max words - at ./dataset/shuffle-word-620-count.jsonl\n",
      "Generated a single JSONL file with 400 samples (100 token repeat) - 790 max words - at ./dataset/shuffle-word-790-count.jsonl\n",
      "Generated a single JSONL file with 298 samples (100 token repeat) - 1110 max words - at ./dataset/shuffle-word-1110-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 935 max words - at ./dataset/shuffle-word-935-count.jsonl\n",
      "Generated a single JSONL file with 405 samples (100 token repeat) - 695 max words - at ./dataset/shuffle-word-695-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 600 max words - at ./dataset/shuffle-word-600-count.jsonl\n",
      "Generated a single JSONL file with 320 samples (100 token repeat) - 880 max words - at ./dataset/shuffle-word-880-count.jsonl\n",
      "Generated a single JSONL file with 399 samples (100 token repeat) - 745 max words - at ./dataset/shuffle-word-745-count.jsonl\n",
      "Generated JSONL file with - 1135 max words, 100 samples - at ./dataset/gen-word-1135-count.jsonl\n",
      "Generated a single JSONL file with 498 samples (100 token repeat) - 575 max words - at ./dataset/shuffle-word-575-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 940 max words - at ./dataset/shuffle-word-940-count.jsonl\n",
      "Generated JSONL file with - 1105 max words, 100 samples - at ./dataset/gen-word-1105-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 545 max words - at ./dataset/shuffle-word-545-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 920 max words - at ./dataset/shuffle-word-920-count.jsonl\n",
      "Generated a single JSONL file with 400 samples (100 token repeat) - 675 max words - at ./dataset/shuffle-word-675-count.jsonl\n",
      "Generated a single JSONL file with 316 samples (100 token repeat) - 845 max words - at ./dataset/shuffle-word-845-count.jsonl\n",
      "Generated a single JSONL file with 590 samples (100 token repeat) - 435 max words - at ./dataset/shuffle-word-435-count.jsonl\n",
      "Generated a single JSONL file with 252 samples (100 token repeat) - 1245 max words - at ./dataset/shuffle-word-1245-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 970 max words - at ./dataset/shuffle-word-970-count.jsonl\n",
      "Generated a single JSONL file with 5858 samples (100 token repeat) - 45 max words - at ./dataset/shuffle-word-45-count.jsonl\n",
      "Generated a single JSONL file with 710 samples (100 token repeat) - 325 max words - at ./dataset/shuffle-word-325-count.jsonl\n",
      "Generated JSONL file with - 635 max words, 100 samples - at ./dataset/gen-word-635-count.jsonl\n",
      "Generated a single JSONL file with 404 samples (100 token repeat) - 650 max words - at ./dataset/shuffle-word-650-count.jsonl\n",
      "Generated JSONL file with - 1020 max words, 100 samples - at ./dataset/gen-word-1020-count.jsonl\n",
      "Generated a single JSONL file with 497 samples (100 token repeat) - 565 max words - at ./dataset/shuffle-word-565-count.jsonl\n",
      "Generated a single JSONL file with 592 samples (100 token repeat) - 425 max words - at ./dataset/shuffle-word-425-count.jsonl\n",
      "Generated a single JSONL file with 3318 samples (100 token repeat) - 80 max words - at ./dataset/shuffle-word-80-count.jsonl\n",
      "Generated a single JSONL file with 701 samples (100 token repeat) - 350 max words - at ./dataset/shuffle-word-350-count.jsonl\n",
      "Generated a single JSONL file with 592 samples (100 token repeat) - 465 max words - at ./dataset/shuffle-word-465-count.jsonl\n",
      "Generated a single JSONL file with 314 samples (100 token repeat) - 810 max words - at ./dataset/shuffle-word-810-count.jsonl\n",
      "Generated a single JSONL file with 324 samples (100 token repeat) - 855 max words - at ./dataset/shuffle-word-855-count.jsonl\n",
      "Generated a single JSONL file with 399 samples (100 token repeat) - 775 max words - at ./dataset/shuffle-word-775-count.jsonl\n",
      "Generated JSONL file with - 1235 max words, 100 samples - at ./dataset/gen-word-1235-count.jsonl\n",
      "Generated a single JSONL file with 317 samples (100 token repeat) - 805 max words - at ./dataset/shuffle-word-805-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 905 max words - at ./dataset/shuffle-word-905-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1455 max words - at ./dataset/shuffle-word-1455-count.jsonl\n",
      "Generated JSONL file with - 950 max words, 100 samples - at ./dataset/gen-word-950-count.jsonl\n",
      "Generated JSONL file with - 1460 max words, 100 samples - at ./dataset/gen-word-1460-count.jsonl\n",
      "Generated a single JSONL file with 403 samples (100 token repeat) - 645 max words - at ./dataset/shuffle-word-645-count.jsonl\n",
      "Generated a single JSONL file with 404 samples (100 token repeat) - 610 max words - at ./dataset/shuffle-word-610-count.jsonl\n",
      "Generated a single JSONL file with 252 samples (100 token repeat) - 1300 max words - at ./dataset/shuffle-word-1300-count.jsonl\n",
      "Generated a single JSONL file with 398 samples (100 token repeat) - 710 max words - at ./dataset/shuffle-word-710-count.jsonl\n",
      "Generated a single JSONL file with 206 samples (100 token repeat) - 1350 max words - at ./dataset/shuffle-word-1350-count.jsonl\n",
      "Generated a single JSONL file with 254 samples (100 token repeat) - 1255 max words - at ./dataset/shuffle-word-1255-count.jsonl\n",
      "Generated JSONL file with - 555 max words, 100 samples - at ./dataset/gen-word-555-count.jsonl\n",
      "Generated a single JSONL file with 702 samples (100 token repeat) - 390 max words - at ./dataset/shuffle-word-390-count.jsonl\n",
      "Generated JSONL file with - 1230 max words, 100 samples - at ./dataset/gen-word-1230-count.jsonl\n",
      "Generated JSONL file with - 1050 max words, 100 samples - at ./dataset/gen-word-1050-count.jsonl\n",
      "Generated JSONL file with - 1330 max words, 100 samples - at ./dataset/gen-word-1330-count.jsonl\n",
      "Generated a single JSONL file with 400 samples (100 token repeat) - 715 max words - at ./dataset/shuffle-word-715-count.jsonl\n",
      "Generated a single JSONL file with 398 samples (100 token repeat) - 765 max words - at ./dataset/shuffle-word-765-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 985 max words - at ./dataset/shuffle-word-985-count.jsonl\n",
      "Generated JSONL file with - 1195 max words, 100 samples - at ./dataset/gen-word-1195-count.jsonl\n",
      "Generated a single JSONL file with 399 samples (100 token repeat) - 730 max words - at ./dataset/shuffle-word-730-count.jsonl\n",
      "Generated a single JSONL file with 319 samples (100 token repeat) - 825 max words - at ./dataset/shuffle-word-825-count.jsonl\n",
      "Generated JSONL file with - 980 max words, 100 samples - at ./dataset/gen-word-980-count.jsonl\n",
      "Generated JSONL file with - 955 max words, 100 samples - at ./dataset/gen-word-955-count.jsonl\n",
      "Generated a single JSONL file with 1683 samples (100 token repeat) - 135 max words - at ./dataset/shuffle-word-135-count.jsonl\n",
      "Generated JSONL file with - 1335 max words, 100 samples - at ./dataset/gen-word-1335-count.jsonl\n",
      "Generated JSONL file with - 1455 max words, 100 samples - at ./dataset/gen-word-1455-count.jsonl\n",
      "Generated JSONL file with - 1055 max words, 100 samples - at ./dataset/gen-word-1055-count.jsonl\n",
      "Generated JSONL file with - 1445 max words, 100 samples - at ./dataset/gen-word-1445-count.jsonl\n",
      "Generated JSONL file with - 1465 max words, 100 samples - at ./dataset/gen-word-1465-count.jsonl\n",
      "Generated a single JSONL file with 399 samples (100 token repeat) - 760 max words - at ./dataset/shuffle-word-760-count.jsonl\n",
      "Generated JSONL file with - 1205 max words, 100 samples - at ./dataset/gen-word-1205-count.jsonl\n",
      "Generated a single JSONL file with 296 samples (100 token repeat) - 1115 max words - at ./dataset/shuffle-word-1115-count.jsonl\n",
      "Generated JSONL file with - 1290 max words, 100 samples - at ./dataset/gen-word-1290-count.jsonl\n",
      "Generated a single JSONL file with 318 samples (100 token repeat) - 900 max words - at ./dataset/shuffle-word-900-count.jsonl\n",
      "Generated a single JSONL file with 1537 samples (100 token repeat) - 150 max words - at ./dataset/shuffle-word-150-count.jsonl\n",
      "Generated JSONL file with - 935 max words, 100 samples - at ./dataset/gen-word-935-count.jsonl\n",
      "Generated a single JSONL file with 595 samples (100 token repeat) - 415 max words - at ./dataset/shuffle-word-415-count.jsonl\n",
      "Generated JSONL file with - 595 max words, 100 samples - at ./dataset/gen-word-595-count.jsonl\n",
      "Generated a single JSONL file with 324 samples (100 token repeat) - 895 max words - at ./dataset/shuffle-word-895-count.jsonl\n",
      "Generated a single JSONL file with 586 samples (100 token repeat) - 480 max words - at ./dataset/shuffle-word-480-count.jsonl\n",
      "Generated a single JSONL file with 313 samples (100 token repeat) - 835 max words - at ./dataset/shuffle-word-835-count.jsonl\n",
      "Generated JSONL file with - 940 max words, 100 samples - at ./dataset/gen-word-940-count.jsonl\n",
      "Generated JSONL file with - 1180 max words, 100 samples - at ./dataset/gen-word-1180-count.jsonl\n",
      "Generated JSONL file with - 1370 max words, 100 samples - at ./dataset/gen-word-1370-count.jsonl\n",
      "Generated JSONL file with - 1450 max words, 100 samples - at ./dataset/gen-word-1450-count.jsonl\n",
      "Generated JSONL file with - 985 max words, 100 samples - at ./dataset/gen-word-985-count.jsonl\n",
      "Generated JSONL file with - 1390 max words, 100 samples - at ./dataset/gen-word-1390-count.jsonl\n",
      "Generated JSONL file with - 960 max words, 100 samples - at ./dataset/gen-word-960-count.jsonl\n",
      "Generated a single JSONL file with 1468 samples (100 token repeat) - 160 max words - at ./dataset/shuffle-word-160-count.jsonl\n",
      "Generated a single JSONL file with 312 samples (100 token repeat) - 860 max words - at ./dataset/shuffle-word-860-count.jsonl\n",
      "Generated JSONL file with - 1495 max words, 100 samples - at ./dataset/gen-word-1495-count.jsonl\n",
      "Generated a single JSONL file with 398 samples (100 token repeat) - 770 max words - at ./dataset/shuffle-word-770-count.jsonl\n",
      "Generated a single JSONL file with 1001 samples (100 token repeat) - 225 max words - at ./dataset/shuffle-word-225-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 915 max words - at ./dataset/shuffle-word-915-count.jsonl\n",
      "Generated a single JSONL file with 316 samples (100 token repeat) - 875 max words - at ./dataset/shuffle-word-875-count.jsonl\n",
      "Generated JSONL file with - 1360 max words, 100 samples - at ./dataset/gen-word-1360-count.jsonl\n",
      "Generated a single JSONL file with 586 samples (100 token repeat) - 440 max words - at ./dataset/shuffle-word-440-count.jsonl\n",
      "Generated a single JSONL file with 1394 samples (100 token repeat) - 175 max words - at ./dataset/shuffle-word-175-count.jsonl\n",
      "Generated JSONL file with - 1085 max words, 100 samples - at ./dataset/gen-word-1085-count.jsonl\n",
      "Generated a single JSONL file with 203 samples (100 token repeat) - 1360 max words - at ./dataset/shuffle-word-1360-count.jsonl\n",
      "Generated JSONL file with - 1010 max words, 100 samples - at ./dataset/gen-word-1010-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1475 max words - at ./dataset/shuffle-word-1475-count.jsonl\n",
      "Generated JSONL file with - 1080 max words, 100 samples - at ./dataset/gen-word-1080-count.jsonl\n",
      "Generated a single JSONL file with 399 samples (100 token repeat) - 740 max words - at ./dataset/shuffle-word-740-count.jsonl\n",
      "Generated JSONL file with - 1500 max words, 100 samples - at ./dataset/gen-word-1500-count.jsonl\n",
      "Generated JSONL file with - 745 max words, 100 samples - at ./dataset/gen-word-745-count.jsonl\n",
      "Generated a single JSONL file with 204 samples (100 token repeat) - 1315 max words - at ./dataset/shuffle-word-1315-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 950 max words - at ./dataset/shuffle-word-950-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1025 max words - at ./dataset/shuffle-word-1025-count.jsonl\n",
      "Generated a single JSONL file with 204 samples (100 token repeat) - 1330 max words - at ./dataset/shuffle-word-1330-count.jsonl\n",
      "Generated a single JSONL file with 397 samples (100 token repeat) - 705 max words - at ./dataset/shuffle-word-705-count.jsonl\n",
      "Generated a single JSONL file with 247 samples (100 token repeat) - 1275 max words - at ./dataset/shuffle-word-1275-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 525 max words - at ./dataset/shuffle-word-525-count.jsonl\n",
      "Generated a single JSONL file with 299 samples (100 token repeat) - 1120 max words - at ./dataset/shuffle-word-1120-count.jsonl\n",
      "Generated a single JSONL file with 298 samples (100 token repeat) - 1175 max words - at ./dataset/shuffle-word-1175-count.jsonl\n",
      "Generated JSONL file with - 1470 max words, 100 samples - at ./dataset/gen-word-1470-count.jsonl\n",
      "Generated a single JSONL file with 248 samples (100 token repeat) - 1235 max words - at ./dataset/shuffle-word-1235-count.jsonl\n",
      "Generated a single JSONL file with 699 samples (100 token repeat) - 395 max words - at ./dataset/shuffle-word-395-count.jsonl\n",
      "Generated a single JSONL file with 500 samples (100 token repeat) - 580 max words - at ./dataset/shuffle-word-580-count.jsonl\n",
      "Generated JSONL file with - 1065 max words, 100 samples - at ./dataset/gen-word-1065-count.jsonl\n",
      "Generated JSONL file with - 1090 max words, 100 samples - at ./dataset/gen-word-1090-count.jsonl\n",
      "Generated a single JSONL file with 1382 samples (100 token repeat) - 180 max words - at ./dataset/shuffle-word-180-count.jsonl\n",
      "Generated a single JSONL file with 597 samples (100 token repeat) - 405 max words - at ./dataset/shuffle-word-405-count.jsonl\n",
      "Generated JSONL file with - 1240 max words, 100 samples - at ./dataset/gen-word-1240-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1450 max words - at ./dataset/shuffle-word-1450-count.jsonl\n",
      "Generated JSONL file with - 1475 max words, 100 samples - at ./dataset/gen-word-1475-count.jsonl\n",
      "Generated JSONL file with - 1365 max words, 100 samples - at ./dataset/gen-word-1365-count.jsonl\n",
      "Generated JSONL file with - 995 max words, 100 samples - at ./dataset/gen-word-995-count.jsonl\n",
      "Generated JSONL file with - 1175 max words, 100 samples - at ./dataset/gen-word-1175-count.jsonl\n",
      "Generated JSONL file with - 1035 max words, 100 samples - at ./dataset/gen-word-1035-count.jsonl\n",
      "Generated a single JSONL file with 402 samples (100 token repeat) - 630 max words - at ./dataset/shuffle-word-630-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 555 max words - at ./dataset/shuffle-word-555-count.jsonl\n",
      "Generated JSONL file with - 1310 max words, 100 samples - at ./dataset/gen-word-1310-count.jsonl\n",
      "Generated a single JSONL file with 401 samples (100 token repeat) - 640 max words - at ./dataset/shuffle-word-640-count.jsonl\n",
      "Generated JSONL file with - 1245 max words, 100 samples - at ./dataset/gen-word-1245-count.jsonl\n",
      "Generated JSONL file with - 1125 max words, 100 samples - at ./dataset/gen-word-1125-count.jsonl\n",
      "Generated a single JSONL file with 500 samples (100 token repeat) - 505 max words - at ./dataset/shuffle-word-505-count.jsonl\n",
      "Generated JSONL file with - 1210 max words, 100 samples - at ./dataset/gen-word-1210-count.jsonl\n",
      "Generated a single JSONL file with 2057 samples (100 token repeat) - 105 max words - at ./dataset/shuffle-word-105-count.jsonl\n",
      "Generated JSONL file with - 1270 max words, 100 samples - at ./dataset/gen-word-1270-count.jsonl\n",
      "Generated JSONL file with - 1225 max words, 100 samples - at ./dataset/gen-word-1225-count.jsonl\n",
      "Generated JSONL file with - 945 max words, 100 samples - at ./dataset/gen-word-945-count.jsonl\n",
      "Generated JSONL file with - 1400 max words, 100 samples - at ./dataset/gen-word-1400-count.jsonl\n",
      "Generated JSONL file with - 1410 max words, 100 samples - at ./dataset/gen-word-1410-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1090 max words - at ./dataset/shuffle-word-1090-count.jsonl\n",
      "Generated JSONL file with - 1185 max words, 100 samples - at ./dataset/gen-word-1185-count.jsonl\n",
      "Generated a single JSONL file with 498 samples (100 token repeat) - 550 max words - at ./dataset/shuffle-word-550-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1015 max words - at ./dataset/shuffle-word-1015-count.jsonl\n",
      "Generated JSONL file with - 1295 max words, 100 samples - at ./dataset/gen-word-1295-count.jsonl\n",
      "Generated JSONL file with - 1375 max words, 100 samples - at ./dataset/gen-word-1375-count.jsonl\n",
      "Generated a single JSONL file with 257 samples (100 token repeat) - 1290 max words - at ./dataset/shuffle-word-1290-count.jsonl\n",
      "Generated a single JSONL file with 1046 samples (100 token repeat) - 210 max words - at ./dataset/shuffle-word-210-count.jsonl\n",
      "Generated JSONL file with - 1425 max words, 100 samples - at ./dataset/gen-word-1425-count.jsonl\n",
      "Generated JSONL file with - 1325 max words, 100 samples - at ./dataset/gen-word-1325-count.jsonl\n",
      "Generated a single JSONL file with 254 samples (100 token repeat) - 1230 max words - at ./dataset/shuffle-word-1230-count.jsonl\n",
      "Generated a single JSONL file with 498 samples (100 token repeat) - 570 max words - at ./dataset/shuffle-word-570-count.jsonl\n",
      "Generated JSONL file with - 965 max words, 100 samples - at ./dataset/gen-word-965-count.jsonl\n",
      "Generated JSONL file with - 1075 max words, 100 samples - at ./dataset/gen-word-1075-count.jsonl\n",
      "Generated a single JSONL file with 1412 samples (100 token repeat) - 170 max words - at ./dataset/shuffle-word-170-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1480 max words - at ./dataset/shuffle-word-1480-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1055 max words - at ./dataset/shuffle-word-1055-count.jsonl\n",
      "Generated JSONL file with - 1100 max words, 100 samples - at ./dataset/gen-word-1100-count.jsonl\n",
      "Generated a single JSONL file with 249 samples (100 token repeat) - 1225 max words - at ./dataset/shuffle-word-1225-count.jsonl\n",
      "Generated JSONL file with - 1415 max words, 100 samples - at ./dataset/gen-word-1415-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1185 max words - at ./dataset/shuffle-word-1185-count.jsonl\n",
      "Generated JSONL file with - 1355 max words, 100 samples - at ./dataset/gen-word-1355-count.jsonl\n",
      "Generated a single JSONL file with 17799 samples (100 token repeat) - 15 max words - at ./dataset/shuffle-word-15-count.jsonl\n",
      "Generated a single JSONL file with 1845 samples (100 token repeat) - 120 max words - at ./dataset/shuffle-word-120-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1490 max words - at ./dataset/shuffle-word-1490-count.jsonl\n",
      "Generated a single JSONL file with 996 samples (100 token repeat) - 230 max words - at ./dataset/shuffle-word-230-count.jsonl\n",
      "Generated JSONL file with - 1120 max words, 100 samples - at ./dataset/gen-word-1120-count.jsonl\n",
      "Generated JSONL file with - 1060 max words, 100 samples - at ./dataset/gen-word-1060-count.jsonl\n",
      "Generated a single JSONL file with 584 samples (100 token repeat) - 450 max words - at ./dataset/shuffle-word-450-count.jsonl\n",
      "Generated a single JSONL file with 919 samples (100 token repeat) - 280 max words - at ./dataset/shuffle-word-280-count.jsonl\n",
      "Generated JSONL file with - 1480 max words, 100 samples - at ./dataset/gen-word-1480-count.jsonl\n",
      "Generated JSONL file with - 1220 max words, 100 samples - at ./dataset/gen-word-1220-count.jsonl\n",
      "Generated JSONL file with - 1320 max words, 100 samples - at ./dataset/gen-word-1320-count.jsonl\n",
      "Generated JSONL file with - 1045 max words, 100 samples - at ./dataset/gen-word-1045-count.jsonl\n",
      "Generated a single JSONL file with 202 samples (100 token repeat) - 1335 max words - at ./dataset/shuffle-word-1335-count.jsonl\n",
      "Generated JSONL file with - 1280 max words, 100 samples - at ./dataset/gen-word-1280-count.jsonl\n",
      "Generated JSONL file with - 1405 max words, 100 samples - at ./dataset/gen-word-1405-count.jsonl\n",
      "Generated JSONL file with - 1160 max words, 100 samples - at ./dataset/gen-word-1160-count.jsonl\n",
      "Generated a single JSONL file with 398 samples (100 token repeat) - 735 max words - at ./dataset/shuffle-word-735-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 585 max words - at ./dataset/shuffle-word-585-count.jsonl\n",
      "Generated JSONL file with - 1200 max words, 100 samples - at ./dataset/gen-word-1200-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 955 max words - at ./dataset/shuffle-word-955-count.jsonl\n",
      "Generated a single JSONL file with 913 samples (100 token repeat) - 290 max words - at ./dataset/shuffle-word-290-count.jsonl\n",
      "Generated a single JSONL file with 939 samples (100 token repeat) - 250 max words - at ./dataset/shuffle-word-250-count.jsonl\n",
      "Generated JSONL file with - 1275 max words, 100 samples - at ./dataset/gen-word-1275-count.jsonl\n",
      "Generated JSONL file with - 1030 max words, 100 samples - at ./dataset/gen-word-1030-count.jsonl\n",
      "Generated a single JSONL file with 699 samples (100 token repeat) - 400 max words - at ./dataset/shuffle-word-400-count.jsonl\n",
      "Generated JSONL file with - 1040 max words, 100 samples - at ./dataset/gen-word-1040-count.jsonl\n",
      "Generated a single JSONL file with 704 samples (100 token repeat) - 370 max words - at ./dataset/shuffle-word-370-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1370 max words - at ./dataset/shuffle-word-1370-count.jsonl\n",
      "Generated JSONL file with - 970 max words, 100 samples - at ./dataset/gen-word-970-count.jsonl\n",
      "Generated a single JSONL file with 2932 samples (100 token repeat) - 90 max words - at ./dataset/shuffle-word-90-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 945 max words - at ./dataset/shuffle-word-945-count.jsonl\n",
      "Generated JSONL file with - 1190 max words, 100 samples - at ./dataset/gen-word-1190-count.jsonl\n",
      "Generated a single JSONL file with 2659 samples (100 token repeat) - 100 max words - at ./dataset/shuffle-word-100-count.jsonl\n",
      "Generated a single JSONL file with 258 samples (100 token repeat) - 1260 max words - at ./dataset/shuffle-word-1260-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1435 max words - at ./dataset/shuffle-word-1435-count.jsonl\n",
      "Generated a single JSONL file with 1791 samples (100 token repeat) - 125 max words - at ./dataset/shuffle-word-125-count.jsonl\n",
      "Generated a single JSONL file with 931 samples (100 token repeat) - 260 max words - at ./dataset/shuffle-word-260-count.jsonl\n",
      "Generated a single JSONL file with 915 samples (100 token repeat) - 285 max words - at ./dataset/shuffle-word-285-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1180 max words - at ./dataset/shuffle-word-1180-count.jsonl\n",
      "Generated JSONL file with - 1385 max words, 100 samples - at ./dataset/gen-word-1385-count.jsonl\n",
      "Generated JSONL file with - 1110 max words, 100 samples - at ./dataset/gen-word-1110-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1035 max words - at ./dataset/shuffle-word-1035-count.jsonl\n",
      "Generated a single JSONL file with 593 samples (100 token repeat) - 420 max words - at ./dataset/shuffle-word-420-count.jsonl\n",
      "Generated a single JSONL file with 250 samples (100 token repeat) - 1265 max words - at ./dataset/shuffle-word-1265-count.jsonl\n",
      "Generated a single JSONL file with 990 samples (100 token repeat) - 235 max words - at ./dataset/shuffle-word-235-count.jsonl\n",
      "Generated a single JSONL file with 239 samples (100 token repeat) - 1280 max words - at ./dataset/shuffle-word-1280-count.jsonl\n",
      "Generated a single JSONL file with 298 samples (100 token repeat) - 1125 max words - at ./dataset/shuffle-word-1125-count.jsonl\n",
      "Generated a single JSONL file with 203 samples (100 token repeat) - 1375 max words - at ./dataset/shuffle-word-1375-count.jsonl\n",
      "Generated JSONL file with - 1250 max words, 100 samples - at ./dataset/gen-word-1250-count.jsonl\n",
      "Generated JSONL file with - 1430 max words, 100 samples - at ./dataset/gen-word-1430-count.jsonl\n",
      "Generated a single JSONL file with 497 samples (100 token repeat) - 560 max words - at ./dataset/shuffle-word-560-count.jsonl\n",
      "Generated a single JSONL file with 500 samples (100 token repeat) - 515 max words - at ./dataset/shuffle-word-515-count.jsonl\n",
      "Generated JSONL file with - 1140 max words, 100 samples - at ./dataset/gen-word-1140-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1060 max words - at ./dataset/shuffle-word-1060-count.jsonl\n",
      "Generated a single JSONL file with 298 samples (100 token repeat) - 1195 max words - at ./dataset/shuffle-word-1195-count.jsonl\n",
      "Generated JSONL file with - 1145 max words, 100 samples - at ./dataset/gen-word-1145-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1470 max words - at ./dataset/shuffle-word-1470-count.jsonl\n",
      "Generated a single JSONL file with 203 samples (100 token repeat) - 1365 max words - at ./dataset/shuffle-word-1365-count.jsonl\n",
      "Generated a single JSONL file with 500 samples (100 token repeat) - 595 max words - at ./dataset/shuffle-word-595-count.jsonl\n",
      "Generated JSONL file with - 990 max words, 100 samples - at ./dataset/gen-word-990-count.jsonl\n",
      "Generated JSONL file with - 1340 max words, 100 samples - at ./dataset/gen-word-1340-count.jsonl\n",
      "Generated JSONL file with - 1165 max words, 100 samples - at ./dataset/gen-word-1165-count.jsonl\n",
      "Generated JSONL file with - 1315 max words, 100 samples - at ./dataset/gen-word-1315-count.jsonl\n",
      "Generated a single JSONL file with 1582 samples (100 token repeat) - 145 max words - at ./dataset/shuffle-word-145-count.jsonl\n",
      "Generated a single JSONL file with 202 samples (100 token repeat) - 1380 max words - at ./dataset/shuffle-word-1380-count.jsonl\n",
      "Generated JSONL file with - 1435 max words, 100 samples - at ./dataset/gen-word-1435-count.jsonl\n",
      "Generated a single JSONL file with 969 samples (100 token repeat) - 240 max words - at ./dataset/shuffle-word-240-count.jsonl\n",
      "Generated a single JSONL file with 299 samples (100 token repeat) - 1200 max words - at ./dataset/shuffle-word-1200-count.jsonl\n",
      "Generated JSONL file with - 1005 max words, 100 samples - at ./dataset/gen-word-1005-count.jsonl\n",
      "Generated a single JSONL file with 298 samples (100 token repeat) - 1190 max words - at ./dataset/shuffle-word-1190-count.jsonl\n",
      "Generated a single JSONL file with 203 samples (100 token repeat) - 1340 max words - at ./dataset/shuffle-word-1340-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1065 max words - at ./dataset/shuffle-word-1065-count.jsonl\n",
      "Generated a single JSONL file with 258 samples (100 token repeat) - 1240 max words - at ./dataset/shuffle-word-1240-count.jsonl\n",
      "Generated a single JSONL file with 1992 samples (100 token repeat) - 110 max words - at ./dataset/shuffle-word-110-count.jsonl\n",
      "Generated JSONL file with - 1485 max words, 100 samples - at ./dataset/gen-word-1485-count.jsonl\n",
      "Generated JSONL file with - 1380 max words, 100 samples - at ./dataset/gen-word-1380-count.jsonl\n",
      "Generated a single JSONL file with 7531 samples (100 token repeat) - 35 max words - at ./dataset/shuffle-word-35-count.jsonl\n",
      "Generated a single JSONL file with 299 samples (100 token repeat) - 1155 max words - at ./dataset/shuffle-word-1155-count.jsonl\n",
      "Generated a single JSONL file with 917 samples (100 token repeat) - 275 max words - at ./dataset/shuffle-word-275-count.jsonl\n",
      "Generated a single JSONL file with 583 samples (100 token repeat) - 470 max words - at ./dataset/shuffle-word-470-count.jsonl\n",
      "Generated a single JSONL file with 403 samples (100 token repeat) - 615 max words - at ./dataset/shuffle-word-615-count.jsonl\n",
      "Generated a single JSONL file with 1353 samples (100 token repeat) - 195 max words - at ./dataset/shuffle-word-195-count.jsonl\n",
      "Generated JSONL file with - 1070 max words, 100 samples - at ./dataset/gen-word-1070-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1430 max words - at ./dataset/shuffle-word-1430-count.jsonl\n",
      "Generated a single JSONL file with 13090 samples (100 token repeat) - 20 max words - at ./dataset/shuffle-word-20-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 960 max words - at ./dataset/shuffle-word-960-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1005 max words - at ./dataset/shuffle-word-1005-count.jsonl\n",
      "Generated JSONL file with - 1215 max words, 100 samples - at ./dataset/gen-word-1215-count.jsonl\n",
      "Generated JSONL file with - 1285 max words, 100 samples - at ./dataset/gen-word-1285-count.jsonl\n",
      "Generated a single JSONL file with 1498 samples (100 token repeat) - 155 max words - at ./dataset/shuffle-word-155-count.jsonl\n",
      "Generated a single JSONL file with 954 samples (100 token repeat) - 245 max words - at ./dataset/shuffle-word-245-count.jsonl\n",
      "Generated a single JSONL file with 257 samples (100 token repeat) - 1220 max words - at ./dataset/shuffle-word-1220-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1405 max words - at ./dataset/shuffle-word-1405-count.jsonl\n",
      "Generated a single JSONL file with 599 samples (100 token repeat) - 410 max words - at ./dataset/shuffle-word-410-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 535 max words - at ./dataset/shuffle-word-535-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1465 max words - at ./dataset/shuffle-word-1465-count.jsonl\n",
      "Generated a single JSONL file with 258 samples (100 token repeat) - 1295 max words - at ./dataset/shuffle-word-1295-count.jsonl\n",
      "Generated a single JSONL file with 203 samples (100 token repeat) - 1305 max words - at ./dataset/shuffle-word-1305-count.jsonl\n",
      "Generated a single JSONL file with 1006 samples (100 token repeat) - 220 max words - at ./dataset/shuffle-word-220-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1010 max words - at ./dataset/shuffle-word-1010-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 980 max words - at ./dataset/shuffle-word-980-count.jsonl\n",
      "Generated a single JSONL file with 297 samples (100 token repeat) - 1135 max words - at ./dataset/shuffle-word-1135-count.jsonl\n",
      "Generated a single JSONL file with 1083 samples (100 token repeat) - 205 max words - at ./dataset/shuffle-word-205-count.jsonl\n",
      "Generated a single JSONL file with 8728 samples (100 token repeat) - 30 max words - at ./dataset/shuffle-word-30-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 990 max words - at ./dataset/shuffle-word-990-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1040 max words - at ./dataset/shuffle-word-1040-count.jsonl\n",
      "Generated a single JSONL file with 6585 samples (100 token repeat) - 40 max words - at ./dataset/shuffle-word-40-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1500 max words - at ./dataset/shuffle-word-1500-count.jsonl\n",
      "Generated JSONL file with - 1305 max words, 100 samples - at ./dataset/gen-word-1305-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 590 max words - at ./dataset/shuffle-word-590-count.jsonl\n",
      "Generated a single JSONL file with 700 samples (100 token repeat) - 375 max words - at ./dataset/shuffle-word-375-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1410 max words - at ./dataset/shuffle-word-1410-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1460 max words - at ./dataset/shuffle-word-1460-count.jsonl\n",
      "Generated JSONL file with - 1265 max words, 100 samples - at ./dataset/gen-word-1265-count.jsonl\n",
      "Generated a single JSONL file with 253 samples (100 token repeat) - 1215 max words - at ./dataset/shuffle-word-1215-count.jsonl\n",
      "Generated a single JSONL file with 298 samples (100 token repeat) - 1145 max words - at ./dataset/shuffle-word-1145-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1075 max words - at ./dataset/shuffle-word-1075-count.jsonl\n",
      "Generated JSONL file with - 1255 max words, 100 samples - at ./dataset/gen-word-1255-count.jsonl\n",
      "Generated a single JSONL file with 405 samples (100 token repeat) - 605 max words - at ./dataset/shuffle-word-605-count.jsonl\n",
      "Generated a single JSONL file with 595 samples (100 token repeat) - 430 max words - at ./dataset/shuffle-word-430-count.jsonl\n",
      "Generated a single JSONL file with 584 samples (100 token repeat) - 445 max words - at ./dataset/shuffle-word-445-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1050 max words - at ./dataset/shuffle-word-1050-count.jsonl\n",
      "Generated JSONL file with - 1300 max words, 100 samples - at ./dataset/gen-word-1300-count.jsonl\n",
      "Generated a single JSONL file with 204 samples (100 token repeat) - 1385 max words - at ./dataset/shuffle-word-1385-count.jsonl\n",
      "Generated a single JSONL file with 296 samples (100 token repeat) - 1160 max words - at ./dataset/shuffle-word-1160-count.jsonl\n",
      "Generated a single JSONL file with 201 samples (100 token repeat) - 1390 max words - at ./dataset/shuffle-word-1390-count.jsonl\n",
      "Generated JSONL file with - 1440 max words, 100 samples - at ./dataset/gen-word-1440-count.jsonl\n",
      "Generated a single JSONL file with 204 samples (100 token repeat) - 1320 max words - at ./dataset/shuffle-word-1320-count.jsonl\n",
      "Generated a single JSONL file with 299 samples (100 token repeat) - 1165 max words - at ./dataset/shuffle-word-1165-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1070 max words - at ./dataset/shuffle-word-1070-count.jsonl\n",
      "Generated a single JSONL file with 500 samples (100 token repeat) - 510 max words - at ./dataset/shuffle-word-510-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1440 max words - at ./dataset/shuffle-word-1440-count.jsonl\n",
      "Generated a single JSONL file with 1439 samples (100 token repeat) - 165 max words - at ./dataset/shuffle-word-165-count.jsonl\n",
      "Generated a single JSONL file with 931 samples (100 token repeat) - 255 max words - at ./dataset/shuffle-word-255-count.jsonl\n",
      "Generated a single JSONL file with 400 samples (100 token repeat) - 635 max words - at ./dataset/shuffle-word-635-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1495 max words - at ./dataset/shuffle-word-1495-count.jsonl\n",
      "Generated JSONL file with - 1395 max words, 100 samples - at ./dataset/gen-word-1395-count.jsonl\n",
      "Generated a single JSONL file with 586 samples (100 token repeat) - 475 max words - at ./dataset/shuffle-word-475-count.jsonl\n",
      "Generated a single JSONL file with 498 samples (100 token repeat) - 520 max words - at ./dataset/shuffle-word-520-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1140 max words - at ./dataset/shuffle-word-1140-count.jsonl\n",
      "Generated a single JSONL file with 1622 samples (100 token repeat) - 140 max words - at ./dataset/shuffle-word-140-count.jsonl\n",
      "Generated a single JSONL file with 204 samples (100 token repeat) - 1400 max words - at ./dataset/shuffle-word-1400-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1045 max words - at ./dataset/shuffle-word-1045-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1420 max words - at ./dataset/shuffle-word-1420-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1425 max words - at ./dataset/shuffle-word-1425-count.jsonl\n",
      "Generated a single JSONL file with 299 samples (100 token repeat) - 1150 max words - at ./dataset/shuffle-word-1150-count.jsonl\n",
      "Generated a single JSONL file with 254 samples (100 token repeat) - 1270 max words - at ./dataset/shuffle-word-1270-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1030 max words - at ./dataset/shuffle-word-1030-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1100 max words - at ./dataset/shuffle-word-1100-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1085 max words - at ./dataset/shuffle-word-1085-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1020 max words - at ./dataset/shuffle-word-1020-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 995 max words - at ./dataset/shuffle-word-995-count.jsonl\n",
      "Generated a single JSONL file with 704 samples (100 token repeat) - 360 max words - at ./dataset/shuffle-word-360-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 530 max words - at ./dataset/shuffle-word-530-count.jsonl\n",
      "Generated a single JSONL file with 592 samples (100 token repeat) - 485 max words - at ./dataset/shuffle-word-485-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 975 max words - at ./dataset/shuffle-word-975-count.jsonl\n",
      "Generated a single JSONL file with 201 samples (100 token repeat) - 1325 max words - at ./dataset/shuffle-word-1325-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 965 max words - at ./dataset/shuffle-word-965-count.jsonl\n",
      "Generated a single JSONL file with 588 samples (100 token repeat) - 495 max words - at ./dataset/shuffle-word-495-count.jsonl\n",
      "Generated a single JSONL file with 205 samples (100 token repeat) - 1310 max words - at ./dataset/shuffle-word-1310-count.jsonl\n",
      "Generated a single JSONL file with 257 samples (100 token repeat) - 1250 max words - at ./dataset/shuffle-word-1250-count.jsonl\n",
      "Generated a single JSONL file with 297 samples (100 token repeat) - 1130 max words - at ./dataset/shuffle-word-1130-count.jsonl\n",
      "Generated a single JSONL file with 296 samples (100 token repeat) - 1170 max words - at ./dataset/shuffle-word-1170-count.jsonl\n",
      "Generated a single JSONL file with 703 samples (100 token repeat) - 380 max words - at ./dataset/shuffle-word-380-count.jsonl\n",
      "Generated a single JSONL file with 403 samples (100 token repeat) - 625 max words - at ./dataset/shuffle-word-625-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1095 max words - at ./dataset/shuffle-word-1095-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1445 max words - at ./dataset/shuffle-word-1445-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1485 max words - at ./dataset/shuffle-word-1485-count.jsonl\n",
      "Generated a single JSONL file with 297 samples (100 token repeat) - 1105 max words - at ./dataset/shuffle-word-1105-count.jsonl\n",
      "Generated a single JSONL file with 246 samples (100 token repeat) - 1205 max words - at ./dataset/shuffle-word-1205-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1080 max words - at ./dataset/shuffle-word-1080-count.jsonl\n",
      "Generated a single JSONL file with 10630 samples (100 token repeat) - 25 max words - at ./dataset/shuffle-word-25-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1000 max words - at ./dataset/shuffle-word-1000-count.jsonl\n",
      "Generated a single JSONL file with 250 samples (100 token repeat) - 1285 max words - at ./dataset/shuffle-word-1285-count.jsonl\n",
      "Generated a single JSONL file with 203 samples (100 token repeat) - 1395 max words - at ./dataset/shuffle-word-1395-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1415 max words - at ./dataset/shuffle-word-1415-count.jsonl\n",
      "Generated a single JSONL file with 26127 samples (100 token repeat) - 10 max words - at ./dataset/shuffle-word-10-count.jsonl\n",
      "Generated a single JSONL file with 55948 samples (100 token repeat) - 5 max words - at ./dataset/shuffle-word-5-count.jsonl\n",
      "## Done ##\n",
      "total 1011M\n",
      "drwxrwxr-x 2 recursal recursal   84K Jan 22 20:29 .\n",
      "drwxrwxr-x 5 recursal recursal  4.0K Jan 22 18:29 ..\n",
      "-rw-rw-r-- 1 recursal recursal  973K Jan 22 20:29 gen-word-1000-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  994K Jan 22 20:29 gen-word-1005-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  526K Jan 22 20:29 gen-word-100-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  999K Jan 22 20:29 gen-word-1010-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  994K Jan 22 20:29 gen-word-1015-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal 1004K Jan 22 20:29 gen-word-1020-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  998K Jan 22 20:29 gen-word-1025-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal 1016K Jan 22 20:29 gen-word-1030-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal 1017K Jan 22 20:29 gen-word-1035-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal 1018K Jan 22 20:29 gen-word-1040-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal 1021K Jan 22 20:29 gen-word-1045-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1050-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1055-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  143K Jan 22 20:29 gen-word-105-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1060-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1065-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1070-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1075-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1080-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1085-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1090-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1095-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal   99K Jan 22 20:29 gen-word-10-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1100-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1105-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  143K Jan 22 20:29 gen-word-110-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1110-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1115-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1120-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1125-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1130-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1135-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1140-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1145-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1150-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1155-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  152K Jan 22 20:29 gen-word-115-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 20:29 gen-word-1160-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1165-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1170-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1175-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1180-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1185-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1190-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1195-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1200-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1205-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  159K Jan 22 20:29 gen-word-120-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1210-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1215-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1220-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1225-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1230-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1235-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1240-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1245-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1250-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1255-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  166K Jan 22 20:29 gen-word-125-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 20:29 gen-word-1260-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1265-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1270-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1275-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1280-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1285-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1290-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1295-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1300-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1305-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  168K Jan 22 20:29 gen-word-130-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1310-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1315-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1320-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1325-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1330-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1335-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1340-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1345-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1350-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1355-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  173K Jan 22 20:29 gen-word-135-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1360-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1365-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 20:29 gen-word-1370-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1375-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1380-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1385-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1390-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1395-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1400-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1405-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  178K Jan 22 20:29 gen-word-140-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1410-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1415-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1420-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1425-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1430-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1435-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1440-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1445-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1450-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 20:29 gen-word-1455-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  189K Jan 22 20:29 gen-word-145-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1460-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 20:29 gen-word-1465-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 20:29 gen-word-1470-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 20:29 gen-word-1475-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 20:29 gen-word-1480-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 20:29 gen-word-1485-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 20:29 gen-word-1490-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 20:29 gen-word-1495-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 20:29 gen-word-1500-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  192K Jan 22 20:29 gen-word-150-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  201K Jan 22 20:29 gen-word-155-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  122K Jan 22 20:29 gen-word-15-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  205K Jan 22 20:29 gen-word-160-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  216K Jan 22 20:29 gen-word-165-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  216K Jan 22 20:29 gen-word-170-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  225K Jan 22 20:29 gen-word-175-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  229K Jan 22 20:29 gen-word-180-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  234K Jan 22 20:29 gen-word-185-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  251K Jan 22 20:29 gen-word-190-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  251K Jan 22 20:29 gen-word-195-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  252K Jan 22 20:29 gen-word-200-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  207K Jan 22 20:29 gen-word-205-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  149K Jan 22 20:29 gen-word-20-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  215K Jan 22 20:29 gen-word-210-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  218K Jan 22 20:29 gen-word-215-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  222K Jan 22 20:29 gen-word-220-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  229K Jan 22 20:29 gen-word-225-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  236K Jan 22 20:29 gen-word-230-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  242K Jan 22 20:29 gen-word-235-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  251K Jan 22 20:29 gen-word-240-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  246K Jan 22 20:29 gen-word-245-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  256K Jan 22 20:29 gen-word-250-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  262K Jan 22 20:29 gen-word-255-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  171K Jan 22 20:29 gen-word-25-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  262K Jan 22 20:29 gen-word-260-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  267K Jan 22 20:29 gen-word-265-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  277K Jan 22 20:29 gen-word-270-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  276K Jan 22 20:29 gen-word-275-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  275K Jan 22 20:29 gen-word-280-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  289K Jan 22 20:29 gen-word-285-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  290K Jan 22 20:29 gen-word-290-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  296K Jan 22 20:29 gen-word-295-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  307K Jan 22 20:29 gen-word-300-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  307K Jan 22 20:29 gen-word-305-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  196K Jan 22 20:29 gen-word-30-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  307K Jan 22 20:29 gen-word-310-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  322K Jan 22 20:29 gen-word-315-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  318K Jan 22 20:29 gen-word-320-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  332K Jan 22 20:29 gen-word-325-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  328K Jan 22 20:29 gen-word-330-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  334K Jan 22 20:29 gen-word-335-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  344K Jan 22 20:29 gen-word-340-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  349K Jan 22 20:29 gen-word-345-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  356K Jan 22 20:29 gen-word-350-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  354K Jan 22 20:29 gen-word-355-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  219K Jan 22 20:29 gen-word-35-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  351K Jan 22 20:29 gen-word-360-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  364K Jan 22 20:29 gen-word-365-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  372K Jan 22 20:29 gen-word-370-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  375K Jan 22 20:29 gen-word-375-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  387K Jan 22 20:29 gen-word-380-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  386K Jan 22 20:29 gen-word-385-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  386K Jan 22 20:29 gen-word-390-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  399K Jan 22 20:29 gen-word-395-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  395K Jan 22 20:29 gen-word-400-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  404K Jan 22 20:29 gen-word-405-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  241K Jan 22 20:29 gen-word-40-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  408K Jan 22 20:29 gen-word-410-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  411K Jan 22 20:29 gen-word-415-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  420K Jan 22 20:29 gen-word-420-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  426K Jan 22 20:29 gen-word-425-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  429K Jan 22 20:29 gen-word-430-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  431K Jan 22 20:29 gen-word-435-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  433K Jan 22 20:29 gen-word-440-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  440K Jan 22 20:29 gen-word-445-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  449K Jan 22 20:29 gen-word-450-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  457K Jan 22 20:29 gen-word-455-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  267K Jan 22 20:29 gen-word-45-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  464K Jan 22 20:29 gen-word-460-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  456K Jan 22 20:29 gen-word-465-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  470K Jan 22 20:29 gen-word-470-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  466K Jan 22 20:29 gen-word-475-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  480K Jan 22 20:29 gen-word-480-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  477K Jan 22 20:29 gen-word-485-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  486K Jan 22 20:29 gen-word-490-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  483K Jan 22 20:29 gen-word-495-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  499K Jan 22 20:29 gen-word-500-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  494K Jan 22 20:29 gen-word-505-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  295K Jan 22 20:29 gen-word-50-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  506K Jan 22 20:29 gen-word-510-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  499K Jan 22 20:29 gen-word-515-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  515K Jan 22 20:29 gen-word-520-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  522K Jan 22 20:29 gen-word-525-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  526K Jan 22 20:29 gen-word-530-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  532K Jan 22 20:29 gen-word-535-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  535K Jan 22 20:29 gen-word-540-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  539K Jan 22 20:29 gen-word-545-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  546K Jan 22 20:29 gen-word-550-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  555K Jan 22 20:29 gen-word-555-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  315K Jan 22 20:29 gen-word-55-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  557K Jan 22 20:29 gen-word-560-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  558K Jan 22 20:29 gen-word-565-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  566K Jan 22 20:29 gen-word-570-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  567K Jan 22 20:29 gen-word-575-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  569K Jan 22 20:29 gen-word-580-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  586K Jan 22 20:29 gen-word-585-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  583K Jan 22 20:29 gen-word-590-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  594K Jan 22 20:29 gen-word-595-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal   72K Jan 22 20:29 gen-word-5-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  585K Jan 22 20:29 gen-word-600-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  608K Jan 22 20:29 gen-word-605-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  346K Jan 22 20:29 gen-word-60-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  596K Jan 22 20:29 gen-word-610-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  612K Jan 22 20:29 gen-word-615-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  610K Jan 22 20:29 gen-word-620-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  623K Jan 22 20:29 gen-word-625-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  628K Jan 22 20:29 gen-word-630-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  631K Jan 22 20:29 gen-word-635-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  636K Jan 22 20:29 gen-word-640-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  633K Jan 22 20:29 gen-word-645-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  644K Jan 22 20:29 gen-word-650-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  639K Jan 22 20:29 gen-word-655-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  369K Jan 22 20:29 gen-word-65-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  651K Jan 22 20:29 gen-word-660-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  656K Jan 22 20:29 gen-word-665-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  656K Jan 22 20:29 gen-word-670-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  674K Jan 22 20:29 gen-word-675-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  681K Jan 22 20:29 gen-word-680-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  680K Jan 22 20:29 gen-word-685-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  678K Jan 22 20:29 gen-word-690-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  686K Jan 22 20:29 gen-word-695-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  697K Jan 22 20:29 gen-word-700-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  705K Jan 22 20:29 gen-word-705-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  393K Jan 22 20:29 gen-word-70-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  697K Jan 22 20:29 gen-word-710-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  709K Jan 22 20:29 gen-word-715-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  717K Jan 22 20:29 gen-word-720-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  707K Jan 22 20:29 gen-word-725-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  720K Jan 22 20:29 gen-word-730-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  734K Jan 22 20:29 gen-word-735-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  727K Jan 22 20:29 gen-word-740-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  735K Jan 22 20:29 gen-word-745-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  737K Jan 22 20:29 gen-word-750-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  748K Jan 22 20:29 gen-word-755-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  411K Jan 22 20:29 gen-word-75-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  747K Jan 22 20:29 gen-word-760-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  745K Jan 22 20:29 gen-word-765-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  752K Jan 22 20:29 gen-word-770-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  754K Jan 22 20:29 gen-word-775-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  771K Jan 22 20:29 gen-word-780-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  765K Jan 22 20:29 gen-word-785-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  776K Jan 22 20:29 gen-word-790-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  782K Jan 22 20:29 gen-word-795-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  792K Jan 22 20:29 gen-word-800-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  796K Jan 22 20:29 gen-word-805-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  441K Jan 22 20:29 gen-word-80-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  801K Jan 22 20:29 gen-word-810-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  805K Jan 22 20:29 gen-word-815-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  820K Jan 22 20:29 gen-word-820-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  814K Jan 22 20:29 gen-word-825-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  811K Jan 22 20:29 gen-word-830-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  820K Jan 22 20:29 gen-word-835-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  826K Jan 22 20:29 gen-word-840-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  838K Jan 22 20:29 gen-word-845-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  836K Jan 22 20:29 gen-word-850-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  840K Jan 22 20:29 gen-word-855-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  462K Jan 22 20:29 gen-word-85-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  855K Jan 22 20:29 gen-word-860-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  858K Jan 22 20:29 gen-word-865-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  854K Jan 22 20:29 gen-word-870-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  864K Jan 22 20:29 gen-word-875-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  867K Jan 22 20:29 gen-word-880-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  865K Jan 22 20:29 gen-word-885-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  866K Jan 22 20:29 gen-word-890-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  877K Jan 22 20:29 gen-word-895-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  883K Jan 22 20:29 gen-word-900-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  896K Jan 22 20:29 gen-word-905-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  489K Jan 22 20:29 gen-word-90-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  892K Jan 22 20:29 gen-word-910-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  897K Jan 22 20:29 gen-word-915-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  907K Jan 22 20:29 gen-word-920-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  907K Jan 22 20:29 gen-word-925-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  912K Jan 22 20:29 gen-word-930-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  927K Jan 22 20:29 gen-word-935-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  936K Jan 22 20:29 gen-word-940-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  923K Jan 22 20:29 gen-word-945-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  944K Jan 22 20:29 gen-word-950-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  933K Jan 22 20:29 gen-word-955-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  509K Jan 22 20:29 gen-word-95-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  944K Jan 22 20:29 gen-word-960-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  947K Jan 22 20:29 gen-word-965-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  955K Jan 22 20:29 gen-word-970-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  964K Jan 22 20:29 gen-word-975-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  967K Jan 22 20:29 gen-word-980-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  966K Jan 22 20:29 gen-word-985-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  966K Jan 22 20:29 gen-word-990-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  974K Jan 22 20:29 gen-word-995-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1000-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1005-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 20:29 shuffle-word-100-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1010-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1015-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1020-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1025-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1030-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1035-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1040-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1045-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1050-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1055-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 20:29 shuffle-word-105-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1060-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1065-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1070-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1075-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1080-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1085-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1090-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1095-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  5.1M Jan 22 20:29 shuffle-word-10-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1100-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1105-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 20:29 shuffle-word-110-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1110-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1115-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1120-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1125-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1130-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1135-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1140-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1145-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1150-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1155-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-115-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1160-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1165-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1170-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1175-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1180-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1185-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1190-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1195-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1200-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1205-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-120-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1210-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1215-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1220-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1225-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1230-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1235-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1240-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1245-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1250-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1255-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-125-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1260-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1265-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1270-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1275-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1280-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1285-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1290-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1295-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1300-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1305-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-130-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1310-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1315-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1320-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1325-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1330-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1335-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1340-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1345-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1350-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1355-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-135-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1360-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1365-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1370-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1375-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1380-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1385-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1390-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1395-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1400-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1405-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-140-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1410-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1415-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1420-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1425-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1430-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1435-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1440-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1445-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1450-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1455-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-145-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1460-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1465-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1470-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1475-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1480-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1485-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1490-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1495-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-1500-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-150-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-155-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  4.2M Jan 22 20:29 shuffle-word-15-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-160-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-165-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-170-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-175-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-180-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-185-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-190-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-195-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-200-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-205-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 20:29 shuffle-word-20-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-210-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-215-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-220-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-225-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-230-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-235-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-240-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-245-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-250-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-255-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 20:29 shuffle-word-25-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-260-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-265-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-270-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-275-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-280-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-285-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-290-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-295-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 20:29 shuffle-word-300-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-305-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 20:29 shuffle-word-30-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-310-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-315-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-320-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-325-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-330-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-335-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-340-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-345-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-350-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-355-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 20:29 shuffle-word-35-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-360-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-365-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-370-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-375-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-380-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-385-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-390-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-395-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-400-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-405-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 20:29 shuffle-word-40-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-410-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-415-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-420-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-425-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-430-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-435-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-440-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-445-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-450-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-455-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 20:29 shuffle-word-45-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-460-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-465-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-470-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-475-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-480-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-485-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-490-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-495-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-500-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-505-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 20:29 shuffle-word-50-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-510-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-515-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-520-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-525-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-530-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-535-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-540-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-545-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-550-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-555-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 20:29 shuffle-word-55-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-560-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-565-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-570-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-575-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-580-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-585-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-590-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-595-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  8.0M Jan 22 20:29 shuffle-word-5-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-600-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-605-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 20:29 shuffle-word-60-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-610-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-615-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-620-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-625-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-630-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-635-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-640-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-645-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-650-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-655-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 20:29 shuffle-word-65-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-660-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-665-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-670-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-675-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-680-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-685-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-690-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-695-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-700-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-705-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 20:29 shuffle-word-70-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-710-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-715-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-720-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-725-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-730-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-735-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-740-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-745-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-750-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-755-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 20:29 shuffle-word-75-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-760-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-765-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-770-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-775-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-780-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-785-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-790-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-795-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-800-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-805-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 20:29 shuffle-word-80-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-810-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-815-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-820-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-825-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-830-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-835-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-840-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-845-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-850-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-855-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 20:29 shuffle-word-85-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-860-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-865-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-870-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-875-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-880-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-885-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-890-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-895-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-900-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-905-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 20:29 shuffle-word-90-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-910-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-915-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-920-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-925-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-930-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-935-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-940-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-945-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-950-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-955-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 20:29 shuffle-word-95-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-960-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-965-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-970-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-975-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-980-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-985-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-990-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 20:29 shuffle-word-995-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  141K Jan 22 20:29 word-2-count.jsonl\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "########################################\n",
    "# Generate the required jsonl dataset\n",
    "########################################\n",
    "\n",
    "# Reset the dataset dir\n",
    "mkdir -p ./dataset\n",
    "rm -rf ./dataset/*.jsonl\n",
    "\n",
    "# Generate the various datasets\n",
    "echo \"## Generating word reptition dataset ##\"\n",
    "\n",
    "#\n",
    "# Training set for < 50 words\n",
    "# This is used to fill up as much blanks as possible\n",
    "#\n",
    "python ./memory_script/gen_limited_prompt_completion_jsonl.py ./dataset/word-2-count.jsonl 2 300 &\n",
    "python ./memory_script/gen_limited_prompt_completion_jsonl.py ./dataset/word-2-count.jsonl 4 1000 &\n",
    "for i in {5..100..5} \n",
    "do\n",
    "    python ./memory_script/gen_limited_prompt_completion_jsonl.py ./dataset/gen-word-$i-count.jsonl $i 500 & \n",
    "    python ./memory_script/shuffle_limited_prompt_completion_jsonl.py ./dataset/shuffle-word-$i-count.jsonl $i 100 & \n",
    "done\n",
    "\n",
    "#\n",
    "# Ramping up the 50+ - 400 words dataset\n",
    "# \n",
    "for i in {105..200..5} \n",
    "do\n",
    "    python ./memory_script/gen_limited_prompt_completion_jsonl.py ./dataset/gen-word-$i-count.jsonl $i 125 & \n",
    "    python ./memory_script/shuffle_limited_prompt_completion_jsonl.py ./dataset/shuffle-word-$i-count.jsonl $i 100 & \n",
    "done\n",
    "\n",
    "#\n",
    "# Ramping up the 50+ - 400 words dataset\n",
    "# \n",
    "for i in {205..1500..5} \n",
    "do\n",
    "    python ./memory_script/gen_limited_prompt_completion_jsonl.py ./dataset/gen-word-$i-count.jsonl $i 100 & \n",
    "    python ./memory_script/shuffle_limited_prompt_completion_jsonl.py ./dataset/shuffle-word-$i-count.jsonl $i 100 & \n",
    "done\n",
    "\n",
    "wait\n",
    "echo \"## Done ##\"\n",
    "\n",
    "ls -alh ./dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|███████████████| 601/601 [00:00<00:00, 370647.95it/s]\n",
      "Filter (num_proc=160): 100%|██| 372801/372801 [00:03<00:00, 93704.48 examples/s]\n",
      "Map (num_proc=160): 100%|████| 363015/363015 [00:02<00:00, 127526.30 examples/s]\n",
      "Map (num_proc=160): 100%|█████| 363015/363015 [00:07<00:00, 46066.68 examples/s]\n",
      "Map (num_proc=160): 100%|███████| 87900/87900 [00:03<00:00, 27106.01 examples/s]\n",
      "Saving the dataset (2/2 shards): 100%|█| 87900/87900 [00:01<00:00, 82134.79 exam\n",
      "Saving the dataset (1/1 shards): 100%|█| 364/364 [00:00<00:00, 13312.35 examples\n"
     ]
    }
   ],
   "source": [
    "# Lets pre tokenize the requried dataset\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 preload_datapath.py \"{NOTEBOOK_DIR}/stage-1-tune.yaml\"\n",
    "\n",
    "# Ensure the checkpoint directory exists\n",
    "!cd \"{TRAINER_DIR}\" && mkdir -p \"../checkpoint/stage-1-memory-finetune/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune 1 : The actual tune!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-22 20:30:14,781] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py:518: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['fit', '-c', '/home/recursal/RWKV-infctx-trainer/notebook/rwkv-x-exp/v5-exp/memory-test/stage-1-tune.yaml', '--model.load_model=../model/RWKV-v5-1B5-world.pth', '--trainer.callbacks.init_args.dirpath=../checkpoint/stage-1-memory-finetune/RWKV-v5-1B5-world.pth/', '--trainer.logger.init_args.name=[8x4090] RWKV-v5-1B5-World - Mem-Finetune-1 (bs=256, train-ctx=2048, deepspeed_stage_1)', '--trainer.strategy=deepspeed_stage_1', '--trainer.devices=auto', '--trainer.microbatch_size=8', '--model.ctx_len=2048'], args=['fit', '-c', '/home/recursal/RWKV-infctx-trainer/notebook/rwkv-x-exp/v5-exp/memory-test/stage-1-tune.yaml', '--model.load_model=../model/RWKV-v5-1B5-world.pth', '--trainer.callbacks.init_args.dirpath=../checkpoint/stage-1-memory-finetune/RWKV-v5-1B5-world.pth/', '--trainer.logger.init_args.name=[8x4090] RWKV-v5-1B5-World - Mem-Finetune-1 (bs=256, train-ctx=2048, deepspeed_stage_1)', '--trainer.strategy=deepspeed_stage_1', '--trainer.devices=auto', '--trainer.microbatch_size=8', '--model.ctx_len=2048'].\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/fabric/utilities/seed.py:40: No seed found, seed set to 2435230032\n",
      "Seed set to 2435230032\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/wkv5/build.ninja...\n",
      "Building extension module wkv5...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/fabric/connector.py:558: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "\n",
      "[RWKV.Trainer] Applying 'target_batch_size' with the following:\n",
      "   - target_batch_size:       256\n",
      "   - num_nodes:               1\n",
      "   - num_devices:             8\n",
      "   - microbatch_size:         8\n",
      "   - accumulate_grad_batches: 4\n",
      "   - effective_batch_size:    256\n",
      "\n",
      "[rank: 0] Seed set to 2435230032\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "[2024-01-22 20:30:34,516] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-22 20:30:34,555] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-22 20:30:34,573] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-22 20:30:34,643] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-22 20:30:34,665] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-22 20:30:34,667] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-22 20:30:34,779] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[rank: 6] Seed set to 2435230032\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 3] Seed set to 2435230032\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 4] Seed set to 2435230032\n",
      "[rank: 7] Seed set to 2435230032\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 5] Seed set to 2435230032\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 2] Seed set to 2435230032\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 1] Seed set to 2435230032\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/wkv5/build.ninja...\n",
      "Building extension module wkv5...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/wkv5/build.ninja...\n",
      "Building extension module wkv5...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "ninja: no work to do.\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/wkv5/build.ninja...\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Building extension module wkv5...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/wkv5/build.ninja...\n",
      "Building extension module wkv5...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "[rank: 1] Seed set to 2435230032\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "[rank: 2] Seed set to 2435230032\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "[rank: 3] Seed set to 2435230032\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "[rank: 6] Seed set to 2435230032\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "[rank: 5] Seed set to 2435230032\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "[rank: 7] Seed set to 2435230032\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "[rank: 4] Seed set to 2435230032\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "Enabling DeepSpeed BF16. Model parameters and inputs will be cast to `bfloat16`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicocreator\u001b[0m (\u001b[33mrwkv-x-dev\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20240122_203109-hhwmn520\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m[8x4090] RWKV-v5-1B5-World - Mem-Finetune-1 (bs=256, train-ctx=2048, deepspeed_stage_1)\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-Memory-Experiment\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-Memory-Experiment/runs/hhwmn520\u001b[0m\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "#\n",
      "# RWKV lighting_trainer.py important notes \n",
      "# https://github.com/RWKV/RWKV-infctx-trainer \n",
      "#\n",
      "# - Ensure your host is not running cuda 12.0 (use either 11.8, or >=12.1), as this is known to have freeze issues\n",
      "# - The terms used in wandb / the progress bar can be confusing, see the github README.md for beter clarifications\n",
      "# - When resuming from checkpoint, the estimated time is inaccurate\n",
      "#LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "\n",
      "[RWKV.model] Configuring optimizer with\n",
      "    - lr_init:  8.000e-04 (0.0008)\n",
      "    - lr_final: 4.000e-04 (0.0004)\n",
      "\n",
      "LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.07379484176635742 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.1038506031036377 seconds\n",
      "Time to load fused_adam op: 0.10417509078979492 seconds\n",
      "Time to load fused_adam op: 0.10447382926940918 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Time to load fused_adam op: 0.10385513305664062 seconds\n",
      "Time to load fused_adam op: 0.10325026512145996 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Time to load fused_adam op: 0.10282731056213379 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10386180877685547 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | emb    | Embedding  | 134 M \n",
      "1 | blocks | ModuleList | 1.3 B \n",
      "2 | ln_out | LayerNorm  | 4.1 K \n",
      "3 | head   | Linear     | 134 M \n",
      "--------------------------------------\n",
      "1.6 B     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 B     Total params\n",
      "6,311.018 Total estimated model params size (MB)\n",
      "Epoch 0:   7%| | 100/1374 [04:50<1:01:41,  0.34it/s, v_num=n520, train/loss=0.05/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Epoch 0: 100%|█| 1374/1374 [1:01:19<00:00,  0.37it/s, v_num=n520, train/loss=0.1\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/46 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/46 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▍                  | 1/46 [00:00<00:12,  3.62it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▊                  | 2/46 [00:00<00:08,  5.12it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█▏                 | 3/46 [00:00<00:07,  5.67it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▋                 | 4/46 [00:00<00:06,  6.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|██                 | 5/46 [00:00<00:06,  6.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▍                | 6/46 [00:00<00:05,  7.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▉                | 7/46 [00:00<00:05,  7.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|███▎               | 8/46 [00:01<00:04,  7.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▋               | 9/46 [00:01<00:04,  7.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▉              | 10/46 [00:01<00:04,  8.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████▎             | 11/46 [00:01<00:04,  8.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▋             | 12/46 [00:01<00:04,  8.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|█████             | 13/46 [00:01<00:03,  8.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▍            | 14/46 [00:01<00:03,  8.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|█████▊            | 15/46 [00:01<00:03,  8.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▎           | 16/46 [00:01<00:03,  8.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|██████▋           | 17/46 [00:01<00:03,  8.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|███████           | 18/46 [00:02<00:03,  8.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|███████▍          | 19/46 [00:02<00:03,  8.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▊          | 20/46 [00:02<00:02,  8.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|████████▏         | 21/46 [00:02<00:02,  8.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████▌         | 22/46 [00:02<00:02,  8.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 23/46 [00:02<00:02,  8.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|█████████▍        | 24/46 [00:02<00:02,  8.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|█████████▊        | 25/46 [00:02<00:02,  8.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|██████████▏       | 26/46 [00:02<00:02,  9.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|██████████▌       | 27/46 [00:02<00:02,  9.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|██████████▉       | 28/46 [00:03<00:01,  9.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|███████████▎      | 29/46 [00:03<00:01,  9.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 30/46 [00:03<00:01,  9.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████████▏     | 31/46 [00:03<00:01,  9.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 32/46 [00:03<00:01,  9.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|████████████▉     | 33/46 [00:03<00:01,  8.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████████▎    | 34/46 [00:03<00:01,  8.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████████▋    | 35/46 [00:03<00:01,  8.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████████    | 36/46 [00:04<00:01,  8.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 37/46 [00:04<00:01,  8.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████████▊   | 38/46 [00:04<00:00,  8.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 39/46 [00:04<00:00,  8.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████████▋  | 40/46 [00:04<00:00,  9.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|████████████████  | 41/46 [00:04<00:00,  9.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|████████████████▍ | 42/46 [00:04<00:00,  9.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████████▊ | 43/46 [00:04<00:00,  8.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|█████████████████▏| 44/46 [00:04<00:00,  8.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|█████████████████▌| 45/46 [00:05<00:00,  8.94it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 46/46 [00:05<00:00,  8.96it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 1374/1374 [1:01:25<00:00,  0.37it/s, v_num=n520, train/loss=0.1`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Epoch 0: 100%|█| 1374/1374 [1:01:25<00:00,  0.37it/s, v_num=n520, train/loss=0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.032 MB of 0.032 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   batchidx ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                global_rank ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: perf/kTokens_per_sec.gpu.0 █▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    substep ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/ctx_len ███▇▇▇█▇▅▆▇▃▄▅▆▇▇█▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/data_loss ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▇▇▇▆▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▅▅▅▅▃▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/tokens ▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▇████▆▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      trainer/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            validation/loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   batchidx 1373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                global_rank 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: perf/kTokens_per_sec.gpu.0 4.92636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    substep 10984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/ctx_len 1024.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/data_loss 0.1709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/loss 0.16992\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/tokens 136.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        trainer/global_step 343\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      trainer/learning_rate 0.00075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            validation/loss 0.50709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33m[8x4090] RWKV-v5-1B5-World - Mem-Finetune-1 (bs=256, train-ctx=2048, deepspeed_stage_1)\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-Memory-Experiment/runs/hhwmn520\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ️⚡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-Memory-Experiment/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMjQ3NDY3MA==/version_details/v3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240122_203109-hhwmn520/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Start the finetune model training\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    python3 lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/stage-1-tune.yaml\" \\\n",
    "        --model.load_model=\"../model/{MODEL_NAME}\" \\\n",
    "        --trainer.callbacks.init_args.dirpath=\"../checkpoint/stage-1-memory-finetune/{MODEL_NAME}/\" \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX} - Mem-Finetune-1 (bs=256, train-ctx=2048, {DEEPSPEED_STRAT})\" \\\n",
    "        --trainer.strategy=\"{DEEPSPEED_STRAT}\" \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\"  \\\n",
    "        --trainer.microbatch_size=8 \\\n",
    "        --model.ctx_len=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-22 21:33:02,316] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Processing zero checkpoint '../checkpoint/stage-1-memory-finetune/RWKV-v5-1B5-world.pth/last.ckpt/checkpoint'\n",
      "Detected checkpoint of type zero stage ZeroStageEnum.optimizer_states, world_size: 8\n",
      "Parsing checkpoint created by deepspeed==0.12.6\n",
      "Reconstructed fp32 state dict with 534 params 1577754624 elements\n",
      "Saving bf16 state dict to ../model/Memory-Tune-Stage-1-RWKV-v5-1B5-world.pth\n",
      "-rw-rw-r-- 1 recursal recursal 3.0G Jan 22 21:33 ../model/Memory-Tune-Stage-1-RWKV-v5-1B5-world.pth\n"
     ]
    }
   ],
   "source": [
    "# Lets export the model from the checkpoint\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python export_checkpoint.py \\\n",
    "        \"../checkpoint/stage-1-memory-finetune/{MODEL_NAME}/last.ckpt\" \\\n",
    "        \"../model/Memory-Tune-Stage-1-{MODEL_NAME}\"\n",
    "!cd \"{TRAINER_DIR}\" && ls -alh \"../model/Memory-Tune-Stage-1-{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-22 21:33:21,418] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[SimpleRWKV] Warning: dtype mismatch, only fp32 is supported (for now)\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/wkv5/build.ninja...\n",
      "Building extension module wkv5...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "/home/recursal/RWKV-infctx-trainer/RWKV-v5/src/model.py:1390: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_tokens = torch.tensor(\n",
      "--- DRAGON PROMPT ---\n",
      "In a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese. tea even more surprise to thee researchers was thee fact that the speak perfect Chinese tea even more surprise to thee researchers was thee fact that the speak perfect Chinese tea even more surprise to thee researchers was thee fact that the speak perfect Chinese tea even more surprise to thee researchers was thee fact that speak perfect Chinese tea even more surprise to thee settlers was thee fact that speak perfect Chinese tea even more surprise to thee settlers was thee fact that speak perfect Chinese tea even more surprise to thee settlers was thee fact that speak perfect Chinese tea even more surprise to thee settlers was thee fact that speak perfect Chinese tea even more surprise to thee settlers was thee fact that speak perfect Chinese tea even more surprise to thee settlers was thee fact that speak perfect Chinese tea even more surprise to thee settlers was thee fact that speak perfect Chinese tea even more surprise to thee settlers was thee fact that speak perfect Chinese tea even more surprise to thee settlers was thee fact that speak perfect Chinese tea even more surprise to thee settlers was thee fact that speak perfect Chinese tea\n"
     ]
    }
   ],
   "source": [
    "# # Lets do a quick dragon prompt validation\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 dragon_test.py \"../model/Memory-Tune-Stage-1-{MODEL_NAME}\" \"cuda fp32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCRIPT_DIR:  /home/recursal/RWKV-infctx-trainer/notebook/rwkv-x-exp/v5-exp/memory-test/memory_script\n",
      "PROJECT_DIR:  /home/recursal/RWKV-infctx-trainer\n",
      "MODEL_CODE_DIR:  /home/recursal/RWKV-infctx-trainer/RWKV-v5\n",
      "[2024-01-22 22:55:37,758] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/wkv5/build.ninja...\n",
      "Building extension module wkv5...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "/home/recursal/RWKV-infctx-trainer/RWKV-v5/src/model.py:1390: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_tokens = torch.tensor(\n",
      "###\n",
      "### Model validation start ###\n",
      "###\n",
      "## Model validation for 5 tokens : 60.0% similarity, with 3 matched token, and 2 token mismatch\n",
      "## Model validation for 10 tokens : 80.0% similarity, with 8 matched token, and 2 token mismatch\n",
      "## Model validation for 15 tokens : 86.66666666666667% similarity, with 13 matched token, and 2 token mismatch\n",
      "## Model validation for 20 tokens : 90.0% similarity, with 18 matched token, and 2 token mismatch\n",
      "## Model validation for 25 tokens : 92.0% similarity, with 23 matched token, and 2 token mismatch\n",
      "## Model validation for 30 tokens : 93.33333333333333% similarity, with 28 matched token, and 2 token mismatch\n",
      "## Model validation for 35 tokens : 94.28571428571428% similarity, with 33 matched token, and 2 token mismatch\n",
      "## Model validation for 40 tokens : 95.0% similarity, with 38 matched token, and 2 token mismatch\n",
      "## Model validation for 45 tokens : 95.55555555555556% similarity, with 43 matched token, and 2 token mismatch\n",
      "## Model validation for 50 tokens : 96.0% similarity, with 48 matched token, and 2 token mismatch\n",
      "## Model validation for 55 tokens : 96.36363636363636% similarity, with 53 matched token, and 2 token mismatch\n",
      "## Model validation for 60 tokens : 96.66666666666667% similarity, with 58 matched token, and 2 token mismatch\n",
      "## Model validation for 65 tokens : 96.92307692307692% similarity, with 63 matched token, and 2 token mismatch\n",
      "## Model validation for 70 tokens : 97.14285714285714% similarity, with 68 matched token, and 2 token mismatch\n",
      "## Model validation for 75 tokens : 97.33333333333334% similarity, with 73 matched token, and 2 token mismatch\n",
      "## Model validation for 80 tokens : 97.5% similarity, with 78 matched token, and 2 token mismatch\n",
      "## Model validation for 85 tokens : 97.6470588235294% similarity, with 83 matched token, and 2 token mismatch\n",
      "## Model validation for 90 tokens : 97.77777777777777% similarity, with 88 matched token, and 2 token mismatch\n",
      "## Model validation for 95 tokens : 97.89473684210527% similarity, with 93 matched token, and 2 token mismatch\n",
      "## Model validation for 100 tokens : 98.0% similarity, with 98 matched token, and 2 token mismatch\n",
      "## Model validation for 105 tokens : 98.09523809523809% similarity, with 103 matched token, and 2 token mismatch\n",
      "## Model validation for 110 tokens : 98.18181818181819% similarity, with 108 matched token, and 2 token mismatch\n",
      "## Model validation for 115 tokens : 98.26086956521739% similarity, with 113 matched token, and 2 token mismatch\n",
      "## Model validation for 120 tokens : 98.33333333333333% similarity, with 118 matched token, and 2 token mismatch\n",
      "## Model validation for 125 tokens : 98.4% similarity, with 123 matched token, and 2 token mismatch\n",
      "## Model validation for 130 tokens : 98.46153846153847% similarity, with 128 matched token, and 2 token mismatch\n",
      "## Model validation for 135 tokens : 98.51851851851852% similarity, with 133 matched token, and 2 token mismatch\n",
      "## Model validation for 140 tokens : 98.57142857142858% similarity, with 138 matched token, and 2 token mismatch\n",
      "## Model validation for 145 tokens : 98.62068965517241% similarity, with 143 matched token, and 2 token mismatch\n",
      "## Model validation for 150 tokens : 98.66666666666667% similarity, with 148 matched token, and 2 token mismatch\n",
      "## Model validation for 160 tokens : 98.75% similarity, with 158 matched token, and 2 token mismatch\n",
      "## Model validation for 170 tokens : 98.82352941176471% similarity, with 168 matched token, and 2 token mismatch\n",
      "## Model validation for 180 tokens : 98.88888888888889% similarity, with 178 matched token, and 2 token mismatch\n",
      "## Model validation for 190 tokens : 98.94736842105263% similarity, with 188 matched token, and 2 token mismatch\n",
      "## Model validation for 200 tokens : 99.0% similarity, with 198 matched token, and 2 token mismatch\n",
      "## Model validation for 210 tokens : 99.04761904761905% similarity, with 208 matched token, and 2 token mismatch\n",
      "## Model validation for 220 tokens : 98.63636363636363% similarity, with 217 matched token, and 3 token mismatch\n",
      "## Model validation for 230 tokens : 98.69565217391305% similarity, with 227 matched token, and 3 token mismatch\n",
      "## Model validation for 240 tokens : 98.33333333333333% similarity, with 236 matched token, and 4 token mismatch\n",
      "## Model validation for 250 tokens : 98.4% similarity, with 246 matched token, and 4 token mismatch\n",
      "## Model validation for 260 tokens : 98.84615384615385% similarity, with 257 matched token, and 3 token mismatch\n",
      "## Model validation for 270 tokens : 97.4074074074074% similarity, with 263 matched token, and 7 token mismatch\n",
      "## Model validation for 280 tokens : 98.57142857142858% similarity, with 276 matched token, and 4 token mismatch\n",
      "## Model validation for 290 tokens : 97.93103448275862% similarity, with 284 matched token, and 6 token mismatch\n",
      "## Model validation for 300 tokens : 98.33333333333333% similarity, with 295 matched token, and 5 token mismatch\n",
      "## Model validation for 325 tokens : 97.84615384615385% similarity, with 318 matched token, and 7 token mismatch\n",
      "## Model validation for 350 tokens : 97.71428571428571% similarity, with 342 matched token, and 8 token mismatch\n",
      "## Model validation for 375 tokens : 98.4% similarity, with 369 matched token, and 6 token mismatch\n",
      "## Model validation for 400 tokens : 98.0% similarity, with 392 matched token, and 8 token mismatch\n",
      "## Model validation for 425 tokens : 98.11764705882354% similarity, with 417 matched token, and 8 token mismatch\n",
      "## Model validation for 450 tokens : 97.11111111111111% similarity, with 437 matched token, and 13 token mismatch\n",
      "## Model validation for 475 tokens : 97.05263157894737% similarity, with 461 matched token, and 14 token mismatch\n",
      "## Model validation for 500 tokens : 96.8% similarity, with 484 matched token, and 16 token mismatch\n",
      "## Model validation for 525 tokens : 96.19047619047619% similarity, with 505 matched token, and 20 token mismatch\n",
      "## Model validation for 550 tokens : 95.81818181818181% similarity, with 527 matched token, and 23 token mismatch\n",
      "## Model validation for 575 tokens : 96.34782608695652% similarity, with 554 matched token, and 21 token mismatch\n",
      "## Model validation for 600 tokens : 96.0% similarity, with 576 matched token, and 24 token mismatch\n",
      "## Model validation for 625 tokens : 94.88% similarity, with 593 matched token, and 32 token mismatch\n",
      "## Model validation for 650 tokens : 94.3076923076923% similarity, with 613 matched token, and 37 token mismatch\n",
      "## Model validation for 675 tokens : 93.62962962962963% similarity, with 632 matched token, and 43 token mismatch\n",
      "## Model validation for 700 tokens : 92.57142857142857% similarity, with 648 matched token, and 52 token mismatch\n",
      "## Model validation for 750 tokens : 91.33333333333333% similarity, with 685 matched token, and 65 token mismatch\n",
      "## Model validation for 800 tokens : 89.75% similarity, with 718 matched token, and 82 token mismatch\n",
      "## Model validation for 850 tokens : 88.47058823529412% similarity, with 752 matched token, and 98 token mismatch\n",
      "## Model validation for 900 tokens : 87.44444444444444% similarity, with 787 matched token, and 113 token mismatch\n",
      "## Model validation for 950 tokens : 85.26315789473684% similarity, with 810 matched token, and 140 token mismatch\n",
      "## Model validation for 1000 tokens : 84.6% similarity, with 846 matched token, and 154 token mismatch\n",
      "###\n",
      "### Model validation end ###\n",
      "###\n",
      "SCRIPT_DIR:  /home/recursal/RWKV-infctx-trainer/notebook/rwkv-x-exp/v5-exp/memory-test/memory_script\n",
      "PROJECT_DIR:  /home/recursal/RWKV-infctx-trainer\n",
      "MODEL_CODE_DIR:  /home/recursal/RWKV-infctx-trainer/RWKV-v5\n",
      "[2024-01-22 22:56:41,762] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/wkv5/build.ninja...\n",
      "Building extension module wkv5...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "/home/recursal/RWKV-infctx-trainer/RWKV-v5/src/model.py:1390: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_tokens = torch.tensor(\n",
      "###\n",
      "### Model validation start ###\n",
      "###\n",
      "## Model validation for 1000 tokens : 84.6% similarity, with 846 matched token, and 154 token mismatch\n",
      "## Model validation for 1050 tokens : 81.61904761904762% similarity, with 857 matched token, and 193 token mismatch\n",
      "## Model validation for 1100 tokens : 80.0% similarity, with 880 matched token, and 220 token mismatch\n",
      "## Model validation for 1150 tokens : 76.52173913043478% similarity, with 880 matched token, and 270 token mismatch\n",
      "## Model validation for 1200 tokens : 74.41666666666666% similarity, with 893 matched token, and 307 token mismatch\n",
      "## Model validation for 1250 tokens : 73.04% similarity, with 913 matched token, and 337 token mismatch\n",
      "## Model validation for 1300 tokens : 70.15384615384616% similarity, with 912 matched token, and 388 token mismatch\n",
      "## Model validation for 1350 tokens : 67.62962962962963% similarity, with 913 matched token, and 437 token mismatch\n",
      "## Model validation for 1400 tokens : 65.64285714285715% similarity, with 919 matched token, and 481 token mismatch\n",
      "## Model validation for 1450 tokens : 62.96551724137931% similarity, with 913 matched token, and 537 token mismatch\n",
      "## Model validation for 1500 tokens : 59.8% similarity, with 897 matched token, and 603 token mismatch\n",
      "## Model validation for 1550 tokens : 58.774193548387096% similarity, with 911 matched token, and 639 token mismatch\n",
      "## Model validation for 1600 tokens : 56.8125% similarity, with 909 matched token, and 691 token mismatch\n",
      "## Model validation for 1650 tokens : 53.81818181818182% similarity, with 888 matched token, and 762 token mismatch\n",
      "## Model validation for 1700 tokens : 52.294117647058826% similarity, with 889 matched token, and 811 token mismatch\n",
      "## Model validation for 1750 tokens : 49.42857142857143% similarity, with 865 matched token, and 885 token mismatch\n",
      "## Model validation for 1800 tokens : 46.833333333333336% similarity, with 843 matched token, and 957 token mismatch\n",
      "## Model validation for 1850 tokens : 44.81081081081081% similarity, with 829 matched token, and 1021 token mismatch\n",
      "## Model validation for 1900 tokens : 43.57894736842105% similarity, with 828 matched token, and 1072 token mismatch\n",
      "## Model validation for 1950 tokens : 40.35897435897436% similarity, with 787 matched token, and 1163 token mismatch\n",
      "## Model validation for 2000 tokens : 39.2% similarity, with 784 matched token, and 1216 token mismatch\n",
      "## Model validation for 2050 tokens : 37.26829268292683% similarity, with 764 matched token, and 1286 token mismatch\n",
      "## Model validation for 2100 tokens : 35.76190476190476% similarity, with 751 matched token, and 1349 token mismatch\n",
      "## Model validation for 2150 tokens : 34.27906976744186% similarity, with 737 matched token, and 1413 token mismatch\n",
      "## Model validation for 2200 tokens : 32.95454545454545% similarity, with 725 matched token, and 1475 token mismatch\n",
      "## Model validation for 2250 tokens : 32.22222222222222% similarity, with 725 matched token, and 1525 token mismatch\n",
      "## Model validation for 2300 tokens : 30.043478260869566% similarity, with 691 matched token, and 1609 token mismatch\n",
      "## Model validation for 2350 tokens : 29.06382978723404% similarity, with 683 matched token, and 1667 token mismatch\n",
      "## Model validation for 2400 tokens : 27.375% similarity, with 657 matched token, and 1743 token mismatch\n",
      "## Model validation for 2450 tokens : 26.040816326530614% similarity, with 638 matched token, and 1812 token mismatch\n",
      "## Model validation for 2500 tokens : 24.12% similarity, with 603 matched token, and 1897 token mismatch\n",
      "## Model validation for 2550 tokens : 22.980392156862745% similarity, with 586 matched token, and 1964 token mismatch\n",
      "## Model validation for 2600 tokens : 22.692307692307693% similarity, with 590 matched token, and 2010 token mismatch\n",
      "## Model validation for 2650 tokens : 21.132075471698116% similarity, with 560 matched token, and 2090 token mismatch\n",
      "## Model validation for 2700 tokens : 20.14814814814815% similarity, with 544 matched token, and 2156 token mismatch\n",
      "## Model validation for 2750 tokens : 18.654545454545453% similarity, with 513 matched token, and 2237 token mismatch\n"
     ]
    }
   ],
   "source": [
    "# Lets do a memory eval!\n",
    "!python3 ./memory_script/eval_v5_memory_guided.py \"{PROJECT_DIR}/model/Memory-Tune-Stage-1-{MODEL_NAME}\"\n",
    "!python3 ./memory_script/eval_v5_memory_guided.py \"{PROJECT_DIR}/model/Memory-Tune-Stage-1-{MODEL_NAME}\" \"none\" 1000 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune 2 - More data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Generating word reptition dataset ##\n",
      "Generated JSONL file with - 5 max words, 150 samples - at ./dataset/gen-word-5-count.jsonl\n",
      "Generated JSONL file with - 35 max words, 150 samples - at ./dataset/gen-word-35-count.jsonl\n",
      "Generated JSONL file with - 40 max words, 150 samples - at ./dataset/gen-word-40-count.jsonl\n",
      "Generated JSONL file with - 10 max words, 150 samples - at ./dataset/gen-word-10-count.jsonl\n",
      "Generated JSONL file with - 25 max words, 150 samples - at ./dataset/gen-word-25-count.jsonl\n",
      "Generated JSONL file with - 60 max words, 150 samples - at ./dataset/gen-word-60-count.jsonl\n",
      "Generated JSONL file with - 55 max words, 150 samples - at ./dataset/gen-word-55-count.jsonl\n",
      "Generated JSONL file with - 20 max words, 150 samples - at ./dataset/gen-word-20-count.jsonl\n",
      "Generated JSONL file with - 65 max words, 150 samples - at ./dataset/gen-word-65-count.jsonl\n",
      "Generated JSONL file with - 70 max words, 150 samples - at ./dataset/gen-word-70-count.jsonl\n",
      "Generated JSONL file with - 85 max words, 150 samples - at ./dataset/gen-word-85-count.jsonl\n",
      "Generated JSONL file with - 95 max words, 150 samples - at ./dataset/gen-word-95-count.jsonl\n",
      "Generated JSONL file with - 15 max words, 150 samples - at ./dataset/gen-word-15-count.jsonl\n",
      "Generated JSONL file with - 110 max words, 150 samples - at ./dataset/gen-word-110-count.jsonl\n",
      "Generated JSONL file with - 50 max words, 150 samples - at ./dataset/gen-word-50-count.jsonl\n",
      "Generated JSONL file with - 45 max words, 150 samples - at ./dataset/gen-word-45-count.jsonl\n",
      "Generated JSONL file with - 115 max words, 150 samples - at ./dataset/gen-word-115-count.jsonl\n",
      "Generated JSONL file with - 30 max words, 150 samples - at ./dataset/gen-word-30-count.jsonl\n",
      "Generated JSONL file with - 120 max words, 150 samples - at ./dataset/gen-word-120-count.jsonl\n",
      "Generated JSONL file with - 100 max words, 150 samples - at ./dataset/gen-word-100-count.jsonl\n",
      "Generated JSONL file with - 80 max words, 150 samples - at ./dataset/gen-word-80-count.jsonl\n",
      "Generated JSONL file with - 145 max words, 150 samples - at ./dataset/gen-word-145-count.jsonl\n",
      "Generated JSONL file with - 90 max words, 150 samples - at ./dataset/gen-word-90-count.jsonl\n",
      "Generated JSONL file with - 75 max words, 150 samples - at ./dataset/gen-word-75-count.jsonl\n",
      "Generated JSONL file with - 105 max words, 150 samples - at ./dataset/gen-word-105-count.jsonl\n",
      "Generated JSONL file with - 170 max words, 150 samples - at ./dataset/gen-word-170-count.jsonl\n",
      "Generated JSONL file with - 125 max words, 150 samples - at ./dataset/gen-word-125-count.jsonl\n",
      "Generated JSONL file with - 135 max words, 150 samples - at ./dataset/gen-word-135-count.jsonl\n",
      "Generated JSONL file with - 220 max words, 150 samples - at ./dataset/gen-word-220-count.jsonl\n",
      "Generated JSONL file with - 165 max words, 150 samples - at ./dataset/gen-word-165-count.jsonl\n",
      "Generated JSONL file with - 250 max words, 150 samples - at ./dataset/gen-word-250-count.jsonl\n",
      "Generated JSONL file with - 130 max words, 150 samples - at ./dataset/gen-word-130-count.jsonl\n",
      "Generated JSONL file with - 140 max words, 150 samples - at ./dataset/gen-word-140-count.jsonl\n",
      "Generated JSONL file with - 255 max words, 150 samples - at ./dataset/gen-word-255-count.jsonl\n",
      "Generated JSONL file with - 175 max words, 150 samples - at ./dataset/gen-word-175-count.jsonl\n",
      "Generated JSONL file with - 150 max words, 150 samples - at ./dataset/gen-word-150-count.jsonl\n",
      "Generated JSONL file with - 285 max words, 150 samples - at ./dataset/gen-word-285-count.jsonl\n",
      "Generated JSONL file with - 190 max words, 150 samples - at ./dataset/gen-word-190-count.jsonl\n",
      "Generated JSONL file with - 160 max words, 150 samples - at ./dataset/gen-word-160-count.jsonl\n",
      "Generated JSONL file with - 195 max words, 150 samples - at ./dataset/gen-word-195-count.jsonl\n",
      "Generated JSONL file with - 185 max words, 150 samples - at ./dataset/gen-word-185-count.jsonl\n",
      "Generated JSONL file with - 155 max words, 150 samples - at ./dataset/gen-word-155-count.jsonl\n",
      "Generated JSONL file with - 205 max words, 150 samples - at ./dataset/gen-word-205-count.jsonl\n",
      "Generated JSONL file with - 290 max words, 150 samples - at ./dataset/gen-word-290-count.jsonl\n",
      "Generated JSONL file with - 315 max words, 150 samples - at ./dataset/gen-word-315-count.jsonl\n",
      "Generated JSONL file with - 180 max words, 150 samples - at ./dataset/gen-word-180-count.jsonl\n",
      "Generated JSONL file with - 325 max words, 150 samples - at ./dataset/gen-word-325-count.jsonl\n",
      "Generated JSONL file with - 210 max words, 150 samples - at ./dataset/gen-word-210-count.jsonl\n",
      "Generated JSONL file with - 345 max words, 150 samples - at ./dataset/gen-word-345-count.jsonl\n",
      "Generated JSONL file with - 200 max words, 150 samples - at ./dataset/gen-word-200-count.jsonl\n",
      "Generated JSONL file with - 350 max words, 150 samples - at ./dataset/gen-word-350-count.jsonl\n",
      "Generated JSONL file with - 225 max words, 150 samples - at ./dataset/gen-word-225-count.jsonl\n",
      "Generated JSONL file with - 230 max words, 150 samples - at ./dataset/gen-word-230-count.jsonl\n",
      "Generated JSONL file with - 335 max words, 150 samples - at ./dataset/gen-word-335-count.jsonl\n",
      "Generated JSONL file with - 330 max words, 150 samples - at ./dataset/gen-word-330-count.jsonl\n",
      "Generated JSONL file with - 215 max words, 150 samples - at ./dataset/gen-word-215-count.jsonl\n",
      "Generated JSONL file with - 245 max words, 150 samples - at ./dataset/gen-word-245-count.jsonl\n",
      "Generated JSONL file with - 380 max words, 150 samples - at ./dataset/gen-word-380-count.jsonl\n",
      "Generated JSONL file with - 390 max words, 150 samples - at ./dataset/gen-word-390-count.jsonl\n",
      "Generated JSONL file with - 265 max words, 150 samples - at ./dataset/gen-word-265-count.jsonl\n",
      "Generated JSONL file with - 235 max words, 150 samples - at ./dataset/gen-word-235-count.jsonl\n",
      "Generated JSONL file with - 310 max words, 150 samples - at ./dataset/gen-word-310-count.jsonl\n",
      "Generated JSONL file with - 300 max words, 150 samples - at ./dataset/gen-word-300-count.jsonl\n",
      "Generated JSONL file with - 270 max words, 150 samples - at ./dataset/gen-word-270-count.jsonl\n",
      "Generated JSONL file with - 355 max words, 150 samples - at ./dataset/gen-word-355-count.jsonl\n",
      "Generated JSONL file with - 375 max words, 150 samples - at ./dataset/gen-word-375-count.jsonl\n",
      "Generated JSONL file with - 240 max words, 150 samples - at ./dataset/gen-word-240-count.jsonl\n",
      "Generated JSONL file with - 275 max words, 150 samples - at ./dataset/gen-word-275-count.jsonl\n",
      "Generated JSONL file with - 425 max words, 150 samples - at ./dataset/gen-word-425-count.jsonl\n",
      "Generated JSONL file with - 260 max words, 150 samples - at ./dataset/gen-word-260-count.jsonl\n",
      "Generated JSONL file with - 280 max words, 150 samples - at ./dataset/gen-word-280-count.jsonl\n",
      "Generated JSONL file with - 305 max words, 150 samples - at ./dataset/gen-word-305-count.jsonl\n",
      "Generated JSONL file with - 405 max words, 150 samples - at ./dataset/gen-word-405-count.jsonl\n",
      "Generated JSONL file with - 320 max words, 150 samples - at ./dataset/gen-word-320-count.jsonl\n",
      "Generated a single JSONL file with 1731 samples (100 token repeat) - 130 max words - at ./dataset/shuffle-word-130-count.jsonl\n",
      "Generated a single JSONL file with 3551 samples (100 token repeat) - 75 max words - at ./dataset/shuffle-word-75-count.jsonl\n",
      "Generated a single JSONL file with 3767 samples (100 token repeat) - 70 max words - at ./dataset/shuffle-word-70-count.jsonl\n",
      "Generated JSONL file with - 430 max words, 150 samples - at ./dataset/gen-word-430-count.jsonl\n",
      "Generated JSONL file with - 340 max words, 150 samples - at ./dataset/gen-word-340-count.jsonl\n",
      "Generated JSONL file with - 445 max words, 150 samples - at ./dataset/gen-word-445-count.jsonl\n",
      "Generated a single JSONL file with 1538 samples (100 token repeat) - 150 max words - at ./dataset/shuffle-word-150-count.jsonl\n",
      "Generated a single JSONL file with 1980 samples (100 token repeat) - 110 max words - at ./dataset/shuffle-word-110-count.jsonl\n",
      "Generated JSONL file with - 495 max words, 150 samples - at ./dataset/gen-word-495-count.jsonl\n",
      "Generated JSONL file with - 720 max words, 150 samples - at ./dataset/gen-word-720-count.jsonl\n",
      "Generated JSONL file with - 665 max words, 150 samples - at ./dataset/gen-word-665-count.jsonl\n",
      "Generated JSONL file with - 415 max words, 150 samples - at ./dataset/gen-word-415-count.jsonl\n",
      "Generated JSONL file with - 410 max words, 150 samples - at ./dataset/gen-word-410-count.jsonl\n",
      "Generated JSONL file with - 710 max words, 150 samples - at ./dataset/gen-word-710-count.jsonl\n",
      "Generated JSONL file with - 810 max words, 150 samples - at ./dataset/gen-word-810-count.jsonl\n",
      "Generated a single JSONL file with 4834 samples (100 token repeat) - 55 max words - at ./dataset/shuffle-word-55-count.jsonl\n",
      "Generated a single JSONL file with 4068 samples (100 token repeat) - 65 max words - at ./dataset/shuffle-word-65-count.jsonl\n",
      "Generated JSONL file with - 530 max words, 150 samples - at ./dataset/gen-word-530-count.jsonl\n",
      "Generated a single JSONL file with 729 samples (100 token repeat) - 305 max words - at ./dataset/shuffle-word-305-count.jsonl\n",
      "Generated JSONL file with - 470 max words, 150 samples - at ./dataset/gen-word-470-count.jsonl\n",
      "Generated JSONL file with - 440 max words, 150 samples - at ./dataset/gen-word-440-count.jsonl\n",
      "Generated JSONL file with - 365 max words, 150 samples - at ./dataset/gen-word-365-count.jsonl\n",
      "Generated a single JSONL file with 920 samples (100 token repeat) - 300 max words - at ./dataset/shuffle-word-300-count.jsonl\n",
      "Generated JSONL file with - 730 max words, 150 samples - at ./dataset/gen-word-730-count.jsonl\n",
      "Generated JSONL file with - 715 max words, 150 samples - at ./dataset/gen-word-715-count.jsonl\n",
      "Generated a single JSONL file with 715 samples (100 token repeat) - 310 max words - at ./dataset/shuffle-word-310-count.jsonl\n",
      "Generated JSONL file with - 500 max words, 150 samples - at ./dataset/gen-word-500-count.jsonl\n",
      "Generated a single JSONL file with 702 samples (100 token repeat) - 335 max words - at ./dataset/shuffle-word-335-count.jsonl\n",
      "Generated a single JSONL file with 923 samples (100 token repeat) - 265 max words - at ./dataset/shuffle-word-265-count.jsonl\n",
      "Generated a single JSONL file with 700 samples (100 token repeat) - 380 max words - at ./dataset/shuffle-word-380-count.jsonl\n",
      "Generated JSONL file with - 750 max words, 150 samples - at ./dataset/gen-word-750-count.jsonl\n",
      "Generated JSONL file with - 435 max words, 150 samples - at ./dataset/gen-word-435-count.jsonl\n",
      "Generated JSONL file with - 700 max words, 150 samples - at ./dataset/gen-word-700-count.jsonl\n",
      "Generated JSONL file with - 510 max words, 150 samples - at ./dataset/gen-word-510-count.jsonl\n",
      "Generated JSONL file with - 925 max words, 150 samples - at ./dataset/gen-word-925-count.jsonl\n",
      "Generated JSONL file with - 370 max words, 150 samples - at ./dataset/gen-word-370-count.jsonl\n",
      "Generated a single JSONL file with 705 samples (100 token repeat) - 325 max words - at ./dataset/shuffle-word-325-count.jsonl\n",
      "Generated JSONL file with - 620 max words, 150 samples - at ./dataset/gen-word-620-count.jsonl\n",
      "Generated JSONL file with - 675 max words, 150 samples - at ./dataset/gen-word-675-count.jsonl\n",
      "Generated JSONL file with - 480 max words, 150 samples - at ./dataset/gen-word-480-count.jsonl\n",
      "Generated JSONL file with - 395 max words, 150 samples - at ./dataset/gen-word-395-count.jsonl\n",
      "Generated JSONL file with - 760 max words, 150 samples - at ./dataset/gen-word-760-count.jsonl\n",
      "Generated JSONL file with - 295 max words, 150 samples - at ./dataset/gen-word-295-count.jsonl\n",
      "Generated a single JSONL file with 400 samples (100 token repeat) - 750 max words - at ./dataset/shuffle-word-750-count.jsonl\n",
      "Generated a single JSONL file with 6539 samples (100 token repeat) - 40 max words - at ./dataset/shuffle-word-40-count.jsonl\n",
      "Generated JSONL file with - 490 max words, 150 samples - at ./dataset/gen-word-490-count.jsonl\n",
      "Generated JSONL file with - 850 max words, 150 samples - at ./dataset/gen-word-850-count.jsonl\n",
      "Generated JSONL file with - 955 max words, 150 samples - at ./dataset/gen-word-955-count.jsonl\n",
      "Generated a single JSONL file with 702 samples (100 token repeat) - 360 max words - at ./dataset/shuffle-word-360-count.jsonl\n",
      "Generated a single JSONL file with 2944 samples (100 token repeat) - 90 max words - at ./dataset/shuffle-word-90-count.jsonl\n",
      "Generated JSONL file with - 965 max words, 150 samples - at ./dataset/gen-word-965-count.jsonl\n",
      "Generated JSONL file with - 635 max words, 150 samples - at ./dataset/gen-word-635-count.jsonl\n",
      "Generated a single JSONL file with 919 samples (100 token repeat) - 290 max words - at ./dataset/shuffle-word-290-count.jsonl\n",
      "Generated JSONL file with - 805 max words, 150 samples - at ./dataset/gen-word-805-count.jsonl\n",
      "Generated JSONL file with - 420 max words, 150 samples - at ./dataset/gen-word-420-count.jsonl\n",
      "Generated a single JSONL file with 4381 samples (100 token repeat) - 60 max words - at ./dataset/shuffle-word-60-count.jsonl\n",
      "Generated JSONL file with - 775 max words, 150 samples - at ./dataset/gen-word-775-count.jsonl\n",
      "Generated a single JSONL file with 3117 samples (100 token repeat) - 85 max words - at ./dataset/shuffle-word-85-count.jsonl\n",
      "Generated a single JSONL file with 589 samples (100 token repeat) - 475 max words - at ./dataset/shuffle-word-475-count.jsonl\n",
      "Generated JSONL file with - 705 max words, 150 samples - at ./dataset/gen-word-705-count.jsonl\n",
      "Generated JSONL file with - 825 max words, 150 samples - at ./dataset/gen-word-825-count.jsonl\n",
      "Generated a single JSONL file with 5256 samples (100 token repeat) - 50 max words - at ./dataset/shuffle-word-50-count.jsonl\n",
      "Generated JSONL file with - 605 max words, 150 samples - at ./dataset/gen-word-605-count.jsonl\n",
      "Generated a single JSONL file with 400 samples (100 token repeat) - 710 max words - at ./dataset/shuffle-word-710-count.jsonl\n",
      "Generated JSONL file with - 610 max words, 150 samples - at ./dataset/gen-word-610-count.jsonl\n",
      "Generated JSONL file with - 860 max words, 150 samples - at ./dataset/gen-word-860-count.jsonl\n",
      "Generated a single JSONL file with 702 samples (100 token repeat) - 385 max words - at ./dataset/shuffle-word-385-count.jsonl\n",
      "Generated a single JSONL file with 702 samples (100 token repeat) - 390 max words - at ./dataset/shuffle-word-390-count.jsonl\n",
      "Generated a single JSONL file with 703 samples (100 token repeat) - 375 max words - at ./dataset/shuffle-word-375-count.jsonl\n",
      "Generated a single JSONL file with 498 samples (100 token repeat) - 525 max words - at ./dataset/shuffle-word-525-count.jsonl\n",
      "Generated JSONL file with - 560 max words, 150 samples - at ./dataset/gen-word-560-count.jsonl\n",
      "Generated a single JSONL file with 594 samples (100 token repeat) - 420 max words - at ./dataset/shuffle-word-420-count.jsonl\n",
      "Generated a single JSONL file with 927 samples (100 token repeat) - 255 max words - at ./dataset/shuffle-word-255-count.jsonl\n",
      "Generated a single JSONL file with 399 samples (100 token repeat) - 720 max words - at ./dataset/shuffle-word-720-count.jsonl\n",
      "Generated a single JSONL file with 582 samples (100 token repeat) - 445 max words - at ./dataset/shuffle-word-445-count.jsonl\n",
      "Generated JSONL file with - 735 max words, 150 samples - at ./dataset/gen-word-735-count.jsonl\n",
      "Generated JSONL file with - 475 max words, 150 samples - at ./dataset/gen-word-475-count.jsonl\n",
      "Generated a single JSONL file with 322 samples (100 token repeat) - 860 max words - at ./dataset/shuffle-word-860-count.jsonl\n",
      "Generated JSONL file with - 820 max words, 150 samples - at ./dataset/gen-word-820-count.jsonl\n",
      "Generated JSONL file with - 695 max words, 150 samples - at ./dataset/gen-word-695-count.jsonl\n",
      "Generated JSONL file with - 540 max words, 150 samples - at ./dataset/gen-word-540-count.jsonl\n",
      "Generated JSONL file with - 385 max words, 150 samples - at ./dataset/gen-word-385-count.jsonl\n",
      "Generated JSONL file with - 670 max words, 150 samples - at ./dataset/gen-word-670-count.jsonl\n",
      "Generated a single JSONL file with 587 samples (100 token repeat) - 430 max words - at ./dataset/shuffle-word-430-count.jsonl\n",
      "Generated JSONL file with - 625 max words, 150 samples - at ./dataset/gen-word-625-count.jsonl\n",
      "Generated JSONL file with - 520 max words, 150 samples - at ./dataset/gen-word-520-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 905 max words - at ./dataset/shuffle-word-905-count.jsonl\n",
      "Generated JSONL file with - 800 max words, 150 samples - at ./dataset/gen-word-800-count.jsonl\n",
      "Generated JSONL file with - 755 max words, 150 samples - at ./dataset/gen-word-755-count.jsonl\n",
      "Generated JSONL file with - 830 max words, 150 samples - at ./dataset/gen-word-830-count.jsonl\n",
      "Generated JSONL file with - 615 max words, 150 samples - at ./dataset/gen-word-615-count.jsonl\n",
      "Generated JSONL file with - 575 max words, 150 samples - at ./dataset/gen-word-575-count.jsonl\n",
      "Generated a single JSONL file with 397 samples (100 token repeat) - 755 max words - at ./dataset/shuffle-word-755-count.jsonl\n",
      "Generated JSONL file with - 815 max words, 150 samples - at ./dataset/gen-word-815-count.jsonl\n",
      "Generated JSONL file with - 505 max words, 150 samples - at ./dataset/gen-word-505-count.jsonl\n",
      "Generated JSONL file with - 555 max words, 150 samples - at ./dataset/gen-word-555-count.jsonl\n",
      "Generated a single JSONL file with 1381 samples (100 token repeat) - 180 max words - at ./dataset/shuffle-word-180-count.jsonl\n",
      "Generated JSONL file with - 680 max words, 150 samples - at ./dataset/gen-word-680-count.jsonl\n",
      "Generated a single JSONL file with 698 samples (100 token repeat) - 395 max words - at ./dataset/shuffle-word-395-count.jsonl\n",
      "Generated JSONL file with - 565 max words, 150 samples - at ./dataset/gen-word-565-count.jsonl\n",
      "Generated a single JSONL file with 398 samples (100 token repeat) - 715 max words - at ./dataset/shuffle-word-715-count.jsonl\n",
      "Generated JSONL file with - 725 max words, 150 samples - at ./dataset/gen-word-725-count.jsonl\n",
      "Generated JSONL file with - 515 max words, 150 samples - at ./dataset/gen-word-515-count.jsonl\n",
      "Generated a single JSONL file with 399 samples (100 token repeat) - 800 max words - at ./dataset/shuffle-word-800-count.jsonl\n",
      "Generated JSONL file with - 795 max words, 150 samples - at ./dataset/gen-word-795-count.jsonl\n",
      "Generated JSONL file with - 690 max words, 150 samples - at ./dataset/gen-word-690-count.jsonl\n",
      "Generated a single JSONL file with 316 samples (100 token repeat) - 820 max words - at ./dataset/shuffle-word-820-count.jsonl\n",
      "Generated a single JSONL file with 312 samples (100 token repeat) - 875 max words - at ./dataset/shuffle-word-875-count.jsonl\n",
      "Generated JSONL file with - 890 max words, 150 samples - at ./dataset/gen-word-890-count.jsonl\n",
      "Generated JSONL file with - 855 max words, 150 samples - at ./dataset/gen-word-855-count.jsonl\n",
      "Generated JSONL file with - 455 max words, 150 samples - at ./dataset/gen-word-455-count.jsonl\n",
      "Generated a single JSONL file with 596 samples (100 token repeat) - 410 max words - at ./dataset/shuffle-word-410-count.jsonl\n",
      "Generated JSONL file with - 570 max words, 150 samples - at ./dataset/gen-word-570-count.jsonl\n",
      "Generated a single JSONL file with 405 samples (100 token repeat) - 635 max words - at ./dataset/shuffle-word-635-count.jsonl\n",
      "Generated JSONL file with - 895 max words, 150 samples - at ./dataset/gen-word-895-count.jsonl\n",
      "Generated a single JSONL file with 402 samples (100 token repeat) - 610 max words - at ./dataset/shuffle-word-610-count.jsonl\n",
      "Generated a single JSONL file with 400 samples (100 token repeat) - 740 max words - at ./dataset/shuffle-word-740-count.jsonl\n",
      "Generated JSONL file with - 780 max words, 150 samples - at ./dataset/gen-word-780-count.jsonl\n",
      "Generated a single JSONL file with 704 samples (100 token repeat) - 345 max words - at ./dataset/shuffle-word-345-count.jsonl\n",
      "Generated JSONL file with - 630 max words, 150 samples - at ./dataset/gen-word-630-count.jsonl\n",
      "Generated a single JSONL file with 399 samples (100 token repeat) - 795 max words - at ./dataset/shuffle-word-795-count.jsonl\n",
      "Generated JSONL file with - 450 max words, 150 samples - at ./dataset/gen-word-450-count.jsonl\n",
      "Generated a single JSONL file with 1623 samples (100 token repeat) - 140 max words - at ./dataset/shuffle-word-140-count.jsonl\n",
      "Generated JSONL file with - 990 max words, 150 samples - at ./dataset/gen-word-990-count.jsonl\n",
      "Generated JSONL file with - 935 max words, 150 samples - at ./dataset/gen-word-935-count.jsonl\n",
      "Generated a single JSONL file with 322 samples (100 token repeat) - 880 max words - at ./dataset/shuffle-word-880-count.jsonl\n",
      "Generated JSONL file with - 580 max words, 150 samples - at ./dataset/gen-word-580-count.jsonl\n",
      "Generated a single JSONL file with 585 samples (100 token repeat) - 440 max words - at ./dataset/shuffle-word-440-count.jsonl\n",
      "Generated a single JSONL file with 497 samples (100 token repeat) - 600 max words - at ./dataset/shuffle-word-600-count.jsonl\n",
      "Generated a single JSONL file with 403 samples (100 token repeat) - 615 max words - at ./dataset/shuffle-word-615-count.jsonl\n",
      "Generated a single JSONL file with 397 samples (100 token repeat) - 725 max words - at ./dataset/shuffle-word-725-count.jsonl\n",
      "Generated JSONL file with - 840 max words, 150 samples - at ./dataset/gen-word-840-count.jsonl\n",
      "Generated a single JSONL file with 398 samples (100 token repeat) - 705 max words - at ./dataset/shuffle-word-705-count.jsonl\n",
      "Generated a single JSONL file with 314 samples (100 token repeat) - 840 max words - at ./dataset/shuffle-word-840-count.jsonl\n",
      "Generated a single JSONL file with 405 samples (100 token repeat) - 605 max words - at ./dataset/shuffle-word-605-count.jsonl\n",
      "Generated a single JSONL file with 933 samples (100 token repeat) - 250 max words - at ./dataset/shuffle-word-250-count.jsonl\n",
      "Generated a single JSONL file with 402 samples (100 token repeat) - 690 max words - at ./dataset/shuffle-word-690-count.jsonl\n",
      "Generated a single JSONL file with 314 samples (100 token repeat) - 810 max words - at ./dataset/shuffle-word-810-count.jsonl\n",
      "Generated JSONL file with - 885 max words, 150 samples - at ./dataset/gen-word-885-count.jsonl\n",
      "Generated a single JSONL file with 3310 samples (100 token repeat) - 80 max words - at ./dataset/shuffle-word-80-count.jsonl\n",
      "Generated a single JSONL file with 317 samples (100 token repeat) - 805 max words - at ./dataset/shuffle-word-805-count.jsonl\n",
      "Generated JSONL file with - 845 max words, 150 samples - at ./dataset/gen-word-845-count.jsonl\n",
      "Generated JSONL file with - 880 max words, 150 samples - at ./dataset/gen-word-880-count.jsonl\n",
      "Generated JSONL file with - 465 max words, 150 samples - at ./dataset/gen-word-465-count.jsonl\n",
      "Generated JSONL file with - 550 max words, 150 samples - at ./dataset/gen-word-550-count.jsonl\n",
      "Generated JSONL file with - 960 max words, 150 samples - at ./dataset/gen-word-960-count.jsonl\n",
      "Generated a single JSONL file with 581 samples (100 token repeat) - 490 max words - at ./dataset/shuffle-word-490-count.jsonl\n",
      "Generated JSONL file with - 865 max words, 150 samples - at ./dataset/gen-word-865-count.jsonl\n",
      "Generated JSONL file with - 745 max words, 150 samples - at ./dataset/gen-word-745-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 955 max words - at ./dataset/shuffle-word-955-count.jsonl\n",
      "Generated a single JSONL file with 404 samples (100 token repeat) - 620 max words - at ./dataset/shuffle-word-620-count.jsonl\n",
      "Generated a single JSONL file with 498 samples (100 token repeat) - 530 max words - at ./dataset/shuffle-word-530-count.jsonl\n",
      "Generated JSONL file with - 770 max words, 150 samples - at ./dataset/gen-word-770-count.jsonl\n",
      "Generated JSONL file with - 590 max words, 150 samples - at ./dataset/gen-word-590-count.jsonl\n",
      "Generated JSONL file with - 915 max words, 150 samples - at ./dataset/gen-word-915-count.jsonl\n",
      "Generated a single JSONL file with 916 samples (100 token repeat) - 295 max words - at ./dataset/shuffle-word-295-count.jsonl\n",
      "Generated JSONL file with - 650 max words, 150 samples - at ./dataset/gen-word-650-count.jsonl\n",
      "Generated JSONL file with - 790 max words, 150 samples - at ./dataset/gen-word-790-count.jsonl\n",
      "Generated a single JSONL file with 405 samples (100 token repeat) - 640 max words - at ./dataset/shuffle-word-640-count.jsonl\n",
      "Generated a single JSONL file with 317 samples (100 token repeat) - 845 max words - at ./dataset/shuffle-word-845-count.jsonl\n",
      "Generated JSONL file with - 870 max words, 150 samples - at ./dataset/gen-word-870-count.jsonl\n",
      "Generated a single JSONL file with 400 samples (100 token repeat) - 730 max words - at ./dataset/shuffle-word-730-count.jsonl\n",
      "Generated JSONL file with - 835 max words, 150 samples - at ./dataset/gen-word-835-count.jsonl\n",
      "Generated a single JSONL file with 702 samples (100 token repeat) - 350 max words - at ./dataset/shuffle-word-350-count.jsonl\n",
      "Generated JSONL file with - 905 max words, 150 samples - at ./dataset/gen-word-905-count.jsonl\n",
      "Generated JSONL file with - 585 max words, 150 samples - at ./dataset/gen-word-585-count.jsonl\n",
      "Generated a single JSONL file with 398 samples (100 token repeat) - 765 max words - at ./dataset/shuffle-word-765-count.jsonl\n",
      "Generated JSONL file with - 1000 max words, 150 samples - at ./dataset/gen-word-1000-count.jsonl\n",
      "Generated a single JSONL file with 322 samples (100 token repeat) - 815 max words - at ./dataset/shuffle-word-815-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 910 max words - at ./dataset/shuffle-word-910-count.jsonl\n",
      "Generated JSONL file with - 685 max words, 150 samples - at ./dataset/gen-word-685-count.jsonl\n",
      "Generated JSONL file with - 535 max words, 150 samples - at ./dataset/gen-word-535-count.jsonl\n",
      "Generated JSONL file with - 740 max words, 150 samples - at ./dataset/gen-word-740-count.jsonl\n",
      "Generated a single JSONL file with 400 samples (100 token repeat) - 685 max words - at ./dataset/shuffle-word-685-count.jsonl\n",
      "Generated JSONL file with - 900 max words, 150 samples - at ./dataset/gen-word-900-count.jsonl\n",
      "Generated a single JSONL file with 1360 samples (100 token repeat) - 195 max words - at ./dataset/shuffle-word-195-count.jsonl\n",
      "Generated a single JSONL file with 401 samples (100 token repeat) - 665 max words - at ./dataset/shuffle-word-665-count.jsonl\n",
      "Generated a single JSONL file with 311 samples (100 token repeat) - 850 max words - at ./dataset/shuffle-word-850-count.jsonl\n",
      "Generated a single JSONL file with 398 samples (100 token repeat) - 745 max words - at ./dataset/shuffle-word-745-count.jsonl\n",
      "Generated JSONL file with - 940 max words, 150 samples - at ./dataset/gen-word-940-count.jsonl\n",
      "Generated a single JSONL file with 396 samples (100 token repeat) - 775 max words - at ./dataset/shuffle-word-775-count.jsonl\n",
      "Generated a single JSONL file with 399 samples (100 token repeat) - 760 max words - at ./dataset/shuffle-word-760-count.jsonl\n",
      "Generated a single JSONL file with 1469 samples (100 token repeat) - 160 max words - at ./dataset/shuffle-word-160-count.jsonl\n",
      "Generated JSONL file with - 525 max words, 150 samples - at ./dataset/gen-word-525-count.jsonl\n",
      "Generated a single JSONL file with 316 samples (100 token repeat) - 855 max words - at ./dataset/shuffle-word-855-count.jsonl\n",
      "Generated a single JSONL file with 970 samples (100 token repeat) - 240 max words - at ./dataset/shuffle-word-240-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 520 max words - at ./dataset/shuffle-word-520-count.jsonl\n",
      "Generated JSONL file with - 600 max words, 150 samples - at ./dataset/gen-word-600-count.jsonl\n",
      "Generated a single JSONL file with 944 samples (100 token repeat) - 245 max words - at ./dataset/shuffle-word-245-count.jsonl\n",
      "Generated a single JSONL file with 498 samples (100 token repeat) - 550 max words - at ./dataset/shuffle-word-550-count.jsonl\n",
      "Generated a single JSONL file with 401 samples (100 token repeat) - 645 max words - at ./dataset/shuffle-word-645-count.jsonl\n",
      "Generated a single JSONL file with 403 samples (100 token repeat) - 655 max words - at ./dataset/shuffle-word-655-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 915 max words - at ./dataset/shuffle-word-915-count.jsonl\n",
      "Generated a single JSONL file with 321 samples (100 token repeat) - 865 max words - at ./dataset/shuffle-word-865-count.jsonl\n",
      "Generated JSONL file with - 1065 max words, 150 samples - at ./dataset/gen-word-1065-count.jsonl\n",
      "Generated a single JSONL file with 321 samples (100 token repeat) - 825 max words - at ./dataset/shuffle-word-825-count.jsonl\n",
      "Generated a single JSONL file with 397 samples (100 token repeat) - 735 max words - at ./dataset/shuffle-word-735-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 925 max words - at ./dataset/shuffle-word-925-count.jsonl\n",
      "Generated a single JSONL file with 17777 samples (100 token repeat) - 15 max words - at ./dataset/shuffle-word-15-count.jsonl\n",
      "Generated JSONL file with - 945 max words, 150 samples - at ./dataset/gen-word-945-count.jsonl\n",
      "Generated JSONL file with - 930 max words, 150 samples - at ./dataset/gen-word-930-count.jsonl\n",
      "Generated a single JSONL file with 399 samples (100 token repeat) - 770 max words - at ./dataset/shuffle-word-770-count.jsonl\n",
      "Generated JSONL file with - 980 max words, 150 samples - at ./dataset/gen-word-980-count.jsonl\n",
      "Generated JSONL file with - 360 max words, 150 samples - at ./dataset/gen-word-360-count.jsonl\n",
      "Generated JSONL file with - 975 max words, 150 samples - at ./dataset/gen-word-975-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 585 max words - at ./dataset/shuffle-word-585-count.jsonl\n",
      "Generated a single JSONL file with 318 samples (100 token repeat) - 835 max words - at ./dataset/shuffle-word-835-count.jsonl\n",
      "Generated a single JSONL file with 403 samples (100 token repeat) - 675 max words - at ./dataset/shuffle-word-675-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 975 max words - at ./dataset/shuffle-word-975-count.jsonl\n",
      "Generated a single JSONL file with 1002 samples (100 token repeat) - 220 max words - at ./dataset/shuffle-word-220-count.jsonl\n",
      "Generated a single JSONL file with 398 samples (100 token repeat) - 790 max words - at ./dataset/shuffle-word-790-count.jsonl\n",
      "Generated a single JSONL file with 984 samples (100 token repeat) - 235 max words - at ./dataset/shuffle-word-235-count.jsonl\n",
      "Generated JSONL file with - 920 max words, 150 samples - at ./dataset/gen-word-920-count.jsonl\n",
      "Generated JSONL file with - 1080 max words, 150 samples - at ./dataset/gen-word-1080-count.jsonl\n",
      "Generated a single JSONL file with 496 samples (100 token repeat) - 580 max words - at ./dataset/shuffle-word-580-count.jsonl\n",
      "Generated JSONL file with - 400 max words, 150 samples - at ./dataset/gen-word-400-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 540 max words - at ./dataset/shuffle-word-540-count.jsonl\n",
      "Generated a single JSONL file with 402 samples (100 token repeat) - 680 max words - at ./dataset/shuffle-word-680-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 535 max words - at ./dataset/shuffle-word-535-count.jsonl\n",
      "Generated a single JSONL file with 500 samples (100 token repeat) - 595 max words - at ./dataset/shuffle-word-595-count.jsonl\n",
      "Generated JSONL file with - 1025 max words, 150 samples - at ./dataset/gen-word-1025-count.jsonl\n",
      "Generated JSONL file with - 1005 max words, 150 samples - at ./dataset/gen-word-1005-count.jsonl\n",
      "Generated JSONL file with - 460 max words, 150 samples - at ./dataset/gen-word-460-count.jsonl\n",
      "Generated JSONL file with - 785 max words, 150 samples - at ./dataset/gen-word-785-count.jsonl\n",
      "Generated a single JSONL file with 321 samples (100 token repeat) - 900 max words - at ./dataset/shuffle-word-900-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 985 max words - at ./dataset/shuffle-word-985-count.jsonl\n",
      "Generated JSONL file with - 970 max words, 150 samples - at ./dataset/gen-word-970-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 945 max words - at ./dataset/shuffle-word-945-count.jsonl\n",
      "Generated JSONL file with - 1185 max words, 150 samples - at ./dataset/gen-word-1185-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 940 max words - at ./dataset/shuffle-word-940-count.jsonl\n",
      "Generated JSONL file with - 875 max words, 150 samples - at ./dataset/gen-word-875-count.jsonl\n",
      "Generated JSONL file with - 660 max words, 150 samples - at ./dataset/gen-word-660-count.jsonl\n",
      "Generated a single JSONL file with 996 samples (100 token repeat) - 230 max words - at ./dataset/shuffle-word-230-count.jsonl\n",
      "Generated JSONL file with - 1515 max words, 150 samples - at ./dataset/gen-word-1515-count.jsonl\n",
      "Generated a single JSONL file with 318 samples (100 token repeat) - 890 max words - at ./dataset/shuffle-word-890-count.jsonl\n",
      "Generated JSONL file with - 485 max words, 150 samples - at ./dataset/gen-word-485-count.jsonl\n",
      "Generated a single JSONL file with 310 samples (100 token repeat) - 885 max words - at ./dataset/shuffle-word-885-count.jsonl\n",
      "Generated a single JSONL file with 403 samples (100 token repeat) - 670 max words - at ./dataset/shuffle-word-670-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 970 max words - at ./dataset/shuffle-word-970-count.jsonl\n",
      "Generated JSONL file with - 1015 max words, 150 samples - at ./dataset/gen-word-1015-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 965 max words - at ./dataset/shuffle-word-965-count.jsonl\n",
      "Generated JSONL file with - 1665 max words, 150 samples - at ./dataset/gen-word-1665-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2040 max words - at ./dataset/shuffle-word-2040-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1935 max words - at ./dataset/shuffle-word-1935-count.jsonl\n",
      "Generated JSONL file with - 2055 max words, 125 samples - at ./dataset/gen-word-2055-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1895 max words - at ./dataset/shuffle-word-1895-count.jsonl\n",
      "Generated a single JSONL file with 318 samples (100 token repeat) - 895 max words - at ./dataset/shuffle-word-895-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1800 max words - at ./dataset/shuffle-word-1800-count.jsonl\n",
      "Generated a single JSONL file with 701 samples (100 token repeat) - 365 max words - at ./dataset/shuffle-word-365-count.jsonl\n",
      "Generated JSONL file with - 1935 max words, 150 samples - at ./dataset/gen-word-1935-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1970 max words - at ./dataset/shuffle-word-1970-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2095 max words - at ./dataset/shuffle-word-2095-count.jsonl\n",
      "Generated a single JSONL file with 500 samples (100 token repeat) - 510 max words - at ./dataset/shuffle-word-510-count.jsonl\n",
      "Generated a single JSONL file with 251 samples (100 token repeat) - 1215 max words - at ./dataset/shuffle-word-1215-count.jsonl\n",
      "Generated JSONL file with - 1905 max words, 150 samples - at ./dataset/gen-word-1905-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1590 max words - at ./dataset/shuffle-word-1590-count.jsonl\n",
      "Generated JSONL file with - 1895 max words, 150 samples - at ./dataset/gen-word-1895-count.jsonl\n",
      "Generated a single JSONL file with 596 samples (100 token repeat) - 415 max words - at ./dataset/shuffle-word-415-count.jsonl\n",
      "Generated JSONL file with - 1785 max words, 150 samples - at ./dataset/gen-word-1785-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 920 max words - at ./dataset/shuffle-word-920-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1920 max words - at ./dataset/shuffle-word-1920-count.jsonl\n",
      "Generated JSONL file with - 2080 max words, 125 samples - at ./dataset/gen-word-2080-count.jsonl\n",
      "Generated JSONL file with - 2000 max words, 150 samples - at ./dataset/gen-word-2000-count.jsonl\n",
      "Generated JSONL file with - 995 max words, 150 samples - at ./dataset/gen-word-995-count.jsonl\n",
      "Generated a single JSONL file with 500 samples (100 token repeat) - 515 max words - at ./dataset/shuffle-word-515-count.jsonl\n",
      "Generated a single JSONL file with 201 samples (100 token repeat) - 1360 max words - at ./dataset/shuffle-word-1360-count.jsonl\n",
      "Generated JSONL file with - 1835 max words, 150 samples - at ./dataset/gen-word-1835-count.jsonl\n",
      "Generated JSONL file with - 1630 max words, 150 samples - at ./dataset/gen-word-1630-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1645 max words - at ./dataset/shuffle-word-1645-count.jsonl\n",
      "Generated JSONL file with - 2100 max words, 125 samples - at ./dataset/gen-word-2100-count.jsonl\n",
      "Generated a single JSONL file with 204 samples (100 token repeat) - 1345 max words - at ./dataset/shuffle-word-1345-count.jsonl\n",
      "Generated JSONL file with - 1330 max words, 150 samples - at ./dataset/gen-word-1330-count.jsonl\n",
      "Generated a single JSONL file with 918 samples (100 token repeat) - 285 max words - at ./dataset/shuffle-word-285-count.jsonl\n",
      "Generated JSONL file with - 2105 max words, 125 samples - at ./dataset/gen-word-2105-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1550 max words - at ./dataset/shuffle-word-1550-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1695 max words - at ./dataset/shuffle-word-1695-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1555 max words - at ./dataset/shuffle-word-1555-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1865 max words - at ./dataset/shuffle-word-1865-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2225 max words - at ./dataset/shuffle-word-2225-count.jsonl\n",
      "Generated JSONL file with - 1455 max words, 150 samples - at ./dataset/gen-word-1455-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 935 max words - at ./dataset/shuffle-word-935-count.jsonl\n",
      "Generated JSONL file with - 2225 max words, 125 samples - at ./dataset/gen-word-2225-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1650 max words - at ./dataset/shuffle-word-1650-count.jsonl\n",
      "Generated JSONL file with - 1525 max words, 150 samples - at ./dataset/gen-word-1525-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1605 max words - at ./dataset/shuffle-word-1605-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1925 max words - at ./dataset/shuffle-word-1925-count.jsonl\n",
      "Generated a single JSONL file with 913 samples (100 token repeat) - 280 max words - at ./dataset/shuffle-word-280-count.jsonl\n",
      "Generated JSONL file with - 910 max words, 150 samples - at ./dataset/gen-word-910-count.jsonl\n",
      "Generated a single JSONL file with 318 samples (100 token repeat) - 870 max words - at ./dataset/shuffle-word-870-count.jsonl\n",
      "Generated a single JSONL file with 198 samples (100 token repeat) - 2325 max words - at ./dataset/shuffle-word-2325-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1795 max words - at ./dataset/shuffle-word-1795-count.jsonl\n",
      "Generated JSONL file with - 1550 max words, 150 samples - at ./dataset/gen-word-1550-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1585 max words - at ./dataset/shuffle-word-1585-count.jsonl\n",
      "Generated JSONL file with - 2305 max words, 125 samples - at ./dataset/gen-word-2305-count.jsonl\n",
      "Generated JSONL file with - 1930 max words, 150 samples - at ./dataset/gen-word-1930-count.jsonl\n",
      "Generated JSONL file with - 2315 max words, 125 samples - at ./dataset/gen-word-2315-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2000 max words - at ./dataset/shuffle-word-2000-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1910 max words - at ./dataset/shuffle-word-1910-count.jsonl\n",
      "Generated JSONL file with - 1595 max words, 150 samples - at ./dataset/gen-word-1595-count.jsonl\n",
      "Generated JSONL file with - 1780 max words, 150 samples - at ./dataset/gen-word-1780-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2100 max words - at ./dataset/shuffle-word-2100-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1675 max words - at ./dataset/shuffle-word-1675-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1930 max words - at ./dataset/shuffle-word-1930-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2075 max words - at ./dataset/shuffle-word-2075-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1815 max words - at ./dataset/shuffle-word-1815-count.jsonl\n",
      "Generated JSONL file with - 2040 max words, 125 samples - at ./dataset/gen-word-2040-count.jsonl\n",
      "Generated JSONL file with - 1925 max words, 150 samples - at ./dataset/gen-word-1925-count.jsonl\n",
      "Generated a single JSONL file with 2056 samples (100 token repeat) - 105 max words - at ./dataset/shuffle-word-105-count.jsonl\n",
      "Generated a single JSONL file with 317 samples (100 token repeat) - 830 max words - at ./dataset/shuffle-word-830-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2090 max words - at ./dataset/shuffle-word-2090-count.jsonl\n",
      "Generated a single JSONL file with 199 samples (100 token repeat) - 2320 max words - at ./dataset/shuffle-word-2320-count.jsonl\n",
      "Generated JSONL file with - 2195 max words, 125 samples - at ./dataset/gen-word-2195-count.jsonl\n",
      "Generated JSONL file with - 1020 max words, 150 samples - at ./dataset/gen-word-1020-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1915 max words - at ./dataset/shuffle-word-1915-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1825 max words - at ./dataset/shuffle-word-1825-count.jsonl\n",
      "Generated JSONL file with - 1910 max words, 150 samples - at ./dataset/gen-word-1910-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1065 max words - at ./dataset/shuffle-word-1065-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 950 max words - at ./dataset/shuffle-word-950-count.jsonl\n",
      "Generated a single JSONL file with 1347 samples (100 token repeat) - 200 max words - at ./dataset/shuffle-word-200-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2190 max words - at ./dataset/shuffle-word-2190-count.jsonl\n",
      "Generated a single JSONL file with 914 samples (100 token repeat) - 270 max words - at ./dataset/shuffle-word-270-count.jsonl\n",
      "Generated JSONL file with - 2090 max words, 125 samples - at ./dataset/gen-word-2090-count.jsonl\n",
      "Generated JSONL file with - 1915 max words, 150 samples - at ./dataset/gen-word-1915-count.jsonl\n",
      "Generated a single JSONL file with 198 samples (100 token repeat) - 2310 max words - at ./dataset/shuffle-word-2310-count.jsonl\n",
      "Generated a single JSONL file with 199 samples (100 token repeat) - 2315 max words - at ./dataset/shuffle-word-2315-count.jsonl\n",
      "Generated a single JSONL file with 199 samples (100 token repeat) - 2385 max words - at ./dataset/shuffle-word-2385-count.jsonl\n",
      "Generated JSONL file with - 2320 max words, 125 samples - at ./dataset/gen-word-2320-count.jsonl\n",
      "Generated a single JSONL file with 1416 samples (100 token repeat) - 170 max words - at ./dataset/shuffle-word-170-count.jsonl\n",
      "Generated JSONL file with - 1860 max words, 150 samples - at ./dataset/gen-word-1860-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2395 max words - at ./dataset/shuffle-word-2395-count.jsonl\n",
      "Generated JSONL file with - 2095 max words, 125 samples - at ./dataset/gen-word-2095-count.jsonl\n",
      "Generated a single JSONL file with 110 samples (100 token repeat) - 2700 max words - at ./dataset/shuffle-word-2700-count.jsonl\n",
      "Generated a single JSONL file with 186 samples (100 token repeat) - 2420 max words - at ./dataset/shuffle-word-2420-count.jsonl\n",
      "Generated JSONL file with - 2310 max words, 125 samples - at ./dataset/gen-word-2310-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1010 max words - at ./dataset/shuffle-word-1010-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1845 max words - at ./dataset/shuffle-word-1845-count.jsonl\n",
      "Generated JSONL file with - 2260 max words, 125 samples - at ./dataset/gen-word-2260-count.jsonl\n",
      "Generated JSONL file with - 1800 max words, 150 samples - at ./dataset/gen-word-1800-count.jsonl\n",
      "Generated a single JSONL file with 400 samples (100 token repeat) - 785 max words - at ./dataset/shuffle-word-785-count.jsonl\n",
      "Generated JSONL file with - 2075 max words, 125 samples - at ./dataset/gen-word-2075-count.jsonl\n",
      "Generated a single JSONL file with 590 samples (100 token repeat) - 470 max words - at ./dataset/shuffle-word-470-count.jsonl\n",
      "Generated JSONL file with - 1320 max words, 150 samples - at ./dataset/gen-word-1320-count.jsonl\n",
      "Generated a single JSONL file with 115 samples (100 token repeat) - 2675 max words - at ./dataset/shuffle-word-2675-count.jsonl\n",
      "Generated JSONL file with - 1795 max words, 150 samples - at ./dataset/gen-word-1795-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 930 max words - at ./dataset/shuffle-word-930-count.jsonl\n",
      "Generated a single JSONL file with 106 samples (100 token repeat) - 2690 max words - at ./dataset/shuffle-word-2690-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2030 max words - at ./dataset/shuffle-word-2030-count.jsonl\n",
      "Generated JSONL file with - 545 max words, 150 samples - at ./dataset/gen-word-545-count.jsonl\n",
      "Generated a single JSONL file with 13064 samples (100 token repeat) - 20 max words - at ./dataset/shuffle-word-20-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1685 max words - at ./dataset/shuffle-word-1685-count.jsonl\n",
      "Generated JSONL file with - 1985 max words, 150 samples - at ./dataset/gen-word-1985-count.jsonl\n",
      "Generated a single JSONL file with 102 samples (100 token repeat) - 2745 max words - at ./dataset/shuffle-word-2745-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2035 max words - at ./dataset/shuffle-word-2035-count.jsonl\n",
      "Generated a single JSONL file with 185 samples (100 token repeat) - 2495 max words - at ./dataset/shuffle-word-2495-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1750 max words - at ./dataset/shuffle-word-1750-count.jsonl\n",
      "Generated JSONL file with - 2405 max words, 125 samples - at ./dataset/gen-word-2405-count.jsonl\n",
      "Generated JSONL file with - 2675 max words, 125 samples - at ./dataset/gen-word-2675-count.jsonl\n",
      "Generated JSONL file with - 1205 max words, 150 samples - at ./dataset/gen-word-1205-count.jsonl\n",
      "Generated JSONL file with - 2580 max words, 125 samples - at ./dataset/gen-word-2580-count.jsonl\n",
      "Generated a single JSONL file with 1908 samples (100 token repeat) - 115 max words - at ./dataset/shuffle-word-115-count.jsonl\n",
      "Generated JSONL file with - 2695 max words, 125 samples - at ./dataset/gen-word-2695-count.jsonl\n",
      "Generated a single JSONL file with 1359 samples (100 token repeat) - 190 max words - at ./dataset/shuffle-word-190-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1905 max words - at ./dataset/shuffle-word-1905-count.jsonl\n",
      "Generated JSONL file with - 2630 max words, 125 samples - at ./dataset/gen-word-2630-count.jsonl\n",
      "Generated a single JSONL file with 198 samples (100 token repeat) - 2390 max words - at ./dataset/shuffle-word-2390-count.jsonl\n",
      "Generated a single JSONL file with 1585 samples (100 token repeat) - 145 max words - at ./dataset/shuffle-word-145-count.jsonl\n",
      "Generated a single JSONL file with 702 samples (100 token repeat) - 370 max words - at ./dataset/shuffle-word-370-count.jsonl\n",
      "Generated JSONL file with - 2620 max words, 125 samples - at ./dataset/gen-word-2620-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1485 max words - at ./dataset/shuffle-word-1485-count.jsonl\n",
      "Generated a single JSONL file with 114 samples (100 token repeat) - 2630 max words - at ./dataset/shuffle-word-2630-count.jsonl\n",
      "Generated JSONL file with - 2700 max words, 125 samples - at ./dataset/gen-word-2700-count.jsonl\n",
      "Generated a single JSONL file with 700 samples (100 token repeat) - 355 max words - at ./dataset/shuffle-word-355-count.jsonl\n",
      "Generated a single JSONL file with 180 samples (100 token repeat) - 2490 max words - at ./dataset/shuffle-word-2490-count.jsonl\n",
      "Generated a single JSONL file with 585 samples (100 token repeat) - 495 max words - at ./dataset/shuffle-word-495-count.jsonl\n",
      "Generated JSONL file with - 2690 max words, 125 samples - at ./dataset/gen-word-2690-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1835 max words - at ./dataset/shuffle-word-1835-count.jsonl\n",
      "Generated a single JSONL file with 185 samples (100 token repeat) - 2425 max words - at ./dataset/shuffle-word-2425-count.jsonl\n",
      "Generated a single JSONL file with 199 samples (100 token repeat) - 2345 max words - at ./dataset/shuffle-word-2345-count.jsonl\n",
      "Generated JSONL file with - 2635 max words, 125 samples - at ./dataset/gen-word-2635-count.jsonl\n",
      "Generated a single JSONL file with 150 samples (100 token repeat) - 2570 max words - at ./dataset/shuffle-word-2570-count.jsonl\n",
      "Generated JSONL file with - 2425 max words, 125 samples - at ./dataset/gen-word-2425-count.jsonl\n",
      "Generated a single JSONL file with 199 samples (100 token repeat) - 2355 max words - at ./dataset/shuffle-word-2355-count.jsonl\n",
      "Generated a single JSONL file with 117 samples (100 token repeat) - 2695 max words - at ./dataset/shuffle-word-2695-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3050 max words - at ./dataset/shuffle-word-3050-count.jsonl\n",
      "Generated JSONL file with - 2045 max words, 125 samples - at ./dataset/gen-word-2045-count.jsonl\n",
      "Generated a single JSONL file with 102 samples (100 token repeat) - 2760 max words - at ./dataset/shuffle-word-2760-count.jsonl\n",
      "Generated JSONL file with - 2380 max words, 125 samples - at ./dataset/gen-word-2380-count.jsonl\n",
      "Generated JSONL file with - 2705 max words, 125 samples - at ./dataset/gen-word-2705-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2885 max words - at ./dataset/shuffle-word-2885-count.jsonl\n",
      "Generated JSONL file with - 1845 max words, 150 samples - at ./dataset/gen-word-1845-count.jsonl\n",
      "Generated JSONL file with - 2825 max words, 125 samples - at ./dataset/gen-word-2825-count.jsonl\n",
      "Generated a single JSONL file with 102 samples (100 token repeat) - 2705 max words - at ./dataset/shuffle-word-2705-count.jsonl\n",
      "Generated a single JSONL file with 114 samples (100 token repeat) - 2605 max words - at ./dataset/shuffle-word-2605-count.jsonl\n",
      "Generated JSONL file with - 645 max words, 150 samples - at ./dataset/gen-word-645-count.jsonl\n",
      "Generated JSONL file with - 2365 max words, 125 samples - at ./dataset/gen-word-2365-count.jsonl\n",
      "Generated JSONL file with - 3090 max words, 100 samples - at ./dataset/gen-word-3090-count.jsonl\n",
      "Generated JSONL file with - 2375 max words, 125 samples - at ./dataset/gen-word-2375-count.jsonl\n",
      "Generated JSONL file with - 2290 max words, 125 samples - at ./dataset/gen-word-2290-count.jsonl\n",
      "Generated a single JSONL file with 124 samples (100 token repeat) - 2650 max words - at ./dataset/shuffle-word-2650-count.jsonl\n",
      "Generated a single JSONL file with 122 samples (100 token repeat) - 2685 max words - at ./dataset/shuffle-word-2685-count.jsonl\n",
      "Generated a single JSONL file with 148 samples (100 token repeat) - 2575 max words - at ./dataset/shuffle-word-2575-count.jsonl\n",
      "Generated JSONL file with - 2325 max words, 125 samples - at ./dataset/gen-word-2325-count.jsonl\n",
      "Generated JSONL file with - 3095 max words, 100 samples - at ./dataset/gen-word-3095-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2170 max words - at ./dataset/shuffle-word-2170-count.jsonl\n",
      "Generated a single JSONL file with 160 samples (100 token repeat) - 2515 max words - at ./dataset/shuffle-word-2515-count.jsonl\n",
      "Generated JSONL file with - 2180 max words, 125 samples - at ./dataset/gen-word-2180-count.jsonl\n",
      "Generated JSONL file with - 2395 max words, 125 samples - at ./dataset/gen-word-2395-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1035 max words - at ./dataset/shuffle-word-1035-count.jsonl\n",
      "Generated JSONL file with - 2935 max words, 125 samples - at ./dataset/gen-word-2935-count.jsonl\n",
      "Generated a single JSONL file with 921 samples (100 token repeat) - 275 max words - at ./dataset/shuffle-word-275-count.jsonl\n",
      "Generated a single JSONL file with 156 samples (100 token repeat) - 2580 max words - at ./dataset/shuffle-word-2580-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3145 max words - at ./dataset/shuffle-word-3145-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3120 max words - at ./dataset/shuffle-word-3120-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3185 max words - at ./dataset/shuffle-word-3185-count.jsonl\n",
      "Generated a single JSONL file with 106 samples (100 token repeat) - 2730 max words - at ./dataset/shuffle-word-2730-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3130 max words - at ./dataset/shuffle-word-3130-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3080 max words - at ./dataset/shuffle-word-3080-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3225 max words - at ./dataset/shuffle-word-3225-count.jsonl\n",
      "Generated JSONL file with - 2745 max words, 125 samples - at ./dataset/gen-word-2745-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3155 max words - at ./dataset/shuffle-word-3155-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3450 max words - at ./dataset/shuffle-word-3450-count.jsonl\n",
      "Generated JSONL file with - 2680 max words, 125 samples - at ./dataset/gen-word-2680-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3515 max words - at ./dataset/shuffle-word-3515-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3520 max words - at ./dataset/shuffle-word-3520-count.jsonl\n",
      "Generated a single JSONL file with 1792 samples (100 token repeat) - 125 max words - at ./dataset/shuffle-word-125-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3005 max words - at ./dataset/shuffle-word-3005-count.jsonl\n",
      "Generated JSONL file with - 3315 max words, 100 samples - at ./dataset/gen-word-3315-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3095 max words - at ./dataset/shuffle-word-3095-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2825 max words - at ./dataset/shuffle-word-2825-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3115 max words - at ./dataset/shuffle-word-3115-count.jsonl\n",
      "Generated JSONL file with - 3160 max words, 100 samples - at ./dataset/gen-word-3160-count.jsonl\n",
      "Generated a single JSONL file with 591 samples (100 token repeat) - 435 max words - at ./dataset/shuffle-word-435-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1055 max words - at ./dataset/shuffle-word-1055-count.jsonl\n",
      "Generated JSONL file with - 1060 max words, 150 samples - at ./dataset/gen-word-1060-count.jsonl\n",
      "Generated a single JSONL file with 104 samples (100 token repeat) - 2755 max words - at ./dataset/shuffle-word-2755-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3565 max words - at ./dataset/shuffle-word-3565-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3350 max words - at ./dataset/shuffle-word-3350-count.jsonl\n",
      "Generated JSONL file with - 3350 max words, 100 samples - at ./dataset/gen-word-3350-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3180 max words - at ./dataset/shuffle-word-3180-count.jsonl\n",
      "Generated JSONL file with - 2760 max words, 125 samples - at ./dataset/gen-word-2760-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3065 max words - at ./dataset/shuffle-word-3065-count.jsonl\n",
      "Generated JSONL file with - 2510 max words, 125 samples - at ./dataset/gen-word-2510-count.jsonl\n",
      "Generated a single JSONL file with 55890 samples (100 token repeat) - 5 max words - at ./dataset/shuffle-word-5-count.jsonl\n",
      "Generated JSONL file with - 1555 max words, 150 samples - at ./dataset/gen-word-1555-count.jsonl\n",
      "Generated JSONL file with - 2235 max words, 125 samples - at ./dataset/gen-word-2235-count.jsonl\n",
      "Generated a single JSONL file with 190 samples (100 token repeat) - 2435 max words - at ./dataset/shuffle-word-2435-count.jsonl\n",
      "Generated a single JSONL file with 583 samples (100 token repeat) - 500 max words - at ./dataset/shuffle-word-500-count.jsonl\n",
      "Generated JSONL file with - 3010 max words, 100 samples - at ./dataset/gen-word-3010-count.jsonl\n",
      "Generated JSONL file with - 3500 max words, 100 samples - at ./dataset/gen-word-3500-count.jsonl\n",
      "Generated a single JSONL file with 251 samples (100 token repeat) - 1240 max words - at ./dataset/shuffle-word-1240-count.jsonl\n",
      "Generated JSONL file with - 2330 max words, 125 samples - at ./dataset/gen-word-2330-count.jsonl\n",
      "Generated JSONL file with - 2920 max words, 125 samples - at ./dataset/gen-word-2920-count.jsonl\n",
      "Generated JSONL file with - 3515 max words, 100 samples - at ./dataset/gen-word-3515-count.jsonl\n",
      "Generated a single JSONL file with 501 samples (100 token repeat) - 560 max words - at ./dataset/shuffle-word-560-count.jsonl\n",
      "Generated JSONL file with - 3495 max words, 100 samples - at ./dataset/gen-word-3495-count.jsonl\n",
      "Generated a single JSONL file with 101 samples (100 token repeat) - 2860 max words - at ./dataset/shuffle-word-2860-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3040 max words - at ./dataset/shuffle-word-3040-count.jsonl\n",
      "Generated JSONL file with - 1075 max words, 150 samples - at ./dataset/gen-word-1075-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 575 max words - at ./dataset/shuffle-word-575-count.jsonl\n",
      "Generated JSONL file with - 1180 max words, 150 samples - at ./dataset/gen-word-1180-count.jsonl\n",
      "Generated JSONL file with - 3295 max words, 100 samples - at ./dataset/gen-word-3295-count.jsonl\n",
      "Generated JSONL file with - 3110 max words, 100 samples - at ./dataset/gen-word-3110-count.jsonl\n",
      "Generated JSONL file with - 1170 max words, 150 samples - at ./dataset/gen-word-1170-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1030 max words - at ./dataset/shuffle-word-1030-count.jsonl\n",
      "Generated JSONL file with - 3430 max words, 100 samples - at ./dataset/gen-word-3430-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3505 max words - at ./dataset/shuffle-word-3505-count.jsonl\n",
      "Generated a single JSONL file with 1846 samples (100 token repeat) - 120 max words - at ./dataset/shuffle-word-120-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3535 max words - at ./dataset/shuffle-word-3535-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1710 max words - at ./dataset/shuffle-word-1710-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3195 max words - at ./dataset/shuffle-word-3195-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3355 max words - at ./dataset/shuffle-word-3355-count.jsonl\n",
      "Generated a single JSONL file with 600 samples (100 token repeat) - 405 max words - at ./dataset/shuffle-word-405-count.jsonl\n",
      "Generated a single JSONL file with 702 samples (100 token repeat) - 330 max words - at ./dataset/shuffle-word-330-count.jsonl\n",
      "Generated JSONL file with - 1440 max words, 150 samples - at ./dataset/gen-word-1440-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2930 max words - at ./dataset/shuffle-word-2930-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3100 max words - at ./dataset/shuffle-word-3100-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3560 max words - at ./dataset/shuffle-word-3560-count.jsonl\n",
      "Generated a single JSONL file with 500 samples (100 token repeat) - 545 max words - at ./dataset/shuffle-word-545-count.jsonl\n",
      "Generated a single JSONL file with 1052 samples (100 token repeat) - 210 max words - at ./dataset/shuffle-word-210-count.jsonl\n",
      "Generated a single JSONL file with 584 samples (100 token repeat) - 485 max words - at ./dataset/shuffle-word-485-count.jsonl\n",
      "Generated JSONL file with - 3270 max words, 100 samples - at ./dataset/gen-word-3270-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3215 max words - at ./dataset/shuffle-word-3215-count.jsonl\n",
      "Generated JSONL file with - 2655 max words, 125 samples - at ./dataset/gen-word-2655-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3230 max words - at ./dataset/shuffle-word-3230-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3280 max words - at ./dataset/shuffle-word-3280-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1515 max words - at ./dataset/shuffle-word-1515-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3250 max words - at ./dataset/shuffle-word-3250-count.jsonl\n",
      "Generated JSONL file with - 3525 max words, 100 samples - at ./dataset/gen-word-3525-count.jsonl\n",
      "Generated a single JSONL file with 704 samples (100 token repeat) - 340 max words - at ./dataset/shuffle-word-340-count.jsonl\n",
      "Generated JSONL file with - 3305 max words, 100 samples - at ./dataset/gen-word-3305-count.jsonl\n",
      "Generated JSONL file with - 3310 max words, 100 samples - at ./dataset/gen-word-3310-count.jsonl\n",
      "Generated a single JSONL file with 7570 samples (100 token repeat) - 35 max words - at ./dataset/shuffle-word-35-count.jsonl\n",
      "Generated JSONL file with - 3115 max words, 100 samples - at ./dataset/gen-word-3115-count.jsonl\n",
      "Generated a single JSONL file with 402 samples (100 token repeat) - 700 max words - at ./dataset/shuffle-word-700-count.jsonl\n",
      "Generated JSONL file with - 3175 max words, 100 samples - at ./dataset/gen-word-3175-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3270 max words - at ./dataset/shuffle-word-3270-count.jsonl\n",
      "Generated JSONL file with - 3480 max words, 100 samples - at ./dataset/gen-word-3480-count.jsonl\n",
      "Generated a single JSONL file with 587 samples (100 token repeat) - 480 max words - at ./dataset/shuffle-word-480-count.jsonl\n",
      "Generated JSONL file with - 1265 max words, 150 samples - at ./dataset/gen-word-1265-count.jsonl\n",
      "Generated JSONL file with - 3445 max words, 100 samples - at ./dataset/gen-word-3445-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3445 max words - at ./dataset/shuffle-word-3445-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3285 max words - at ./dataset/shuffle-word-3285-count.jsonl\n",
      "Generated JSONL file with - 3210 max words, 100 samples - at ./dataset/gen-word-3210-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3360 max words - at ./dataset/shuffle-word-3360-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1545 max words - at ./dataset/shuffle-word-1545-count.jsonl\n",
      "Generated JSONL file with - 1090 max words, 150 samples - at ./dataset/gen-word-1090-count.jsonl\n",
      "Generated a single JSONL file with 8738 samples (100 token repeat) - 30 max words - at ./dataset/shuffle-word-30-count.jsonl\n",
      "Generated JSONL file with - 3260 max words, 100 samples - at ./dataset/gen-word-3260-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3385 max words - at ./dataset/shuffle-word-3385-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1450 max words - at ./dataset/shuffle-word-1450-count.jsonl\n",
      "Generated a single JSONL file with 706 samples (100 token repeat) - 320 max words - at ./dataset/shuffle-word-320-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3260 max words - at ./dataset/shuffle-word-3260-count.jsonl\n",
      "Generated JSONL file with - 640 max words, 150 samples - at ./dataset/gen-word-640-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3595 max words - at ./dataset/shuffle-word-3595-count.jsonl\n",
      "Generated JSONL file with - 1085 max words, 150 samples - at ./dataset/gen-word-1085-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3240 max words - at ./dataset/shuffle-word-3240-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3310 max words - at ./dataset/shuffle-word-3310-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3290 max words - at ./dataset/shuffle-word-3290-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3340 max words - at ./dataset/shuffle-word-3340-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3370 max words - at ./dataset/shuffle-word-3370-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3665 max words - at ./dataset/shuffle-word-3665-count.jsonl\n",
      "Generated JSONL file with - 1305 max words, 150 samples - at ./dataset/gen-word-1305-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3655 max words - at ./dataset/shuffle-word-3655-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1745 max words - at ./dataset/shuffle-word-1745-count.jsonl\n",
      "Generated a single JSONL file with 299 samples (100 token repeat) - 1185 max words - at ./dataset/shuffle-word-1185-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3605 max words - at ./dataset/shuffle-word-3605-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3670 max words - at ./dataset/shuffle-word-3670-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3615 max words - at ./dataset/shuffle-word-3615-count.jsonl\n",
      "Generated JSONL file with - 2410 max words, 125 samples - at ./dataset/gen-word-2410-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3630 max words - at ./dataset/shuffle-word-3630-count.jsonl\n",
      "Generated a single JSONL file with 497 samples (100 token repeat) - 570 max words - at ./dataset/shuffle-word-570-count.jsonl\n",
      "Generated JSONL file with - 1340 max words, 150 samples - at ./dataset/gen-word-1340-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1670 max words - at ./dataset/shuffle-word-1670-count.jsonl\n",
      "Generated JSONL file with - 1445 max words, 150 samples - at ./dataset/gen-word-1445-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3600 max words - at ./dataset/shuffle-word-3600-count.jsonl\n",
      "Generated JSONL file with - 1530 max words, 150 samples - at ./dataset/gen-word-1530-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1020 max words - at ./dataset/shuffle-word-1020-count.jsonl\n",
      "Generated JSONL file with - 1010 max words, 150 samples - at ./dataset/gen-word-1010-count.jsonl\n",
      "Generated JSONL file with - 3595 max words, 100 samples - at ./dataset/gen-word-3595-count.jsonl\n",
      "Generated JSONL file with - 3050 max words, 100 samples - at ./dataset/gen-word-3050-count.jsonl\n",
      "Generated a single JSONL file with 406 samples (100 token repeat) - 630 max words - at ./dataset/shuffle-word-630-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3570 max words - at ./dataset/shuffle-word-3570-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3330 max words - at ./dataset/shuffle-word-3330-count.jsonl\n",
      "Generated JSONL file with - 765 max words, 150 samples - at ./dataset/gen-word-765-count.jsonl\n",
      "Generated JSONL file with - 3600 max words, 100 samples - at ./dataset/gen-word-3600-count.jsonl\n",
      "Generated JSONL file with - 3225 max words, 100 samples - at ./dataset/gen-word-3225-count.jsonl\n",
      "Generated a single JSONL file with 586 samples (100 token repeat) - 450 max words - at ./dataset/shuffle-word-450-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2895 max words - at ./dataset/shuffle-word-2895-count.jsonl\n",
      "Generated JSONL file with - 3620 max words, 100 samples - at ./dataset/gen-word-3620-count.jsonl\n",
      "Generated a single JSONL file with 251 samples (100 token repeat) - 1235 max words - at ./dataset/shuffle-word-1235-count.jsonl\n",
      "Generated JSONL file with - 3385 max words, 100 samples - at ./dataset/gen-word-3385-count.jsonl\n",
      "Generated JSONL file with - 3675 max words, 100 samples - at ./dataset/gen-word-3675-count.jsonl\n",
      "Generated JSONL file with - 1355 max words, 150 samples - at ./dataset/gen-word-1355-count.jsonl\n",
      "Generated a single JSONL file with 498 samples (100 token repeat) - 505 max words - at ./dataset/shuffle-word-505-count.jsonl\n",
      "Generated JSONL file with - 3155 max words, 100 samples - at ./dataset/gen-word-3155-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3585 max words - at ./dataset/shuffle-word-3585-count.jsonl\n",
      "Generated JSONL file with - 2590 max words, 125 samples - at ./dataset/gen-word-2590-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1860 max words - at ./dataset/shuffle-word-1860-count.jsonl\n",
      "Generated JSONL file with - 3650 max words, 100 samples - at ./dataset/gen-word-3650-count.jsonl\n",
      "Generated JSONL file with - 3635 max words, 100 samples - at ./dataset/gen-word-3635-count.jsonl\n",
      "Generated JSONL file with - 3300 max words, 100 samples - at ./dataset/gen-word-3300-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3090 max words - at ./dataset/shuffle-word-3090-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3620 max words - at ./dataset/shuffle-word-3620-count.jsonl\n",
      "Generated a single JSONL file with 404 samples (100 token repeat) - 695 max words - at ./dataset/shuffle-word-695-count.jsonl\n",
      "Generated JSONL file with - 1890 max words, 150 samples - at ./dataset/gen-word-1890-count.jsonl\n",
      "Generated JSONL file with - 2865 max words, 125 samples - at ./dataset/gen-word-2865-count.jsonl\n",
      "Generated JSONL file with - 3420 max words, 100 samples - at ./dataset/gen-word-3420-count.jsonl\n",
      "Generated JSONL file with - 3320 max words, 100 samples - at ./dataset/gen-word-3320-count.jsonl\n",
      "Generated JSONL file with - 3460 max words, 100 samples - at ./dataset/gen-word-3460-count.jsonl\n",
      "Generated JSONL file with - 3540 max words, 100 samples - at ./dataset/gen-word-3540-count.jsonl\n",
      "Generated JSONL file with - 1365 max words, 150 samples - at ./dataset/gen-word-1365-count.jsonl\n",
      "Generated a single JSONL file with 1679 samples (100 token repeat) - 135 max words - at ./dataset/shuffle-word-135-count.jsonl\n",
      "Generated JSONL file with - 3655 max words, 100 samples - at ./dataset/gen-word-3655-count.jsonl\n",
      "Generated JSONL file with - 1165 max words, 150 samples - at ./dataset/gen-word-1165-count.jsonl\n",
      "Generated JSONL file with - 3290 max words, 100 samples - at ./dataset/gen-word-3290-count.jsonl\n",
      "Generated JSONL file with - 1700 max words, 150 samples - at ./dataset/gen-word-1700-count.jsonl\n",
      "Generated JSONL file with - 1415 max words, 150 samples - at ./dataset/gen-word-1415-count.jsonl\n",
      "Generated JSONL file with - 3605 max words, 100 samples - at ./dataset/gen-word-3605-count.jsonl\n",
      "Generated JSONL file with - 3610 max words, 100 samples - at ./dataset/gen-word-3610-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2970 max words - at ./dataset/shuffle-word-2970-count.jsonl\n",
      "Generated JSONL file with - 1175 max words, 150 samples - at ./dataset/gen-word-1175-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3085 max words - at ./dataset/shuffle-word-3085-count.jsonl\n",
      "Generated JSONL file with - 1870 max words, 150 samples - at ./dataset/gen-word-1870-count.jsonl\n",
      "Generated JSONL file with - 1395 max words, 150 samples - at ./dataset/gen-word-1395-count.jsonl\n",
      "Generated JSONL file with - 1420 max words, 150 samples - at ./dataset/gen-word-1420-count.jsonl\n",
      "Generated a single JSONL file with 204 samples (100 token repeat) - 1310 max words - at ./dataset/shuffle-word-1310-count.jsonl\n",
      "Generated JSONL file with - 3670 max words, 100 samples - at ./dataset/gen-word-3670-count.jsonl\n",
      "Generated a single JSONL file with 201 samples (100 token repeat) - 1380 max words - at ./dataset/shuffle-word-1380-count.jsonl\n",
      "Generated JSONL file with - 1135 max words, 150 samples - at ./dataset/gen-word-1135-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3695 max words - at ./dataset/shuffle-word-3695-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3800 max words - at ./dataset/shuffle-word-3800-count.jsonl\n",
      "Generated JSONL file with - 3325 max words, 100 samples - at ./dataset/gen-word-3325-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3405 max words - at ./dataset/shuffle-word-3405-count.jsonl\n",
      "Generated a single JSONL file with 120 samples (100 token repeat) - 2655 max words - at ./dataset/shuffle-word-2655-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3650 max words - at ./dataset/shuffle-word-3650-count.jsonl\n",
      "Generated JSONL file with - 1360 max words, 150 samples - at ./dataset/gen-word-1360-count.jsonl\n",
      "Generated JSONL file with - 1105 max words, 150 samples - at ./dataset/gen-word-1105-count.jsonl\n",
      "Generated JSONL file with - 1150 max words, 150 samples - at ./dataset/gen-word-1150-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2805 max words - at ./dataset/shuffle-word-2805-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3320 max words - at ./dataset/shuffle-word-3320-count.jsonl\n",
      "Generated JSONL file with - 2430 max words, 125 samples - at ./dataset/gen-word-2430-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3700 max words - at ./dataset/shuffle-word-3700-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3705 max words - at ./dataset/shuffle-word-3705-count.jsonl\n",
      "Generated a single JSONL file with 1001 samples (100 token repeat) - 225 max words - at ./dataset/shuffle-word-225-count.jsonl\n",
      "Generated JSONL file with - 1650 max words, 150 samples - at ./dataset/gen-word-1650-count.jsonl\n",
      "Generated a single JSONL file with 2676 samples (100 token repeat) - 100 max words - at ./dataset/shuffle-word-100-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1560 max words - at ./dataset/shuffle-word-1560-count.jsonl\n",
      "Generated JSONL file with - 3245 max words, 100 samples - at ./dataset/gen-word-3245-count.jsonl\n",
      "Generated JSONL file with - 1470 max words, 150 samples - at ./dataset/gen-word-1470-count.jsonl\n",
      "Generated a single JSONL file with 1395 samples (100 token repeat) - 175 max words - at ./dataset/shuffle-word-175-count.jsonl\n",
      "Generated a single JSONL file with 104 samples (100 token repeat) - 2780 max words - at ./dataset/shuffle-word-2780-count.jsonl\n",
      "Generated JSONL file with - 1140 max words, 150 samples - at ./dataset/gen-word-1140-count.jsonl\n",
      "Generated JSONL file with - 1110 max words, 150 samples - at ./dataset/gen-word-1110-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3200 max words - at ./dataset/shuffle-word-3200-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3190 max words - at ./dataset/shuffle-word-3190-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3755 max words - at ./dataset/shuffle-word-3755-count.jsonl\n",
      "Generated JSONL file with - 3335 max words, 100 samples - at ./dataset/gen-word-3335-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3395 max words - at ./dataset/shuffle-word-3395-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3750 max words - at ./dataset/shuffle-word-3750-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3725 max words - at ./dataset/shuffle-word-3725-count.jsonl\n",
      "Generated JSONL file with - 3040 max words, 100 samples - at ./dataset/gen-word-3040-count.jsonl\n",
      "Generated JSONL file with - 1720 max words, 150 samples - at ./dataset/gen-word-1720-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1600 max words - at ./dataset/shuffle-word-1600-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1715 max words - at ./dataset/shuffle-word-1715-count.jsonl\n",
      "Generated JSONL file with - 1535 max words, 150 samples - at ./dataset/gen-word-1535-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3795 max words - at ./dataset/shuffle-word-3795-count.jsonl\n",
      "Generated JSONL file with - 1750 max words, 150 samples - at ./dataset/gen-word-1750-count.jsonl\n",
      "Generated JSONL file with - 1990 max words, 150 samples - at ./dataset/gen-word-1990-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3760 max words - at ./dataset/shuffle-word-3760-count.jsonl\n",
      "Generated JSONL file with - 1055 max words, 150 samples - at ./dataset/gen-word-1055-count.jsonl\n",
      "Generated JSONL file with - 3070 max words, 100 samples - at ./dataset/gen-word-3070-count.jsonl\n",
      "Generated JSONL file with - 2150 max words, 125 samples - at ./dataset/gen-word-2150-count.jsonl\n",
      "Generated JSONL file with - 3630 max words, 100 samples - at ./dataset/gen-word-3630-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1575 max words - at ./dataset/shuffle-word-1575-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1535 max words - at ./dataset/shuffle-word-1535-count.jsonl\n",
      "Generated JSONL file with - 3265 max words, 100 samples - at ./dataset/gen-word-3265-count.jsonl\n",
      "Generated JSONL file with - 655 max words, 150 samples - at ./dataset/gen-word-655-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3715 max words - at ./dataset/shuffle-word-3715-count.jsonl\n",
      "Generated JSONL file with - 3805 max words, 100 samples - at ./dataset/gen-word-3805-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 960 max words - at ./dataset/shuffle-word-960-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2015 max words - at ./dataset/shuffle-word-2015-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3710 max words - at ./dataset/shuffle-word-3710-count.jsonl\n",
      "Generated JSONL file with - 3765 max words, 100 samples - at ./dataset/gen-word-3765-count.jsonl\n",
      "Generated JSONL file with - 950 max words, 150 samples - at ./dataset/gen-word-950-count.jsonl\n",
      "Generated JSONL file with - 3800 max words, 100 samples - at ./dataset/gen-word-3800-count.jsonl\n",
      "Generated JSONL file with - 1675 max words, 150 samples - at ./dataset/gen-word-1675-count.jsonl\n",
      "Generated JSONL file with - 1425 max words, 150 samples - at ./dataset/gen-word-1425-count.jsonl\n",
      "Generated JSONL file with - 2135 max words, 125 samples - at ./dataset/gen-word-2135-count.jsonl\n",
      "Generated JSONL file with - 1475 max words, 150 samples - at ./dataset/gen-word-1475-count.jsonl\n",
      "Generated a single JSONL file with 199 samples (100 token repeat) - 2250 max words - at ./dataset/shuffle-word-2250-count.jsonl\n",
      "Generated JSONL file with - 3705 max words, 100 samples - at ./dataset/gen-word-3705-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3685 max words - at ./dataset/shuffle-word-3685-count.jsonl\n",
      "Generated a single JSONL file with 298 samples (100 token repeat) - 1180 max words - at ./dataset/shuffle-word-1180-count.jsonl\n",
      "Generated JSONL file with - 3745 max words, 100 samples - at ./dataset/gen-word-3745-count.jsonl\n",
      "Generated JSONL file with - 1710 max words, 150 samples - at ./dataset/gen-word-1710-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1615 max words - at ./dataset/shuffle-word-1615-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3680 max words - at ./dataset/shuffle-word-3680-count.jsonl\n",
      "Generated a single JSONL file with 298 samples (100 token repeat) - 1130 max words - at ./dataset/shuffle-word-1130-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3735 max words - at ./dataset/shuffle-word-3735-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1890 max words - at ./dataset/shuffle-word-1890-count.jsonl\n",
      "Generated JSONL file with - 1130 max words, 150 samples - at ./dataset/gen-word-1130-count.jsonl\n",
      "Generated JSONL file with - 3645 max words, 100 samples - at ./dataset/gen-word-3645-count.jsonl\n",
      "Generated JSONL file with - 1290 max words, 150 samples - at ./dataset/gen-word-1290-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1655 max words - at ./dataset/shuffle-word-1655-count.jsonl\n",
      "Generated JSONL file with - 2595 max words, 125 samples - at ./dataset/gen-word-2595-count.jsonl\n",
      "Generated JSONL file with - 1095 max words, 150 samples - at ./dataset/gen-word-1095-count.jsonl\n",
      "Generated a single JSONL file with 1503 samples (100 token repeat) - 155 max words - at ./dataset/shuffle-word-155-count.jsonl\n",
      "Generated JSONL file with - 3680 max words, 100 samples - at ./dataset/gen-word-3680-count.jsonl\n",
      "Generated JSONL file with - 1390 max words, 150 samples - at ./dataset/gen-word-1390-count.jsonl\n",
      "Generated a single JSONL file with 104 samples (100 token repeat) - 2750 max words - at ./dataset/shuffle-word-2750-count.jsonl\n",
      "Generated JSONL file with - 1575 max words, 150 samples - at ./dataset/gen-word-1575-count.jsonl\n",
      "Generated JSONL file with - 1580 max words, 150 samples - at ./dataset/gen-word-1580-count.jsonl\n",
      "Generated a single JSONL file with 203 samples (100 token repeat) - 1325 max words - at ./dataset/shuffle-word-1325-count.jsonl\n",
      "Generated JSONL file with - 1810 max words, 150 samples - at ./dataset/gen-word-1810-count.jsonl\n",
      "Generated JSONL file with - 2560 max words, 125 samples - at ./dataset/gen-word-2560-count.jsonl\n",
      "Generated a single JSONL file with 256 samples (100 token repeat) - 1285 max words - at ./dataset/shuffle-word-1285-count.jsonl\n",
      "Generated JSONL file with - 1250 max words, 150 samples - at ./dataset/gen-word-1250-count.jsonl\n",
      "Generated JSONL file with - 3735 max words, 100 samples - at ./dataset/gen-word-3735-count.jsonl\n",
      "Generated JSONL file with - 1235 max words, 150 samples - at ./dataset/gen-word-1235-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1995 max words - at ./dataset/shuffle-word-1995-count.jsonl\n",
      "Generated JSONL file with - 3775 max words, 100 samples - at ./dataset/gen-word-3775-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1840 max words - at ./dataset/shuffle-word-1840-count.jsonl\n",
      "Generated JSONL file with - 595 max words, 150 samples - at ./dataset/gen-word-595-count.jsonl\n",
      "Generated JSONL file with - 3715 max words, 100 samples - at ./dataset/gen-word-3715-count.jsonl\n",
      "Generated JSONL file with - 3720 max words, 100 samples - at ./dataset/gen-word-3720-count.jsonl\n",
      "Generated JSONL file with - 1640 max words, 150 samples - at ./dataset/gen-word-1640-count.jsonl\n",
      "Generated JSONL file with - 1505 max words, 150 samples - at ./dataset/gen-word-1505-count.jsonl\n",
      "Generated JSONL file with - 2770 max words, 125 samples - at ./dataset/gen-word-2770-count.jsonl\n",
      "Generated JSONL file with - 1210 max words, 150 samples - at ./dataset/gen-word-1210-count.jsonl\n",
      "Generated a single JSONL file with 590 samples (100 token repeat) - 425 max words - at ./dataset/shuffle-word-425-count.jsonl\n",
      "Generated JSONL file with - 2455 max words, 125 samples - at ./dataset/gen-word-2455-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1525 max words - at ./dataset/shuffle-word-1525-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3125 max words - at ./dataset/shuffle-word-3125-count.jsonl\n",
      "Generated JSONL file with - 2835 max words, 125 samples - at ./dataset/gen-word-2835-count.jsonl\n",
      "Generated a single JSONL file with 26068 samples (100 token repeat) - 10 max words - at ./dataset/shuffle-word-10-count.jsonl\n",
      "Generated JSONL file with - 2860 max words, 125 samples - at ./dataset/gen-word-2860-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1850 max words - at ./dataset/shuffle-word-1850-count.jsonl\n",
      "Generated a single JSONL file with 202 samples (100 token repeat) - 1365 max words - at ./dataset/shuffle-word-1365-count.jsonl\n",
      "Generated JSONL file with - 1220 max words, 150 samples - at ./dataset/gen-word-1220-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1015 max words - at ./dataset/shuffle-word-1015-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3875 max words - at ./dataset/shuffle-word-3875-count.jsonl\n",
      "Generated a single JSONL file with 299 samples (100 token repeat) - 1175 max words - at ./dataset/shuffle-word-1175-count.jsonl\n",
      "Generated a single JSONL file with 1441 samples (100 token repeat) - 165 max words - at ./dataset/shuffle-word-165-count.jsonl\n",
      "Generated a single JSONL file with 149 samples (100 token repeat) - 2595 max words - at ./dataset/shuffle-word-2595-count.jsonl\n",
      "Generated JSONL file with - 1460 max words, 150 samples - at ./dataset/gen-word-1460-count.jsonl\n",
      "Generated a single JSONL file with 500 samples (100 token repeat) - 555 max words - at ./dataset/shuffle-word-555-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3855 max words - at ./dataset/shuffle-word-3855-count.jsonl\n",
      "Generated a single JSONL file with 1094 samples (100 token repeat) - 205 max words - at ./dataset/shuffle-word-205-count.jsonl\n",
      "Generated JSONL file with - 1255 max words, 150 samples - at ./dataset/gen-word-1255-count.jsonl\n",
      "Generated JSONL file with - 1765 max words, 150 samples - at ./dataset/gen-word-1765-count.jsonl\n",
      "Generated a single JSONL file with 189 samples (100 token repeat) - 2465 max words - at ./dataset/shuffle-word-2465-count.jsonl\n",
      "Generated a single JSONL file with 205 samples (100 token repeat) - 1320 max words - at ./dataset/shuffle-word-1320-count.jsonl\n",
      "Generated a single JSONL file with 298 samples (100 token repeat) - 1105 max words - at ./dataset/shuffle-word-1105-count.jsonl\n",
      "Generated JSONL file with - 1660 max words, 150 samples - at ./dataset/gen-word-1660-count.jsonl\n",
      "Generated JSONL file with - 1590 max words, 150 samples - at ./dataset/gen-word-1590-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1505 max words - at ./dataset/shuffle-word-1505-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1625 max words - at ./dataset/shuffle-word-1625-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3880 max words - at ./dataset/shuffle-word-3880-count.jsonl\n",
      "Generated JSONL file with - 1050 max words, 150 samples - at ./dataset/gen-word-1050-count.jsonl\n",
      "Generated JSONL file with - 2200 max words, 125 samples - at ./dataset/gen-word-2200-count.jsonl\n",
      "Generated JSONL file with - 3690 max words, 100 samples - at ./dataset/gen-word-3690-count.jsonl\n",
      "Generated a single JSONL file with 101 samples (100 token repeat) - 2880 max words - at ./dataset/shuffle-word-2880-count.jsonl\n",
      "Generated JSONL file with - 1995 max words, 150 samples - at ./dataset/gen-word-1995-count.jsonl\n",
      "Generated JSONL file with - 1435 max words, 150 samples - at ./dataset/gen-word-1435-count.jsonl\n",
      "Generated a single JSONL file with 10607 samples (100 token repeat) - 25 max words - at ./dataset/shuffle-word-25-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1070 max words - at ./dataset/shuffle-word-1070-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1480 max words - at ./dataset/shuffle-word-1480-count.jsonl\n",
      "Generated JSONL file with - 1155 max words, 150 samples - at ./dataset/gen-word-1155-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1530 max words - at ./dataset/shuffle-word-1530-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1665 max words - at ./dataset/shuffle-word-1665-count.jsonl\n",
      "Generated a single JSONL file with 2783 samples (100 token repeat) - 95 max words - at ./dataset/shuffle-word-95-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1810 max words - at ./dataset/shuffle-word-1810-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1005 max words - at ./dataset/shuffle-word-1005-count.jsonl\n",
      "Generated JSONL file with - 2740 max words, 125 samples - at ./dataset/gen-word-2740-count.jsonl\n",
      "Generated JSONL file with - 1275 max words, 150 samples - at ./dataset/gen-word-1275-count.jsonl\n",
      "Generated JSONL file with - 1215 max words, 150 samples - at ./dataset/gen-word-1215-count.jsonl\n",
      "Generated JSONL file with - 1410 max words, 150 samples - at ./dataset/gen-word-1410-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1060 max words - at ./dataset/shuffle-word-1060-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1475 max words - at ./dataset/shuffle-word-1475-count.jsonl\n",
      "Generated JSONL file with - 1570 max words, 150 samples - at ./dataset/gen-word-1570-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1805 max words - at ./dataset/shuffle-word-1805-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1580 max words - at ./dataset/shuffle-word-1580-count.jsonl\n",
      "Generated JSONL file with - 3910 max words, 100 samples - at ./dataset/gen-word-3910-count.jsonl\n",
      "Generated JSONL file with - 1770 max words, 150 samples - at ./dataset/gen-word-1770-count.jsonl\n",
      "Generated JSONL file with - 1400 max words, 150 samples - at ./dataset/gen-word-1400-count.jsonl\n",
      "Generated JSONL file with - 1310 max words, 150 samples - at ./dataset/gen-word-1310-count.jsonl\n",
      "Generated JSONL file with - 3230 max words, 100 samples - at ./dataset/gen-word-3230-count.jsonl\n",
      "Generated a single JSONL file with 249 samples (100 token repeat) - 1225 max words - at ./dataset/shuffle-word-1225-count.jsonl\n",
      "Generated JSONL file with - 3750 max words, 100 samples - at ./dataset/gen-word-3750-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1690 max words - at ./dataset/shuffle-word-1690-count.jsonl\n",
      "Generated JSONL file with - 3005 max words, 100 samples - at ./dataset/gen-word-3005-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2135 max words - at ./dataset/shuffle-word-2135-count.jsonl\n",
      "Generated JSONL file with - 3640 max words, 100 samples - at ./dataset/gen-word-3640-count.jsonl\n",
      "Generated a single JSONL file with 298 samples (100 token repeat) - 1190 max words - at ./dataset/shuffle-word-1190-count.jsonl\n",
      "Generated a single JSONL file with 185 samples (100 token repeat) - 2500 max words - at ./dataset/shuffle-word-2500-count.jsonl\n",
      "Generated JSONL file with - 3895 max words, 100 samples - at ./dataset/gen-word-3895-count.jsonl\n",
      "Generated JSONL file with - 3055 max words, 100 samples - at ./dataset/gen-word-3055-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3840 max words - at ./dataset/shuffle-word-3840-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1000 max words - at ./dataset/shuffle-word-1000-count.jsonl\n",
      "Generated a single JSONL file with 251 samples (100 token repeat) - 1260 max words - at ./dataset/shuffle-word-1260-count.jsonl\n",
      "Generated a single JSONL file with 199 samples (100 token repeat) - 2360 max words - at ./dataset/shuffle-word-2360-count.jsonl\n",
      "Generated JSONL file with - 3840 max words, 100 samples - at ./dataset/gen-word-3840-count.jsonl\n",
      "Generated JSONL file with - 3685 max words, 100 samples - at ./dataset/gen-word-3685-count.jsonl\n",
      "Generated a single JSONL file with 251 samples (100 token repeat) - 1300 max words - at ./dataset/shuffle-word-1300-count.jsonl\n",
      "Generated a single JSONL file with 254 samples (100 token repeat) - 1210 max words - at ./dataset/shuffle-word-1210-count.jsonl\n",
      "Generated a single JSONL file with 246 samples (100 token repeat) - 1255 max words - at ./dataset/shuffle-word-1255-count.jsonl\n",
      "Generated JSONL file with - 3860 max words, 100 samples - at ./dataset/gen-word-3860-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1150 max words - at ./dataset/shuffle-word-1150-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1455 max words - at ./dataset/shuffle-word-1455-count.jsonl\n",
      "Generated JSONL file with - 3565 max words, 100 samples - at ./dataset/gen-word-3565-count.jsonl\n",
      "Generated a single JSONL file with 259 samples (100 token repeat) - 1280 max words - at ./dataset/shuffle-word-1280-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1495 max words - at ./dataset/shuffle-word-1495-count.jsonl\n",
      "Generated JSONL file with - 1270 max words, 150 samples - at ./dataset/gen-word-1270-count.jsonl\n",
      "Generated a single JSONL file with 152 samples (100 token repeat) - 2565 max words - at ./dataset/shuffle-word-2565-count.jsonl\n",
      "Generated JSONL file with - 1070 max words, 150 samples - at ./dataset/gen-word-1070-count.jsonl\n",
      "Generated JSONL file with - 1510 max words, 150 samples - at ./dataset/gen-word-1510-count.jsonl\n",
      "Generated JSONL file with - 3590 max words, 100 samples - at ./dataset/gen-word-3590-count.jsonl\n",
      "Generated a single JSONL file with 183 samples (100 token repeat) - 2470 max words - at ./dataset/shuffle-word-2470-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1415 max words - at ./dataset/shuffle-word-1415-count.jsonl\n",
      "Generated JSONL file with - 1385 max words, 150 samples - at ./dataset/gen-word-1385-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3890 max words - at ./dataset/shuffle-word-3890-count.jsonl\n",
      "Generated JSONL file with - 3710 max words, 100 samples - at ./dataset/gen-word-3710-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3905 max words - at ./dataset/shuffle-word-3905-count.jsonl\n",
      "Generated a single JSONL file with 298 samples (100 token repeat) - 1170 max words - at ./dataset/shuffle-word-1170-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1975 max words - at ./dataset/shuffle-word-1975-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1780 max words - at ./dataset/shuffle-word-1780-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3150 max words - at ./dataset/shuffle-word-3150-count.jsonl\n",
      "Generated JSONL file with - 1615 max words, 150 samples - at ./dataset/gen-word-1615-count.jsonl\n",
      "Generated JSONL file with - 2990 max words, 125 samples - at ./dataset/gen-word-2990-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3410 max words - at ./dataset/shuffle-word-3410-count.jsonl\n",
      "Generated JSONL file with - 1030 max words, 150 samples - at ./dataset/gen-word-1030-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1510 max words - at ./dataset/shuffle-word-1510-count.jsonl\n",
      "Generated a single JSONL file with 248 samples (100 token repeat) - 1270 max words - at ./dataset/shuffle-word-1270-count.jsonl\n",
      "Generated JSONL file with - 1695 max words, 150 samples - at ./dataset/gen-word-1695-count.jsonl\n",
      "Generated JSONL file with - 1370 max words, 150 samples - at ./dataset/gen-word-1370-count.jsonl\n",
      "Generated JSONL file with - 2830 max words, 125 samples - at ./dataset/gen-word-2830-count.jsonl\n",
      "Generated a single JSONL file with 401 samples (100 token repeat) - 625 max words - at ./dataset/shuffle-word-625-count.jsonl\n",
      "Generated JSONL file with - 2955 max words, 125 samples - at ./dataset/gen-word-2955-count.jsonl\n",
      "Generated a single JSONL file with 500 samples (100 token repeat) - 590 max words - at ./dataset/shuffle-word-590-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3975 max words - at ./dataset/shuffle-word-3975-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1770 max words - at ./dataset/shuffle-word-1770-count.jsonl\n",
      "Generated JSONL file with - 1335 max words, 150 samples - at ./dataset/gen-word-1335-count.jsonl\n",
      "Generated JSONL file with - 1260 max words, 150 samples - at ./dataset/gen-word-1260-count.jsonl\n",
      "Generated JSONL file with - 1245 max words, 150 samples - at ./dataset/gen-word-1245-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3965 max words - at ./dataset/shuffle-word-3965-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3980 max words - at ./dataset/shuffle-word-3980-count.jsonl\n",
      "Generated a single JSONL file with 298 samples (100 token repeat) - 1115 max words - at ./dataset/shuffle-word-1115-count.jsonl\n",
      "Generated JSONL file with - 1295 max words, 150 samples - at ./dataset/gen-word-1295-count.jsonl\n",
      "Generated a single JSONL file with 202 samples (100 token repeat) - 1385 max words - at ./dataset/shuffle-word-1385-count.jsonl\n",
      "Generated JSONL file with - 1200 max words, 150 samples - at ./dataset/gen-word-1200-count.jsonl\n",
      "Generated JSONL file with - 2295 max words, 125 samples - at ./dataset/gen-word-2295-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2155 max words - at ./dataset/shuffle-word-2155-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3945 max words - at ./dataset/shuffle-word-3945-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1700 max words - at ./dataset/shuffle-word-1700-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3470 max words - at ./dataset/shuffle-word-3470-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1090 max words - at ./dataset/shuffle-word-1090-count.jsonl\n",
      "Generated JSONL file with - 2020 max words, 125 samples - at ./dataset/gen-word-2020-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2160 max words - at ./dataset/shuffle-word-2160-count.jsonl\n",
      "Generated a single JSONL file with 296 samples (100 token repeat) - 1125 max words - at ./dataset/shuffle-word-1125-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3970 max words - at ./dataset/shuffle-word-3970-count.jsonl\n",
      "Generated a single JSONL file with 205 samples (100 token repeat) - 1335 max words - at ./dataset/shuffle-word-1335-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2240 max words - at ./dataset/shuffle-word-2240-count.jsonl\n",
      "Generated JSONL file with - 2070 max words, 125 samples - at ./dataset/gen-word-2070-count.jsonl\n",
      "Generated a single JSONL file with 703 samples (100 token repeat) - 400 max words - at ./dataset/shuffle-word-400-count.jsonl\n",
      "Generated a single JSONL file with 198 samples (100 token repeat) - 2305 max words - at ./dataset/shuffle-word-2305-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2180 max words - at ./dataset/shuffle-word-2180-count.jsonl\n",
      "Generated JSONL file with - 3130 max words, 100 samples - at ./dataset/gen-word-3130-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 980 max words - at ./dataset/shuffle-word-980-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3590 max words - at ./dataset/shuffle-word-3590-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3985 max words - at ./dataset/shuffle-word-3985-count.jsonl\n",
      "Generated JSONL file with - 2140 max words, 125 samples - at ./dataset/gen-word-2140-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2275 max words - at ./dataset/shuffle-word-2275-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2235 max words - at ./dataset/shuffle-word-2235-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1680 max words - at ./dataset/shuffle-word-1680-count.jsonl\n",
      "Generated JSONL file with - 3380 max words, 100 samples - at ./dataset/gen-word-3380-count.jsonl\n",
      "Generated JSONL file with - 1300 max words, 150 samples - at ./dataset/gen-word-1300-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1460 max words - at ./dataset/shuffle-word-1460-count.jsonl\n",
      "Generated JSONL file with - 3185 max words, 100 samples - at ./dataset/gen-word-3185-count.jsonl\n",
      "Generated JSONL file with - 1040 max words, 150 samples - at ./dataset/gen-word-1040-count.jsonl\n",
      "Generated JSONL file with - 1495 max words, 150 samples - at ./dataset/gen-word-1495-count.jsonl\n",
      "Generated JSONL file with - 1430 max words, 150 samples - at ./dataset/gen-word-1430-count.jsonl\n",
      "Generated JSONL file with - 1625 max words, 150 samples - at ./dataset/gen-word-1625-count.jsonl\n",
      "Generated a single JSONL file with 198 samples (100 token repeat) - 2335 max words - at ./dataset/shuffle-word-2335-count.jsonl\n",
      "Generated a single JSONL file with 1369 samples (100 token repeat) - 185 max words - at ./dataset/shuffle-word-185-count.jsonl\n",
      "Generated JSONL file with - 3970 max words, 100 samples - at ./dataset/gen-word-3970-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1830 max words - at ./dataset/shuffle-word-1830-count.jsonl\n",
      "Generated a single JSONL file with 248 samples (100 token repeat) - 1245 max words - at ./dataset/shuffle-word-1245-count.jsonl\n",
      "Generated a single JSONL file with 198 samples (100 token repeat) - 2340 max words - at ./dataset/shuffle-word-2340-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1440 max words - at ./dataset/shuffle-word-1440-count.jsonl\n",
      "Generated a single JSONL file with 202 samples (100 token repeat) - 1395 max words - at ./dataset/shuffle-word-1395-count.jsonl\n",
      "Generated JSONL file with - 2945 max words, 125 samples - at ./dataset/gen-word-2945-count.jsonl\n",
      "Generated a single JSONL file with 199 samples (100 token repeat) - 2350 max words - at ./dataset/shuffle-word-2350-count.jsonl\n",
      "Generated JSONL file with - 1875 max words, 150 samples - at ./dataset/gen-word-1875-count.jsonl\n",
      "Generated JSONL file with - 3165 max words, 100 samples - at ./dataset/gen-word-3165-count.jsonl\n",
      "Generated JSONL file with - 1855 max words, 150 samples - at ./dataset/gen-word-1855-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1085 max words - at ./dataset/shuffle-word-1085-count.jsonl\n",
      "Generated a single JSONL file with 202 samples (100 token repeat) - 1355 max words - at ./dataset/shuffle-word-1355-count.jsonl\n",
      "Generated a single JSONL file with 248 samples (100 token repeat) - 1295 max words - at ./dataset/shuffle-word-1295-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3455 max words - at ./dataset/shuffle-word-3455-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3990 max words - at ./dataset/shuffle-word-3990-count.jsonl\n",
      "Generated JSONL file with - 1830 max words, 150 samples - at ./dataset/gen-word-1830-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2145 max words - at ./dataset/shuffle-word-2145-count.jsonl\n",
      "Generated JSONL file with - 3965 max words, 100 samples - at ./dataset/gen-word-3965-count.jsonl\n",
      "Generated JSONL file with - 1645 max words, 150 samples - at ./dataset/gen-word-1645-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1760 max words - at ./dataset/shuffle-word-1760-count.jsonl\n",
      "Generated a single JSONL file with 246 samples (100 token repeat) - 1250 max words - at ./dataset/shuffle-word-1250-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2205 max words - at ./dataset/shuffle-word-2205-count.jsonl\n",
      "Generated JSONL file with - 2230 max words, 125 samples - at ./dataset/gen-word-2230-count.jsonl\n",
      "Generated JSONL file with - 1670 max words, 150 samples - at ./dataset/gen-word-1670-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2905 max words - at ./dataset/shuffle-word-2905-count.jsonl\n",
      "Generated a single JSONL file with 188 samples (100 token repeat) - 2440 max words - at ./dataset/shuffle-word-2440-count.jsonl\n",
      "Generated JSONL file with - 1115 max words, 150 samples - at ./dataset/gen-word-1115-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2125 max words - at ./dataset/shuffle-word-2125-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2280 max words - at ./dataset/shuffle-word-2280-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1570 max words - at ./dataset/shuffle-word-1570-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2255 max words - at ./dataset/shuffle-word-2255-count.jsonl\n",
      "Generated JSONL file with - 3975 max words, 100 samples - at ./dataset/gen-word-3975-count.jsonl\n",
      "Generated a single JSONL file with 115 samples (100 token repeat) - 2665 max words - at ./dataset/shuffle-word-2665-count.jsonl\n",
      "Generated JSONL file with - 1375 max words, 150 samples - at ./dataset/gen-word-1375-count.jsonl\n",
      "Generated JSONL file with - 1560 max words, 150 samples - at ./dataset/gen-word-1560-count.jsonl\n",
      "Generated a single JSONL file with 401 samples (100 token repeat) - 660 max words - at ./dataset/shuffle-word-660-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3785 max words - at ./dataset/shuffle-word-3785-count.jsonl\n",
      "Generated a single JSONL file with 299 samples (100 token repeat) - 1165 max words - at ./dataset/shuffle-word-1165-count.jsonl\n",
      "Generated JSONL file with - 1965 max words, 150 samples - at ./dataset/gen-word-1965-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3135 max words - at ./dataset/shuffle-word-3135-count.jsonl\n",
      "Generated JSONL file with - 3695 max words, 100 samples - at ./dataset/gen-word-3695-count.jsonl\n",
      "Generated a single JSONL file with 103 samples (100 token repeat) - 2725 max words - at ./dataset/shuffle-word-2725-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1155 max words - at ./dataset/shuffle-word-1155-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1980 max words - at ./dataset/shuffle-word-1980-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3610 max words - at ./dataset/shuffle-word-3610-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2265 max words - at ./dataset/shuffle-word-2265-count.jsonl\n",
      "Generated a single JSONL file with 201 samples (100 token repeat) - 1315 max words - at ./dataset/shuffle-word-1315-count.jsonl\n",
      "Generated JSONL file with - 4000 max words, 100 samples - at ./dataset/gen-word-4000-count.jsonl\n",
      "Generated JSONL file with - 3950 max words, 100 samples - at ./dataset/gen-word-3950-count.jsonl\n",
      "Generated a single JSONL file with 116 samples (100 token repeat) - 2635 max words - at ./dataset/shuffle-word-2635-count.jsonl\n",
      "Generated JSONL file with - 1380 max words, 150 samples - at ./dataset/gen-word-1380-count.jsonl\n",
      "Generated a single JSONL file with 203 samples (100 token repeat) - 1330 max words - at ./dataset/shuffle-word-1330-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1075 max words - at ./dataset/shuffle-word-1075-count.jsonl\n",
      "Generated JSONL file with - 1865 max words, 150 samples - at ./dataset/gen-word-1865-count.jsonl\n",
      "Generated JSONL file with - 3905 max words, 100 samples - at ./dataset/gen-word-3905-count.jsonl\n",
      "Generated a single JSONL file with 246 samples (100 token repeat) - 1205 max words - at ./dataset/shuffle-word-1205-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2050 max words - at ./dataset/shuffle-word-2050-count.jsonl\n",
      "Generated JSONL file with - 2530 max words, 125 samples - at ./dataset/gen-word-2530-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1470 max words - at ./dataset/shuffle-word-1470-count.jsonl\n",
      "Generated JSONL file with - 3870 max words, 100 samples - at ./dataset/gen-word-3870-count.jsonl\n",
      "Generated a single JSONL file with 297 samples (100 token repeat) - 1160 max words - at ./dataset/shuffle-word-1160-count.jsonl\n",
      "Generated JSONL file with - 1100 max words, 150 samples - at ./dataset/gen-word-1100-count.jsonl\n",
      "Generated JSONL file with - 3835 max words, 100 samples - at ./dataset/gen-word-3835-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1765 max words - at ./dataset/shuffle-word-1765-count.jsonl\n",
      "Generated JSONL file with - 2400 max words, 125 samples - at ./dataset/gen-word-2400-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1940 max words - at ./dataset/shuffle-word-1940-count.jsonl\n",
      "Generated JSONL file with - 1280 max words, 150 samples - at ./dataset/gen-word-1280-count.jsonl\n",
      "Generated JSONL file with - 1520 max words, 150 samples - at ./dataset/gen-word-1520-count.jsonl\n",
      "Generated a single JSONL file with 399 samples (100 token repeat) - 780 max words - at ./dataset/shuffle-word-780-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1735 max words - at ./dataset/shuffle-word-1735-count.jsonl\n",
      "Generated JSONL file with - 1775 max words, 150 samples - at ./dataset/gen-word-1775-count.jsonl\n",
      "Generated a single JSONL file with 499 samples (100 token repeat) - 565 max words - at ./dataset/shuffle-word-565-count.jsonl\n",
      "Generated JSONL file with - 3885 max words, 100 samples - at ./dataset/gen-word-3885-count.jsonl\n",
      "Generated JSONL file with - 1610 max words, 150 samples - at ./dataset/gen-word-1610-count.jsonl\n",
      "Generated JSONL file with - 2420 max words, 125 samples - at ./dataset/gen-word-2420-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1730 max words - at ./dataset/shuffle-word-1730-count.jsonl\n",
      "Generated JSONL file with - 1760 max words, 150 samples - at ./dataset/gen-word-1760-count.jsonl\n",
      "Generated JSONL file with - 1045 max words, 150 samples - at ./dataset/gen-word-1045-count.jsonl\n",
      "Generated JSONL file with - 1685 max words, 150 samples - at ./dataset/gen-word-1685-count.jsonl\n",
      "Generated a single JSONL file with 296 samples (100 token repeat) - 1195 max words - at ./dataset/shuffle-word-1195-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1885 max words - at ./dataset/shuffle-word-1885-count.jsonl\n",
      "Generated JSONL file with - 1485 max words, 150 samples - at ./dataset/gen-word-1485-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1405 max words - at ./dataset/shuffle-word-1405-count.jsonl\n",
      "Generated JSONL file with - 2115 max words, 125 samples - at ./dataset/gen-word-2115-count.jsonl\n",
      "Generated JSONL file with - 3410 max words, 100 samples - at ./dataset/gen-word-3410-count.jsonl\n",
      "Generated a single JSONL file with 587 samples (100 token repeat) - 455 max words - at ./dataset/shuffle-word-455-count.jsonl\n",
      "Generated JSONL file with - 2120 max words, 125 samples - at ./dataset/gen-word-2120-count.jsonl\n",
      "Generated JSONL file with - 1605 max words, 150 samples - at ./dataset/gen-word-1605-count.jsonl\n",
      "Generated a single JSONL file with 201 samples (100 token repeat) - 1350 max words - at ./dataset/shuffle-word-1350-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3995 max words - at ./dataset/shuffle-word-3995-count.jsonl\n",
      "Generated JSONL file with - 3560 max words, 100 samples - at ./dataset/gen-word-3560-count.jsonl\n",
      "Generated JSONL file with - 1465 max words, 150 samples - at ./dataset/gen-word-1465-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1565 max words - at ./dataset/shuffle-word-1565-count.jsonl\n",
      "Generated a single JSONL file with 198 samples (100 token repeat) - 2400 max words - at ./dataset/shuffle-word-2400-count.jsonl\n",
      "Generated JSONL file with - 2355 max words, 125 samples - at ./dataset/gen-word-2355-count.jsonl\n",
      "Generated JSONL file with - 2205 max words, 125 samples - at ./dataset/gen-word-2205-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1050 max words - at ./dataset/shuffle-word-1050-count.jsonl\n",
      "Generated a single JSONL file with 186 samples (100 token repeat) - 2410 max words - at ./dataset/shuffle-word-2410-count.jsonl\n",
      "Generated JSONL file with - 2085 max words, 125 samples - at ./dataset/gen-word-2085-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1965 max words - at ./dataset/shuffle-word-1965-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1100 max words - at ./dataset/shuffle-word-1100-count.jsonl\n",
      "Generated JSONL file with - 1920 max words, 150 samples - at ./dataset/gen-word-1920-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1140 max words - at ./dataset/shuffle-word-1140-count.jsonl\n",
      "Generated JSONL file with - 3990 max words, 100 samples - at ./dataset/gen-word-3990-count.jsonl\n",
      "Generated JSONL file with - 1160 max words, 150 samples - at ./dataset/gen-word-1160-count.jsonl\n",
      "Generated JSONL file with - 2245 max words, 125 samples - at ./dataset/gen-word-2245-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2130 max words - at ./dataset/shuffle-word-2130-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2295 max words - at ./dataset/shuffle-word-2295-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1120 max words - at ./dataset/shuffle-word-1120-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 990 max words - at ./dataset/shuffle-word-990-count.jsonl\n",
      "Generated JSONL file with - 2335 max words, 125 samples - at ./dataset/gen-word-2335-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1945 max words - at ./dataset/shuffle-word-1945-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2085 max words - at ./dataset/shuffle-word-2085-count.jsonl\n",
      "Generated JSONL file with - 1450 max words, 150 samples - at ./dataset/gen-word-1450-count.jsonl\n",
      "Generated a single JSONL file with 203 samples (100 token repeat) - 1370 max words - at ./dataset/shuffle-word-1370-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1725 max words - at ./dataset/shuffle-word-1725-count.jsonl\n",
      "Generated JSONL file with - 3575 max words, 100 samples - at ./dataset/gen-word-3575-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3950 max words - at ./dataset/shuffle-word-3950-count.jsonl\n",
      "Generated a single JSONL file with 147 samples (100 token repeat) - 2505 max words - at ./dataset/shuffle-word-2505-count.jsonl\n",
      "Generated JSONL file with - 2625 max words, 125 samples - at ./dataset/gen-word-2625-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2815 max words - at ./dataset/shuffle-word-2815-count.jsonl\n",
      "Generated JSONL file with - 2390 max words, 125 samples - at ./dataset/gen-word-2390-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1110 max words - at ./dataset/shuffle-word-1110-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2150 max words - at ./dataset/shuffle-word-2150-count.jsonl\n",
      "Generated a single JSONL file with 189 samples (100 token repeat) - 2460 max words - at ./dataset/shuffle-word-2460-count.jsonl\n",
      "Generated JSONL file with - 2730 max words, 125 samples - at ./dataset/gen-word-2730-count.jsonl\n",
      "Generated JSONL file with - 2925 max words, 125 samples - at ./dataset/gen-word-2925-count.jsonl\n",
      "Generated a single JSONL file with 580 samples (100 token repeat) - 465 max words - at ./dataset/shuffle-word-465-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1755 max words - at ./dataset/shuffle-word-1755-count.jsonl\n",
      "Generated a single JSONL file with 931 samples (100 token repeat) - 260 max words - at ./dataset/shuffle-word-260-count.jsonl\n",
      "Generated JSONL file with - 2645 max words, 125 samples - at ./dataset/gen-word-2645-count.jsonl\n",
      "Generated JSONL file with - 1790 max words, 150 samples - at ./dataset/gen-word-1790-count.jsonl\n",
      "Generated JSONL file with - 2735 max words, 125 samples - at ./dataset/gen-word-2735-count.jsonl\n",
      "Generated a single JSONL file with 253 samples (100 token repeat) - 1275 max words - at ./dataset/shuffle-word-1275-count.jsonl\n",
      "Generated JSONL file with - 2370 max words, 125 samples - at ./dataset/gen-word-2370-count.jsonl\n",
      "Generated JSONL file with - 1540 max words, 150 samples - at ./dataset/gen-word-1540-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2960 max words - at ./dataset/shuffle-word-2960-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1435 max words - at ./dataset/shuffle-word-1435-count.jsonl\n",
      "Generated JSONL file with - 1285 max words, 150 samples - at ./dataset/gen-word-1285-count.jsonl\n",
      "Generated JSONL file with - 2465 max words, 125 samples - at ./dataset/gen-word-2465-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1950 max words - at ./dataset/shuffle-word-1950-count.jsonl\n",
      "Generated JSONL file with - 1745 max words, 150 samples - at ./dataset/gen-word-1745-count.jsonl\n",
      "Generated JSONL file with - 2005 max words, 125 samples - at ./dataset/gen-word-2005-count.jsonl\n",
      "Generated a single JSONL file with 254 samples (100 token repeat) - 1230 max words - at ./dataset/shuffle-word-1230-count.jsonl\n",
      "Generated a single JSONL file with 404 samples (100 token repeat) - 650 max words - at ./dataset/shuffle-word-650-count.jsonl\n",
      "Generated JSONL file with - 1225 max words, 150 samples - at ./dataset/gen-word-1225-count.jsonl\n",
      "Generated a single JSONL file with 299 samples (100 token repeat) - 1135 max words - at ./dataset/shuffle-word-1135-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3485 max words - at ./dataset/shuffle-word-3485-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2010 max words - at ./dataset/shuffle-word-2010-count.jsonl\n",
      "Generated JSONL file with - 2275 max words, 125 samples - at ./dataset/gen-word-2275-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1145 max words - at ./dataset/shuffle-word-1145-count.jsonl\n",
      "Generated a single JSONL file with 154 samples (100 token repeat) - 2530 max words - at ./dataset/shuffle-word-2530-count.jsonl\n",
      "Generated JSONL file with - 2550 max words, 125 samples - at ./dataset/gen-word-2550-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1080 max words - at ./dataset/shuffle-word-1080-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2300 max words - at ./dataset/shuffle-word-2300-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2870 max words - at ./dataset/shuffle-word-2870-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1430 max words - at ./dataset/shuffle-word-1430-count.jsonl\n",
      "Generated a single JSONL file with 202 samples (100 token repeat) - 1390 max words - at ./dataset/shuffle-word-1390-count.jsonl\n",
      "Generated JSONL file with - 3820 max words, 100 samples - at ./dataset/gen-word-3820-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1785 max words - at ./dataset/shuffle-word-1785-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1595 max words - at ./dataset/shuffle-word-1595-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3540 max words - at ./dataset/shuffle-word-3540-count.jsonl\n",
      "Generated a single JSONL file with 255 samples (100 token repeat) - 1220 max words - at ./dataset/shuffle-word-1220-count.jsonl\n",
      "Generated JSONL file with - 2415 max words, 125 samples - at ./dataset/gen-word-2415-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1520 max words - at ./dataset/shuffle-word-1520-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2995 max words - at ./dataset/shuffle-word-2995-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1640 max words - at ./dataset/shuffle-word-1640-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1610 max words - at ./dataset/shuffle-word-1610-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1790 max words - at ./dataset/shuffle-word-1790-count.jsonl\n",
      "Generated JSONL file with - 1655 max words, 150 samples - at ./dataset/gen-word-1655-count.jsonl\n",
      "Generated JSONL file with - 1900 max words, 150 samples - at ./dataset/gen-word-1900-count.jsonl\n",
      "Generated JSONL file with - 3215 max words, 100 samples - at ./dataset/gen-word-3215-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3860 max words - at ./dataset/shuffle-word-3860-count.jsonl\n",
      "Generated JSONL file with - 3060 max words, 100 samples - at ./dataset/gen-word-3060-count.jsonl\n",
      "Generated JSONL file with - 2175 max words, 125 samples - at ./dataset/gen-word-2175-count.jsonl\n",
      "Generated JSONL file with - 1980 max words, 150 samples - at ./dataset/gen-word-1980-count.jsonl\n",
      "Generated JSONL file with - 1740 max words, 150 samples - at ./dataset/gen-word-1740-count.jsonl\n",
      "Generated JSONL file with - 2535 max words, 125 samples - at ./dataset/gen-word-2535-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3475 max words - at ./dataset/shuffle-word-3475-count.jsonl\n",
      "Generated a single JSONL file with 711 samples (100 token repeat) - 315 max words - at ./dataset/shuffle-word-315-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3420 max words - at ./dataset/shuffle-word-3420-count.jsonl\n",
      "Generated JSONL file with - 2240 max words, 125 samples - at ./dataset/gen-word-2240-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3550 max words - at ./dataset/shuffle-word-3550-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1720 max words - at ./dataset/shuffle-word-1720-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2110 max words - at ./dataset/shuffle-word-2110-count.jsonl\n",
      "Generated JSONL file with - 1620 max words, 150 samples - at ./dataset/gen-word-1620-count.jsonl\n",
      "Generated JSONL file with - 1490 max words, 150 samples - at ./dataset/gen-word-1490-count.jsonl\n",
      "Generated JSONL file with - 3995 max words, 100 samples - at ./dataset/gen-word-3995-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3645 max words - at ./dataset/shuffle-word-3645-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1500 max words - at ./dataset/shuffle-word-1500-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1740 max words - at ./dataset/shuffle-word-1740-count.jsonl\n",
      "Generated a single JSONL file with 117 samples (100 token repeat) - 2625 max words - at ./dataset/shuffle-word-2625-count.jsonl\n",
      "Generated JSONL file with - 2790 max words, 125 samples - at ./dataset/gen-word-2790-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1410 max words - at ./dataset/shuffle-word-1410-count.jsonl\n",
      "Generated JSONL file with - 1565 max words, 150 samples - at ./dataset/gen-word-1565-count.jsonl\n",
      "Generated JSONL file with - 1240 max words, 150 samples - at ./dataset/gen-word-1240-count.jsonl\n",
      "Generated JSONL file with - 2165 max words, 125 samples - at ./dataset/gen-word-2165-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3235 max words - at ./dataset/shuffle-word-3235-count.jsonl\n",
      "Generated a single JSONL file with 149 samples (100 token repeat) - 2525 max words - at ./dataset/shuffle-word-2525-count.jsonl\n",
      "Generated JSONL file with - 3945 max words, 100 samples - at ./dataset/gen-word-3945-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3955 max words - at ./dataset/shuffle-word-3955-count.jsonl\n",
      "Generated a single JSONL file with 149 samples (100 token repeat) - 2535 max words - at ./dataset/shuffle-word-2535-count.jsonl\n",
      "Generated JSONL file with - 2575 max words, 125 samples - at ./dataset/gen-word-2575-count.jsonl\n",
      "Generated JSONL file with - 1120 max words, 150 samples - at ./dataset/gen-word-1120-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1045 max words - at ./dataset/shuffle-word-1045-count.jsonl\n",
      "Generated JSONL file with - 1190 max words, 150 samples - at ./dataset/gen-word-1190-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1465 max words - at ./dataset/shuffle-word-1465-count.jsonl\n",
      "Generated JSONL file with - 1145 max words, 150 samples - at ./dataset/gen-word-1145-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1620 max words - at ./dataset/shuffle-word-1620-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1540 max words - at ./dataset/shuffle-word-1540-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1900 max words - at ./dataset/shuffle-word-1900-count.jsonl\n",
      "Generated JSONL file with - 2445 max words, 125 samples - at ./dataset/gen-word-2445-count.jsonl\n",
      "Generated JSONL file with - 1735 max words, 150 samples - at ./dataset/gen-word-1735-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3815 max words - at ./dataset/shuffle-word-3815-count.jsonl\n",
      "Generated JSONL file with - 1035 max words, 150 samples - at ./dataset/gen-word-1035-count.jsonl\n",
      "Generated JSONL file with - 1725 max words, 150 samples - at ./dataset/gen-word-1725-count.jsonl\n",
      "Generated JSONL file with - 2285 max words, 125 samples - at ./dataset/gen-word-2285-count.jsonl\n",
      "Generated a single JSONL file with 295 samples (100 token repeat) - 1200 max words - at ./dataset/shuffle-word-1200-count.jsonl\n",
      "Generated JSONL file with - 1635 max words, 150 samples - at ./dataset/gen-word-1635-count.jsonl\n",
      "Generated JSONL file with - 3980 max words, 100 samples - at ./dataset/gen-word-3980-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1855 max words - at ./dataset/shuffle-word-1855-count.jsonl\n",
      "Generated a single JSONL file with 5873 samples (100 token repeat) - 45 max words - at ./dataset/shuffle-word-45-count.jsonl\n",
      "Generated JSONL file with - 3555 max words, 100 samples - at ./dataset/gen-word-3555-count.jsonl\n",
      "Generated JSONL file with - 2435 max words, 125 samples - at ./dataset/gen-word-2435-count.jsonl\n",
      "Generated JSONL file with - 3960 max words, 100 samples - at ./dataset/gen-word-3960-count.jsonl\n",
      "Generated a single JSONL file with 101 samples (100 token repeat) - 2795 max words - at ./dataset/shuffle-word-2795-count.jsonl\n",
      "Generated JSONL file with - 1820 max words, 150 samples - at ./dataset/gen-word-1820-count.jsonl\n",
      "Generated JSONL file with - 1545 max words, 150 samples - at ./dataset/gen-word-1545-count.jsonl\n",
      "Generated JSONL file with - 1125 max words, 150 samples - at ./dataset/gen-word-1125-count.jsonl\n",
      "Generated a single JSONL file with 205 samples (100 token repeat) - 1305 max words - at ./dataset/shuffle-word-1305-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1990 max words - at ./dataset/shuffle-word-1990-count.jsonl\n",
      "Generated a single JSONL file with 1011 samples (100 token repeat) - 215 max words - at ./dataset/shuffle-word-215-count.jsonl\n",
      "Generated JSONL file with - 1730 max words, 150 samples - at ./dataset/gen-word-1730-count.jsonl\n",
      "Generated a single JSONL file with 202 samples (100 token repeat) - 1400 max words - at ./dataset/shuffle-word-1400-count.jsonl\n",
      "Generated JSONL file with - 1715 max words, 150 samples - at ./dataset/gen-word-1715-count.jsonl\n",
      "Generated JSONL file with - 1805 max words, 150 samples - at ./dataset/gen-word-1805-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1095 max words - at ./dataset/shuffle-word-1095-count.jsonl\n",
      "Generated JSONL file with - 1195 max words, 150 samples - at ./dataset/gen-word-1195-count.jsonl\n",
      "Generated JSONL file with - 1315 max words, 150 samples - at ./dataset/gen-word-1315-count.jsonl\n",
      "Generated JSONL file with - 2440 max words, 125 samples - at ./dataset/gen-word-2440-count.jsonl\n",
      "Generated JSONL file with - 3985 max words, 100 samples - at ./dataset/gen-word-3985-count.jsonl\n",
      "Generated a single JSONL file with 588 samples (100 token repeat) - 460 max words - at ./dataset/shuffle-word-460-count.jsonl\n",
      "Generated JSONL file with - 2505 max words, 125 samples - at ./dataset/gen-word-2505-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1630 max words - at ./dataset/shuffle-word-1630-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1880 max words - at ./dataset/shuffle-word-1880-count.jsonl\n",
      "Generated a single JSONL file with 259 samples (100 token repeat) - 1265 max words - at ./dataset/shuffle-word-1265-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3910 max words - at ./dataset/shuffle-word-3910-count.jsonl\n",
      "Generated JSONL file with - 1345 max words, 150 samples - at ./dataset/gen-word-1345-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2060 max words - at ./dataset/shuffle-word-2060-count.jsonl\n",
      "Generated JSONL file with - 2800 max words, 125 samples - at ./dataset/gen-word-2800-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1820 max words - at ./dataset/shuffle-word-1820-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1420 max words - at ./dataset/shuffle-word-1420-count.jsonl\n",
      "Generated JSONL file with - 3615 max words, 100 samples - at ./dataset/gen-word-3615-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3960 max words - at ./dataset/shuffle-word-3960-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1040 max words - at ./dataset/shuffle-word-1040-count.jsonl\n",
      "Generated a single JSONL file with 105 samples (100 token repeat) - 2720 max words - at ./dataset/shuffle-word-2720-count.jsonl\n",
      "Generated a single JSONL file with 197 samples (100 token repeat) - 2330 max words - at ./dataset/shuffle-word-2330-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2005 max words - at ./dataset/shuffle-word-2005-count.jsonl\n",
      "Generated JSONL file with - 1600 max words, 150 samples - at ./dataset/gen-word-1600-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 4000 max words - at ./dataset/shuffle-word-4000-count.jsonl\n",
      "Generated JSONL file with - 2060 max words, 125 samples - at ./dataset/gen-word-2060-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2285 max words - at ./dataset/shuffle-word-2285-count.jsonl\n",
      "Generated JSONL file with - 1680 max words, 150 samples - at ./dataset/gen-word-1680-count.jsonl\n",
      "Generated JSONL file with - 1230 max words, 150 samples - at ./dataset/gen-word-1230-count.jsonl\n",
      "Generated JSONL file with - 3490 max words, 100 samples - at ./dataset/gen-word-3490-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2935 max words - at ./dataset/shuffle-word-2935-count.jsonl\n",
      "Generated a single JSONL file with 190 samples (100 token repeat) - 2455 max words - at ./dataset/shuffle-word-2455-count.jsonl\n",
      "Generated JSONL file with - 1500 max words, 150 samples - at ./dataset/gen-word-1500-count.jsonl\n",
      "Generated JSONL file with - 2850 max words, 125 samples - at ./dataset/gen-word-2850-count.jsonl\n",
      "Generated a single JSONL file with 154 samples (100 token repeat) - 2520 max words - at ./dataset/shuffle-word-2520-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2165 max words - at ./dataset/shuffle-word-2165-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 1025 max words - at ./dataset/shuffle-word-1025-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2965 max words - at ./dataset/shuffle-word-2965-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3440 max words - at ./dataset/shuffle-word-3440-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3770 max words - at ./dataset/shuffle-word-3770-count.jsonl\n",
      "Generated JSONL file with - 1350 max words, 150 samples - at ./dataset/gen-word-1350-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3220 max words - at ./dataset/shuffle-word-3220-count.jsonl\n",
      "Generated JSONL file with - 1975 max words, 150 samples - at ./dataset/gen-word-1975-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3790 max words - at ./dataset/shuffle-word-3790-count.jsonl\n",
      "Generated JSONL file with - 2810 max words, 125 samples - at ./dataset/gen-word-2810-count.jsonl\n",
      "Generated JSONL file with - 1325 max words, 150 samples - at ./dataset/gen-word-1325-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2810 max words - at ./dataset/shuffle-word-2810-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2975 max words - at ./dataset/shuffle-word-2975-count.jsonl\n",
      "Generated JSONL file with - 2015 max words, 125 samples - at ./dataset/gen-word-2015-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2890 max words - at ./dataset/shuffle-word-2890-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1635 max words - at ./dataset/shuffle-word-1635-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3460 max words - at ./dataset/shuffle-word-3460-count.jsonl\n",
      "Generated JSONL file with - 3150 max words, 100 samples - at ./dataset/gen-word-3150-count.jsonl\n",
      "Generated JSONL file with - 2145 max words, 125 samples - at ./dataset/gen-word-2145-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2210 max words - at ./dataset/shuffle-word-2210-count.jsonl\n",
      "Generated JSONL file with - 2030 max words, 125 samples - at ./dataset/gen-word-2030-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2915 max words - at ./dataset/shuffle-word-2915-count.jsonl\n",
      "Generated a single JSONL file with 184 samples (100 token repeat) - 2415 max words - at ./dataset/shuffle-word-2415-count.jsonl\n",
      "Generated a single JSONL file with 117 samples (100 token repeat) - 2640 max words - at ./dataset/shuffle-word-2640-count.jsonl\n",
      "Generated JSONL file with - 2265 max words, 125 samples - at ./dataset/gen-word-2265-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2985 max words - at ./dataset/shuffle-word-2985-count.jsonl\n",
      "Generated JSONL file with - 2725 max words, 125 samples - at ./dataset/gen-word-2725-count.jsonl\n",
      "Generated JSONL file with - 1955 max words, 150 samples - at ./dataset/gen-word-1955-count.jsonl\n",
      "Generated JSONL file with - 2270 max words, 125 samples - at ./dataset/gen-word-2270-count.jsonl\n",
      "Generated JSONL file with - 1755 max words, 150 samples - at ./dataset/gen-word-1755-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2055 max words - at ./dataset/shuffle-word-2055-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3885 max words - at ./dataset/shuffle-word-3885-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3870 max words - at ./dataset/shuffle-word-3870-count.jsonl\n",
      "Generated JSONL file with - 2130 max words, 125 samples - at ./dataset/gen-word-2130-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3140 max words - at ./dataset/shuffle-word-3140-count.jsonl\n",
      "Generated JSONL file with - 2125 max words, 125 samples - at ./dataset/gen-word-2125-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2865 max words - at ./dataset/shuffle-word-2865-count.jsonl\n",
      "Generated JSONL file with - 2050 max words, 125 samples - at ./dataset/gen-word-2050-count.jsonl\n",
      "Generated JSONL file with - 1840 max words, 150 samples - at ./dataset/gen-word-1840-count.jsonl\n",
      "Generated JSONL file with - 3780 max words, 100 samples - at ./dataset/gen-word-3780-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2830 max words - at ./dataset/shuffle-word-2830-count.jsonl\n",
      "Generated JSONL file with - 3955 max words, 100 samples - at ./dataset/gen-word-3955-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3575 max words - at ./dataset/shuffle-word-3575-count.jsonl\n",
      "Generated JSONL file with - 2450 max words, 125 samples - at ./dataset/gen-word-2450-count.jsonl\n",
      "Generated JSONL file with - 3625 max words, 100 samples - at ./dataset/gen-word-3625-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1705 max words - at ./dataset/shuffle-word-1705-count.jsonl\n",
      "Generated a single JSONL file with 125 samples (100 token repeat) - 2660 max words - at ./dataset/shuffle-word-2660-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2115 max words - at ./dataset/shuffle-word-2115-count.jsonl\n",
      "Generated a single JSONL file with 246 samples (100 token repeat) - 1290 max words - at ./dataset/shuffle-word-1290-count.jsonl\n",
      "Generated JSONL file with - 2065 max words, 125 samples - at ./dataset/gen-word-2065-count.jsonl\n",
      "Generated JSONL file with - 2910 max words, 125 samples - at ./dataset/gen-word-2910-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1775 max words - at ./dataset/shuffle-word-1775-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3845 max words - at ./dataset/shuffle-word-3845-count.jsonl\n",
      "Generated JSONL file with - 1405 max words, 150 samples - at ./dataset/gen-word-1405-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1955 max words - at ./dataset/shuffle-word-1955-count.jsonl\n",
      "Generated a single JSONL file with 205 samples (100 token repeat) - 1340 max words - at ./dataset/shuffle-word-1340-count.jsonl\n",
      "Generated a single JSONL file with 117 samples (100 token repeat) - 2610 max words - at ./dataset/shuffle-word-2610-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1875 max words - at ./dataset/shuffle-word-1875-count.jsonl\n",
      "Generated JSONL file with - 2215 max words, 125 samples - at ./dataset/gen-word-2215-count.jsonl\n",
      "Generated JSONL file with - 3880 max words, 100 samples - at ./dataset/gen-word-3880-count.jsonl\n",
      "Generated JSONL file with - 2460 max words, 125 samples - at ./dataset/gen-word-2460-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2045 max words - at ./dataset/shuffle-word-2045-count.jsonl\n",
      "Generated JSONL file with - 3140 max words, 100 samples - at ./dataset/gen-word-3140-count.jsonl\n",
      "Generated JSONL file with - 3700 max words, 100 samples - at ./dataset/gen-word-3700-count.jsonl\n",
      "Generated JSONL file with - 3275 max words, 100 samples - at ./dataset/gen-word-3275-count.jsonl\n",
      "Generated JSONL file with - 2720 max words, 125 samples - at ./dataset/gen-word-2720-count.jsonl\n",
      "Generated JSONL file with - 2665 max words, 125 samples - at ./dataset/gen-word-2665-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3940 max words - at ./dataset/shuffle-word-3940-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3345 max words - at ./dataset/shuffle-word-3345-count.jsonl\n",
      "Generated a single JSONL file with 203 samples (100 token repeat) - 1375 max words - at ./dataset/shuffle-word-1375-count.jsonl\n",
      "Generated a single JSONL file with 300 samples (100 token repeat) - 995 max words - at ./dataset/shuffle-word-995-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2215 max words - at ./dataset/shuffle-word-2215-count.jsonl\n",
      "Generated a single JSONL file with 154 samples (100 token repeat) - 2585 max words - at ./dataset/shuffle-word-2585-count.jsonl\n",
      "Generated JSONL file with - 2660 max words, 125 samples - at ./dataset/gen-word-2660-count.jsonl\n",
      "Generated JSONL file with - 2520 max words, 125 samples - at ./dataset/gen-word-2520-count.jsonl\n",
      "Generated JSONL file with - 2610 max words, 125 samples - at ./dataset/gen-word-2610-count.jsonl\n",
      "Generated JSONL file with - 2220 max words, 125 samples - at ./dataset/gen-word-2220-count.jsonl\n",
      "Generated JSONL file with - 2870 max words, 125 samples - at ./dataset/gen-word-2870-count.jsonl\n",
      "Generated JSONL file with - 2525 max words, 125 samples - at ./dataset/gen-word-2525-count.jsonl\n",
      "Generated JSONL file with - 2385 max words, 125 samples - at ./dataset/gen-word-2385-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2070 max words - at ./dataset/shuffle-word-2070-count.jsonl\n",
      "Generated JSONL file with - 2250 max words, 125 samples - at ./dataset/gen-word-2250-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3205 max words - at ./dataset/shuffle-word-3205-count.jsonl\n",
      "Generated JSONL file with - 3425 max words, 100 samples - at ./dataset/gen-word-3425-count.jsonl\n",
      "Generated JSONL file with - 3360 max words, 100 samples - at ./dataset/gen-word-3360-count.jsonl\n",
      "Generated a single JSONL file with 187 samples (100 token repeat) - 2445 max words - at ./dataset/shuffle-word-2445-count.jsonl\n",
      "Generated a single JSONL file with 152 samples (100 token repeat) - 2550 max words - at ./dataset/shuffle-word-2550-count.jsonl\n",
      "Generated JSONL file with - 3340 max words, 100 samples - at ./dataset/gen-word-3340-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3105 max words - at ./dataset/shuffle-word-3105-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2820 max words - at ./dataset/shuffle-word-2820-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2220 max words - at ./dataset/shuffle-word-2220-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2065 max words - at ./dataset/shuffle-word-2065-count.jsonl\n",
      "Generated a single JSONL file with 102 samples (100 token repeat) - 2775 max words - at ./dataset/shuffle-word-2775-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1660 max words - at ./dataset/shuffle-word-1660-count.jsonl\n",
      "Generated JSONL file with - 2475 max words, 125 samples - at ./dataset/gen-word-2475-count.jsonl\n",
      "Generated JSONL file with - 3170 max words, 100 samples - at ./dataset/gen-word-3170-count.jsonl\n",
      "Generated JSONL file with - 3080 max words, 100 samples - at ./dataset/gen-word-3080-count.jsonl\n",
      "Generated JSONL file with - 3105 max words, 100 samples - at ./dataset/gen-word-3105-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3935 max words - at ./dataset/shuffle-word-3935-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2840 max words - at ./dataset/shuffle-word-2840-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3920 max words - at ./dataset/shuffle-word-3920-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3030 max words - at ./dataset/shuffle-word-3030-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2195 max words - at ./dataset/shuffle-word-2195-count.jsonl\n",
      "Generated a single JSONL file with 104 samples (100 token repeat) - 2735 max words - at ./dataset/shuffle-word-2735-count.jsonl\n",
      "Generated JSONL file with - 3190 max words, 100 samples - at ./dataset/gen-word-3190-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3850 max words - at ./dataset/shuffle-word-3850-count.jsonl\n",
      "Generated JSONL file with - 3585 max words, 100 samples - at ./dataset/gen-word-3585-count.jsonl\n",
      "Generated JSONL file with - 3125 max words, 100 samples - at ./dataset/gen-word-3125-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1425 max words - at ./dataset/shuffle-word-1425-count.jsonl\n",
      "Generated JSONL file with - 2710 max words, 125 samples - at ./dataset/gen-word-2710-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3045 max words - at ./dataset/shuffle-word-3045-count.jsonl\n",
      "Generated a single JSONL file with 186 samples (100 token repeat) - 2450 max words - at ./dataset/shuffle-word-2450-count.jsonl\n",
      "Generated JSONL file with - 1970 max words, 150 samples - at ./dataset/gen-word-1970-count.jsonl\n",
      "Generated JSONL file with - 2965 max words, 125 samples - at ./dataset/gen-word-2965-count.jsonl\n",
      "Generated JSONL file with - 1950 max words, 150 samples - at ./dataset/gen-word-1950-count.jsonl\n",
      "Generated JSONL file with - 2885 max words, 125 samples - at ./dataset/gen-word-2885-count.jsonl\n",
      "Generated JSONL file with - 3920 max words, 100 samples - at ./dataset/gen-word-3920-count.jsonl\n",
      "Generated JSONL file with - 2765 max words, 125 samples - at ./dataset/gen-word-2765-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2175 max words - at ./dataset/shuffle-word-2175-count.jsonl\n",
      "Generated JSONL file with - 2780 max words, 125 samples - at ./dataset/gen-word-2780-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2990 max words - at ./dataset/shuffle-word-2990-count.jsonl\n",
      "Generated JSONL file with - 3180 max words, 100 samples - at ./dataset/gen-word-3180-count.jsonl\n",
      "Generated JSONL file with - 3135 max words, 100 samples - at ./dataset/gen-word-3135-count.jsonl\n",
      "Generated JSONL file with - 2025 max words, 125 samples - at ./dataset/gen-word-2025-count.jsonl\n",
      "Generated JSONL file with - 3875 max words, 100 samples - at ./dataset/gen-word-3875-count.jsonl\n",
      "Generated JSONL file with - 2160 max words, 125 samples - at ./dataset/gen-word-2160-count.jsonl\n",
      "Generated a single JSONL file with 157 samples (100 token repeat) - 2560 max words - at ./dataset/shuffle-word-2560-count.jsonl\n",
      "Generated JSONL file with - 3755 max words, 100 samples - at ./dataset/gen-word-3755-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2290 max words - at ./dataset/shuffle-word-2290-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2020 max words - at ./dataset/shuffle-word-2020-count.jsonl\n",
      "Generated JSONL file with - 3020 max words, 100 samples - at ./dataset/gen-word-3020-count.jsonl\n",
      "Generated JSONL file with - 2255 max words, 125 samples - at ./dataset/gen-word-2255-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1445 max words - at ./dataset/shuffle-word-1445-count.jsonl\n",
      "Generated JSONL file with - 3000 max words, 125 samples - at ./dataset/gen-word-3000-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1960 max words - at ./dataset/shuffle-word-1960-count.jsonl\n",
      "Generated a single JSONL file with 117 samples (100 token repeat) - 2615 max words - at ./dataset/shuffle-word-2615-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3165 max words - at ./dataset/shuffle-word-3165-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3060 max words - at ./dataset/shuffle-word-3060-count.jsonl\n",
      "Generated a single JSONL file with 103 samples (100 token repeat) - 2800 max words - at ./dataset/shuffle-word-2800-count.jsonl\n",
      "Generated JSONL file with - 3370 max words, 100 samples - at ./dataset/gen-word-3370-count.jsonl\n",
      "Generated JSONL file with - 2570 max words, 125 samples - at ./dataset/gen-word-2570-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2835 max words - at ./dataset/shuffle-word-2835-count.jsonl\n",
      "Generated a single JSONL file with 161 samples (100 token repeat) - 2590 max words - at ./dataset/shuffle-word-2590-count.jsonl\n",
      "Generated JSONL file with - 2565 max words, 125 samples - at ./dataset/gen-word-2565-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2900 max words - at ./dataset/shuffle-word-2900-count.jsonl\n",
      "Generated JSONL file with - 2970 max words, 125 samples - at ./dataset/gen-word-2970-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2245 max words - at ./dataset/shuffle-word-2245-count.jsonl\n",
      "Generated JSONL file with - 3825 max words, 100 samples - at ./dataset/gen-word-3825-count.jsonl\n",
      "Generated JSONL file with - 3915 max words, 100 samples - at ./dataset/gen-word-3915-count.jsonl\n",
      "Generated JSONL file with - 2995 max words, 125 samples - at ./dataset/gen-word-2995-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3500 max words - at ./dataset/shuffle-word-3500-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3210 max words - at ./dataset/shuffle-word-3210-count.jsonl\n",
      "Generated JSONL file with - 2805 max words, 125 samples - at ./dataset/gen-word-2805-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3305 max words - at ./dataset/shuffle-word-3305-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3495 max words - at ./dataset/shuffle-word-3495-count.jsonl\n",
      "Generated JSONL file with - 985 max words, 150 samples - at ./dataset/gen-word-985-count.jsonl\n",
      "Generated JSONL file with - 2495 max words, 125 samples - at ./dataset/gen-word-2495-count.jsonl\n",
      "Generated JSONL file with - 3850 max words, 100 samples - at ./dataset/gen-word-3850-count.jsonl\n",
      "Generated JSONL file with - 3205 max words, 100 samples - at ./dataset/gen-word-3205-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2230 max words - at ./dataset/shuffle-word-2230-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2120 max words - at ./dataset/shuffle-word-2120-count.jsonl\n",
      "Generated JSONL file with - 1705 max words, 150 samples - at ./dataset/gen-word-1705-count.jsonl\n",
      "Generated JSONL file with - 3435 max words, 100 samples - at ./dataset/gen-word-3435-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1490 max words - at ./dataset/shuffle-word-1490-count.jsonl\n",
      "Generated JSONL file with - 3510 max words, 100 samples - at ./dataset/gen-word-3510-count.jsonl\n",
      "Generated JSONL file with - 3520 max words, 100 samples - at ./dataset/gen-word-3520-count.jsonl\n",
      "Generated JSONL file with - 2950 max words, 125 samples - at ./dataset/gen-word-2950-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3435 max words - at ./dataset/shuffle-word-3435-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3430 max words - at ./dataset/shuffle-word-3430-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3490 max words - at ./dataset/shuffle-word-3490-count.jsonl\n",
      "Generated JSONL file with - 2485 max words, 125 samples - at ./dataset/gen-word-2485-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3415 max words - at ./dataset/shuffle-word-3415-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3325 max words - at ./dataset/shuffle-word-3325-count.jsonl\n",
      "Generated JSONL file with - 1825 max words, 150 samples - at ./dataset/gen-word-1825-count.jsonl\n",
      "Generated JSONL file with - 2795 max words, 125 samples - at ./dataset/gen-word-2795-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3300 max words - at ./dataset/shuffle-word-3300-count.jsonl\n",
      "Generated JSONL file with - 1960 max words, 150 samples - at ./dataset/gen-word-1960-count.jsonl\n",
      "Generated JSONL file with - 2875 max words, 125 samples - at ./dataset/gen-word-2875-count.jsonl\n",
      "Generated JSONL file with - 3890 max words, 100 samples - at ./dataset/gen-word-3890-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2105 max words - at ./dataset/shuffle-word-2105-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2025 max words - at ./dataset/shuffle-word-2025-count.jsonl\n",
      "Generated JSONL file with - 2915 max words, 125 samples - at ./dataset/gen-word-2915-count.jsonl\n",
      "Generated JSONL file with - 2650 max words, 125 samples - at ./dataset/gen-word-2650-count.jsonl\n",
      "Generated JSONL file with - 3450 max words, 100 samples - at ./dataset/gen-word-3450-count.jsonl\n",
      "Generated JSONL file with - 2820 max words, 125 samples - at ./dataset/gen-word-2820-count.jsonl\n",
      "Generated JSONL file with - 3085 max words, 100 samples - at ./dataset/gen-word-3085-count.jsonl\n",
      "Generated JSONL file with - 3505 max words, 100 samples - at ./dataset/gen-word-3505-count.jsonl\n",
      "Generated JSONL file with - 3405 max words, 100 samples - at ./dataset/gen-word-3405-count.jsonl\n",
      "Generated JSONL file with - 3545 max words, 100 samples - at ./dataset/gen-word-3545-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3275 max words - at ./dataset/shuffle-word-3275-count.jsonl\n",
      "Generated JSONL file with - 3390 max words, 100 samples - at ./dataset/gen-word-3390-count.jsonl\n",
      "Generated JSONL file with - 1815 max words, 150 samples - at ./dataset/gen-word-1815-count.jsonl\n",
      "Generated a single JSONL file with 143 samples (100 token repeat) - 2510 max words - at ./dataset/shuffle-word-2510-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2200 max words - at ./dataset/shuffle-word-2200-count.jsonl\n",
      "Generated JSONL file with - 3475 max words, 100 samples - at ./dataset/gen-word-3475-count.jsonl\n",
      "Generated JSONL file with - 1885 max words, 150 samples - at ./dataset/gen-word-1885-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3530 max words - at ./dataset/shuffle-word-3530-count.jsonl\n",
      "Generated a single JSONL file with 147 samples (100 token repeat) - 2600 max words - at ./dataset/shuffle-word-2600-count.jsonl\n",
      "Generated JSONL file with - 2280 max words, 125 samples - at ./dataset/gen-word-2280-count.jsonl\n",
      "Generated JSONL file with - 3940 max words, 100 samples - at ./dataset/gen-word-3940-count.jsonl\n",
      "Generated JSONL file with - 3220 max words, 100 samples - at ./dataset/gen-word-3220-count.jsonl\n",
      "Generated a single JSONL file with 101 samples (100 token repeat) - 2850 max words - at ./dataset/shuffle-word-2850-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3745 max words - at ./dataset/shuffle-word-3745-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3740 max words - at ./dataset/shuffle-word-3740-count.jsonl\n",
      "Generated a single JSONL file with 199 samples (100 token repeat) - 2380 max words - at ./dataset/shuffle-word-2380-count.jsonl\n",
      "Generated JSONL file with - 3235 max words, 100 samples - at ./dataset/gen-word-3235-count.jsonl\n",
      "Generated JSONL file with - 3195 max words, 100 samples - at ./dataset/gen-word-3195-count.jsonl\n",
      "Generated a single JSONL file with 102 samples (100 token repeat) - 2740 max words - at ./dataset/shuffle-word-2740-count.jsonl\n",
      "Generated JSONL file with - 3255 max words, 100 samples - at ./dataset/gen-word-3255-count.jsonl\n",
      "Generated JSONL file with - 3100 max words, 100 samples - at ./dataset/gen-word-3100-count.jsonl\n",
      "Generated JSONL file with - 3415 max words, 100 samples - at ./dataset/gen-word-3415-count.jsonl\n",
      "Generated a single JSONL file with 199 samples (100 token repeat) - 2370 max words - at ./dataset/shuffle-word-2370-count.jsonl\n",
      "Generated JSONL file with - 2350 max words, 125 samples - at ./dataset/gen-word-2350-count.jsonl\n",
      "Generated JSONL file with - 3200 max words, 100 samples - at ./dataset/gen-word-3200-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3295 max words - at ./dataset/shuffle-word-3295-count.jsonl\n",
      "Generated JSONL file with - 3330 max words, 100 samples - at ./dataset/gen-word-3330-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3380 max words - at ./dataset/shuffle-word-3380-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3690 max words - at ./dataset/shuffle-word-3690-count.jsonl\n",
      "Generated JSONL file with - 3530 max words, 100 samples - at ./dataset/gen-word-3530-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3525 max words - at ./dataset/shuffle-word-3525-count.jsonl\n",
      "Generated JSONL file with - 1850 max words, 150 samples - at ./dataset/gen-word-1850-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3805 max words - at ./dataset/shuffle-word-3805-count.jsonl\n",
      "Generated a single JSONL file with 188 samples (100 token repeat) - 2480 max words - at ./dataset/shuffle-word-2480-count.jsonl\n",
      "Generated a single JSONL file with 187 samples (100 token repeat) - 2430 max words - at ./dataset/shuffle-word-2430-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2955 max words - at ./dataset/shuffle-word-2955-count.jsonl\n",
      "Generated JSONL file with - 2190 max words, 125 samples - at ./dataset/gen-word-2190-count.jsonl\n",
      "Generated JSONL file with - 2300 max words, 125 samples - at ./dataset/gen-word-2300-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3160 max words - at ./dataset/shuffle-word-3160-count.jsonl\n",
      "Generated JSONL file with - 3930 max words, 100 samples - at ./dataset/gen-word-3930-count.jsonl\n",
      "Generated a single JSONL file with 102 samples (100 token repeat) - 2715 max words - at ./dataset/shuffle-word-2715-count.jsonl\n",
      "Generated JSONL file with - 2490 max words, 125 samples - at ./dataset/gen-word-2490-count.jsonl\n",
      "Generated JSONL file with - 2340 max words, 125 samples - at ./dataset/gen-word-2340-count.jsonl\n",
      "Generated a single JSONL file with 121 samples (100 token repeat) - 2645 max words - at ./dataset/shuffle-word-2645-count.jsonl\n",
      "Generated a single JSONL file with 101 samples (100 token repeat) - 2785 max words - at ./dataset/shuffle-word-2785-count.jsonl\n",
      "Generated JSONL file with - 3250 max words, 100 samples - at ./dataset/gen-word-3250-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3390 max words - at ./dataset/shuffle-word-3390-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3465 max words - at ./dataset/shuffle-word-3465-count.jsonl\n",
      "Generated JSONL file with - 1880 max words, 150 samples - at ./dataset/gen-word-1880-count.jsonl\n",
      "Generated JSONL file with - 3535 max words, 100 samples - at ./dataset/gen-word-3535-count.jsonl\n",
      "Generated a single JSONL file with 197 samples (100 token repeat) - 2365 max words - at ./dataset/shuffle-word-2365-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3675 max words - at ./dataset/shuffle-word-3675-count.jsonl\n",
      "Generated JSONL file with - 2615 max words, 125 samples - at ./dataset/gen-word-2615-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3000 max words - at ./dataset/shuffle-word-3000-count.jsonl\n",
      "Generated JSONL file with - 3240 max words, 100 samples - at ./dataset/gen-word-3240-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2140 max words - at ./dataset/shuffle-word-2140-count.jsonl\n",
      "Generated a single JSONL file with 148 samples (100 token repeat) - 2545 max words - at ./dataset/shuffle-word-2545-count.jsonl\n",
      "Generated a single JSONL file with 122 samples (100 token repeat) - 2620 max words - at ./dataset/shuffle-word-2620-count.jsonl\n",
      "Generated JSONL file with - 2500 max words, 125 samples - at ./dataset/gen-word-2500-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2270 max words - at ./dataset/shuffle-word-2270-count.jsonl\n",
      "Generated JSONL file with - 2640 max words, 125 samples - at ./dataset/gen-word-2640-count.jsonl\n",
      "Generated JSONL file with - 1480 max words, 150 samples - at ./dataset/gen-word-1480-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3335 max words - at ./dataset/shuffle-word-3335-count.jsonl\n",
      "Generated JSONL file with - 3030 max words, 100 samples - at ./dataset/gen-word-3030-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3510 max words - at ./dataset/shuffle-word-3510-count.jsonl\n",
      "Generated JSONL file with - 2605 max words, 125 samples - at ./dataset/gen-word-2605-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1870 max words - at ./dataset/shuffle-word-1870-count.jsonl\n",
      "Generated JSONL file with - 2155 max words, 125 samples - at ./dataset/gen-word-2155-count.jsonl\n",
      "Generated JSONL file with - 3470 max words, 100 samples - at ./dataset/gen-word-3470-count.jsonl\n",
      "Generated JSONL file with - 3790 max words, 100 samples - at ./dataset/gen-word-3790-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3765 max words - at ./dataset/shuffle-word-3765-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2950 max words - at ./dataset/shuffle-word-2950-count.jsonl\n",
      "Generated JSONL file with - 2755 max words, 125 samples - at ./dataset/gen-word-2755-count.jsonl\n",
      "Generated JSONL file with - 2895 max words, 125 samples - at ./dataset/gen-word-2895-count.jsonl\n",
      "Generated JSONL file with - 2750 max words, 125 samples - at ./dataset/gen-word-2750-count.jsonl\n",
      "Generated JSONL file with - 1585 max words, 150 samples - at ./dataset/gen-word-1585-count.jsonl\n",
      "Generated JSONL file with - 1690 max words, 150 samples - at ./dataset/gen-word-1690-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3175 max words - at ./dataset/shuffle-word-3175-count.jsonl\n",
      "Generated a single JSONL file with 101 samples (100 token repeat) - 2770 max words - at ./dataset/shuffle-word-2770-count.jsonl\n",
      "Generated JSONL file with - 3285 max words, 100 samples - at ./dataset/gen-word-3285-count.jsonl\n",
      "Generated JSONL file with - 1945 max words, 150 samples - at ./dataset/gen-word-1945-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3070 max words - at ./dataset/shuffle-word-3070-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3720 max words - at ./dataset/shuffle-word-3720-count.jsonl\n",
      "Generated a single JSONL file with 114 samples (100 token repeat) - 2670 max words - at ./dataset/shuffle-word-2670-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2845 max words - at ./dataset/shuffle-word-2845-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3865 max words - at ./dataset/shuffle-word-3865-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3075 max words - at ./dataset/shuffle-word-3075-count.jsonl\n",
      "Generated JSONL file with - 3580 max words, 100 samples - at ./dataset/gen-word-3580-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3110 max words - at ./dataset/shuffle-word-3110-count.jsonl\n",
      "Generated JSONL file with - 3740 max words, 100 samples - at ./dataset/gen-word-3740-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3265 max words - at ./dataset/shuffle-word-3265-count.jsonl\n",
      "Generated JSONL file with - 2210 max words, 125 samples - at ./dataset/gen-word-2210-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2875 max words - at ./dataset/shuffle-word-2875-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2185 max words - at ./dataset/shuffle-word-2185-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3915 max words - at ./dataset/shuffle-word-3915-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2910 max words - at ./dataset/shuffle-word-2910-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2080 max words - at ./dataset/shuffle-word-2080-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3015 max words - at ./dataset/shuffle-word-3015-count.jsonl\n",
      "Generated JSONL file with - 3760 max words, 100 samples - at ./dataset/gen-word-3760-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2260 max words - at ./dataset/shuffle-word-2260-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3480 max words - at ./dataset/shuffle-word-3480-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 1985 max words - at ./dataset/shuffle-word-1985-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3365 max words - at ./dataset/shuffle-word-3365-count.jsonl\n",
      "Generated JSONL file with - 3365 max words, 100 samples - at ./dataset/gen-word-3365-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2925 max words - at ./dataset/shuffle-word-2925-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3010 max words - at ./dataset/shuffle-word-3010-count.jsonl\n",
      "Generated JSONL file with - 3485 max words, 100 samples - at ./dataset/gen-word-3485-count.jsonl\n",
      "Generated JSONL file with - 2555 max words, 125 samples - at ./dataset/gen-word-2555-count.jsonl\n",
      "Generated JSONL file with - 2685 max words, 125 samples - at ./dataset/gen-word-2685-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3375 max words - at ./dataset/shuffle-word-3375-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3730 max words - at ./dataset/shuffle-word-3730-count.jsonl\n",
      "Generated JSONL file with - 2345 max words, 125 samples - at ./dataset/gen-word-2345-count.jsonl\n",
      "Generated JSONL file with - 2540 max words, 125 samples - at ./dataset/gen-word-2540-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3640 max words - at ./dataset/shuffle-word-3640-count.jsonl\n",
      "Generated JSONL file with - 2905 max words, 125 samples - at ./dataset/gen-word-2905-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2980 max words - at ./dataset/shuffle-word-2980-count.jsonl\n",
      "Generated JSONL file with - 3725 max words, 100 samples - at ./dataset/gen-word-3725-count.jsonl\n",
      "Generated JSONL file with - 2480 max words, 125 samples - at ./dataset/gen-word-2480-count.jsonl\n",
      "Generated a single JSONL file with 113 samples (100 token repeat) - 2680 max words - at ./dataset/shuffle-word-2680-count.jsonl\n",
      "Generated JSONL file with - 2975 max words, 125 samples - at ./dataset/gen-word-2975-count.jsonl\n",
      "Generated JSONL file with - 2840 max words, 125 samples - at ./dataset/gen-word-2840-count.jsonl\n",
      "Generated JSONL file with - 2470 max words, 125 samples - at ./dataset/gen-word-2470-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3825 max words - at ./dataset/shuffle-word-3825-count.jsonl\n",
      "Generated JSONL file with - 2035 max words, 125 samples - at ./dataset/gen-word-2035-count.jsonl\n",
      "Generated JSONL file with - 3785 max words, 100 samples - at ./dataset/gen-word-3785-count.jsonl\n",
      "Generated JSONL file with - 2855 max words, 125 samples - at ./dataset/gen-word-2855-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3545 max words - at ./dataset/shuffle-word-3545-count.jsonl\n",
      "Generated JSONL file with - 3815 max words, 100 samples - at ./dataset/gen-word-3815-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3400 max words - at ./dataset/shuffle-word-3400-count.jsonl\n",
      "Generated JSONL file with - 1940 max words, 150 samples - at ./dataset/gen-word-1940-count.jsonl\n",
      "Generated JSONL file with - 2775 max words, 125 samples - at ./dataset/gen-word-2775-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3660 max words - at ./dataset/shuffle-word-3660-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3635 max words - at ./dataset/shuffle-word-3635-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3315 max words - at ./dataset/shuffle-word-3315-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3625 max words - at ./dataset/shuffle-word-3625-count.jsonl\n",
      "Generated a single JSONL file with 200 samples (100 token repeat) - 2375 max words - at ./dataset/shuffle-word-2375-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3425 max words - at ./dataset/shuffle-word-3425-count.jsonl\n",
      "Generated a single JSONL file with 103 samples (100 token repeat) - 2765 max words - at ./dataset/shuffle-word-2765-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3255 max words - at ./dataset/shuffle-word-3255-count.jsonl\n",
      "Generated a single JSONL file with 187 samples (100 token repeat) - 2475 max words - at ./dataset/shuffle-word-2475-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3810 max words - at ./dataset/shuffle-word-3810-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2940 max words - at ./dataset/shuffle-word-2940-count.jsonl\n",
      "Generated JSONL file with - 3455 max words, 100 samples - at ./dataset/gen-word-3455-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3780 max words - at ./dataset/shuffle-word-3780-count.jsonl\n",
      "Generated a single JSONL file with 159 samples (100 token repeat) - 2540 max words - at ./dataset/shuffle-word-2540-count.jsonl\n",
      "Generated JSONL file with - 3465 max words, 100 samples - at ./dataset/gen-word-3465-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3055 max words - at ./dataset/shuffle-word-3055-count.jsonl\n",
      "Generated a single JSONL file with 104 samples (100 token repeat) - 2790 max words - at ./dataset/shuffle-word-2790-count.jsonl\n",
      "Generated JSONL file with - 2670 max words, 125 samples - at ./dataset/gen-word-2670-count.jsonl\n",
      "Generated JSONL file with - 2900 max words, 125 samples - at ./dataset/gen-word-2900-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3895 max words - at ./dataset/shuffle-word-3895-count.jsonl\n",
      "Generated JSONL file with - 3120 max words, 100 samples - at ./dataset/gen-word-3120-count.jsonl\n",
      "Generated JSONL file with - 3570 max words, 100 samples - at ./dataset/gen-word-3570-count.jsonl\n",
      "Generated JSONL file with - 3065 max words, 100 samples - at ./dataset/gen-word-3065-count.jsonl\n",
      "Generated JSONL file with - 2360 max words, 125 samples - at ./dataset/gen-word-2360-count.jsonl\n",
      "Generated JSONL file with - 2170 max words, 125 samples - at ./dataset/gen-word-2170-count.jsonl\n",
      "Generated JSONL file with - 3280 max words, 100 samples - at ./dataset/gen-word-3280-count.jsonl\n",
      "Generated JSONL file with - 3375 max words, 100 samples - at ./dataset/gen-word-3375-count.jsonl\n",
      "Generated JSONL file with - 3015 max words, 100 samples - at ./dataset/gen-word-3015-count.jsonl\n",
      "Generated JSONL file with - 2940 max words, 125 samples - at ./dataset/gen-word-2940-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3020 max words - at ./dataset/shuffle-word-3020-count.jsonl\n",
      "Generated JSONL file with - 2185 max words, 125 samples - at ./dataset/gen-word-2185-count.jsonl\n",
      "Generated JSONL file with - 3865 max words, 100 samples - at ./dataset/gen-word-3865-count.jsonl\n",
      "Generated JSONL file with - 3345 max words, 100 samples - at ./dataset/gen-word-3345-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3170 max words - at ./dataset/shuffle-word-3170-count.jsonl\n",
      "Generated a single JSONL file with 144 samples (100 token repeat) - 2555 max words - at ./dataset/shuffle-word-2555-count.jsonl\n",
      "Generated JSONL file with - 2515 max words, 125 samples - at ./dataset/gen-word-2515-count.jsonl\n",
      "Generated JSONL file with - 2815 max words, 125 samples - at ./dataset/gen-word-2815-count.jsonl\n",
      "Generated JSONL file with - 2930 max words, 125 samples - at ./dataset/gen-word-2930-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3555 max words - at ./dataset/shuffle-word-3555-count.jsonl\n",
      "Generated JSONL file with - 3730 max words, 100 samples - at ./dataset/gen-word-3730-count.jsonl\n",
      "Generated JSONL file with - 3440 max words, 100 samples - at ./dataset/gen-word-3440-count.jsonl\n",
      "Generated JSONL file with - 3075 max words, 100 samples - at ./dataset/gen-word-3075-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3835 max words - at ./dataset/shuffle-word-3835-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3035 max words - at ./dataset/shuffle-word-3035-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2855 max words - at ./dataset/shuffle-word-2855-count.jsonl\n",
      "Generated JSONL file with - 2960 max words, 125 samples - at ./dataset/gen-word-2960-count.jsonl\n",
      "Generated JSONL file with - 3400 max words, 100 samples - at ./dataset/gen-word-3400-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2920 max words - at ./dataset/shuffle-word-2920-count.jsonl\n",
      "Generated JSONL file with - 2785 max words, 125 samples - at ./dataset/gen-word-2785-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3245 max words - at ./dataset/shuffle-word-3245-count.jsonl\n",
      "Generated JSONL file with - 2600 max words, 125 samples - at ./dataset/gen-word-2600-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3925 max words - at ./dataset/shuffle-word-3925-count.jsonl\n",
      "Generated JSONL file with - 2010 max words, 125 samples - at ./dataset/gen-word-2010-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3580 max words - at ./dataset/shuffle-word-3580-count.jsonl\n",
      "Generated a single JSONL file with 183 samples (100 token repeat) - 2405 max words - at ./dataset/shuffle-word-2405-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3820 max words - at ./dataset/shuffle-word-3820-count.jsonl\n",
      "Generated JSONL file with - 3550 max words, 100 samples - at ./dataset/gen-word-3550-count.jsonl\n",
      "Generated a single JSONL file with 186 samples (100 token repeat) - 2485 max words - at ./dataset/shuffle-word-2485-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3900 max words - at ./dataset/shuffle-word-3900-count.jsonl\n",
      "Generated JSONL file with - 2880 max words, 125 samples - at ./dataset/gen-word-2880-count.jsonl\n",
      "Generated a single JSONL file with 101 samples (100 token repeat) - 2710 max words - at ./dataset/shuffle-word-2710-count.jsonl\n",
      "Generated JSONL file with - 2715 max words, 125 samples - at ./dataset/gen-word-2715-count.jsonl\n",
      "Generated JSONL file with - 3855 max words, 100 samples - at ./dataset/gen-word-3855-count.jsonl\n",
      "Generated JSONL file with - 3660 max words, 100 samples - at ./dataset/gen-word-3660-count.jsonl\n",
      "Generated JSONL file with - 2110 max words, 125 samples - at ./dataset/gen-word-2110-count.jsonl\n",
      "Generated JSONL file with - 3035 max words, 100 samples - at ./dataset/gen-word-3035-count.jsonl\n",
      "Generated JSONL file with - 2845 max words, 125 samples - at ./dataset/gen-word-2845-count.jsonl\n",
      "Generated JSONL file with - 3395 max words, 100 samples - at ./dataset/gen-word-3395-count.jsonl\n",
      "Generated JSONL file with - 3045 max words, 100 samples - at ./dataset/gen-word-3045-count.jsonl\n",
      "Generated JSONL file with - 2545 max words, 125 samples - at ./dataset/gen-word-2545-count.jsonl\n",
      "Generated JSONL file with - 2585 max words, 125 samples - at ./dataset/gen-word-2585-count.jsonl\n",
      "Generated JSONL file with - 3145 max words, 100 samples - at ./dataset/gen-word-3145-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3775 max words - at ./dataset/shuffle-word-3775-count.jsonl\n",
      "Generated JSONL file with - 3355 max words, 100 samples - at ./dataset/gen-word-3355-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3830 max words - at ./dataset/shuffle-word-3830-count.jsonl\n",
      "Generated JSONL file with - 3025 max words, 100 samples - at ./dataset/gen-word-3025-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3025 max words - at ./dataset/shuffle-word-3025-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 3930 max words - at ./dataset/shuffle-word-3930-count.jsonl\n",
      "Generated JSONL file with - 2980 max words, 125 samples - at ./dataset/gen-word-2980-count.jsonl\n",
      "Generated JSONL file with - 2985 max words, 125 samples - at ./dataset/gen-word-2985-count.jsonl\n",
      "Generated JSONL file with - 2890 max words, 125 samples - at ./dataset/gen-word-2890-count.jsonl\n",
      "Generated a single JSONL file with 100 samples (100 token repeat) - 2945 max words - at ./dataset/shuffle-word-2945-count.jsonl\n",
      "Generated JSONL file with - 3845 max words, 100 samples - at ./dataset/gen-word-3845-count.jsonl\n",
      "Generated JSONL file with - 3830 max words, 100 samples - at ./dataset/gen-word-3830-count.jsonl\n",
      "Generated JSONL file with - 3810 max words, 100 samples - at ./dataset/gen-word-3810-count.jsonl\n",
      "Generated JSONL file with - 3795 max words, 100 samples - at ./dataset/gen-word-3795-count.jsonl\n",
      "Generated JSONL file with - 3665 max words, 100 samples - at ./dataset/gen-word-3665-count.jsonl\n",
      "Generated JSONL file with - 3900 max words, 100 samples - at ./dataset/gen-word-3900-count.jsonl\n",
      "Generated JSONL file with - 3925 max words, 100 samples - at ./dataset/gen-word-3925-count.jsonl\n",
      "Generated JSONL file with - 3770 max words, 100 samples - at ./dataset/gen-word-3770-count.jsonl\n",
      "Generated JSONL file with - 3935 max words, 100 samples - at ./dataset/gen-word-3935-count.jsonl\n",
      "## Done ##\n",
      "total 3.8G\n",
      "drwxrwxr-x 2 recursal recursal   84K Jan 22 08:53 .\n",
      "drwxrwxr-x 5 recursal recursal  4.0K Jan 22 08:52 ..\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-1000-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-1005-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  163K Jan 22 08:53 gen-word-100-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-1010-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-1015-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-1020-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-1025-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-1030-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-1035-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-1040-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.6M Jan 22 08:53 gen-word-1045-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.6M Jan 22 08:53 gen-word-1050-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.6M Jan 22 08:53 gen-word-1055-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  167K Jan 22 08:53 gen-word-105-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.6M Jan 22 08:53 gen-word-1060-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.6M Jan 22 08:53 gen-word-1065-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.6M Jan 22 08:53 gen-word-1070-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.6M Jan 22 08:53 gen-word-1075-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.6M Jan 22 08:53 gen-word-1080-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.6M Jan 22 08:53 gen-word-1085-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.6M Jan 22 08:53 gen-word-1090-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.6M Jan 22 08:53 gen-word-1095-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal   30K Jan 22 08:53 gen-word-10-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.6M Jan 22 08:53 gen-word-1100-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1105-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  175K Jan 22 08:53 gen-word-110-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1110-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1115-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1120-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1125-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1130-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1135-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1140-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1145-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1150-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1155-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  185K Jan 22 08:53 gen-word-115-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1160-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1165-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1170-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1175-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.7M Jan 22 08:53 gen-word-1180-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.8M Jan 22 08:53 gen-word-1185-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.8M Jan 22 08:53 gen-word-1190-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.8M Jan 22 08:53 gen-word-1195-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.8M Jan 22 08:53 gen-word-1200-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.8M Jan 22 08:53 gen-word-1205-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  188K Jan 22 08:53 gen-word-120-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.8M Jan 22 08:53 gen-word-1210-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.8M Jan 22 08:53 gen-word-1215-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.8M Jan 22 08:53 gen-word-1220-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.8M Jan 22 08:53 gen-word-1225-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.8M Jan 22 08:53 gen-word-1230-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.8M Jan 22 08:53 gen-word-1235-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.8M Jan 22 08:53 gen-word-1240-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.8M Jan 22 08:53 gen-word-1245-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.9M Jan 22 08:53 gen-word-1250-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.8M Jan 22 08:53 gen-word-1255-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  199K Jan 22 08:53 gen-word-125-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.9M Jan 22 08:53 gen-word-1260-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.9M Jan 22 08:53 gen-word-1265-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.9M Jan 22 08:53 gen-word-1270-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.9M Jan 22 08:53 gen-word-1275-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.9M Jan 22 08:53 gen-word-1280-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.9M Jan 22 08:53 gen-word-1285-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.9M Jan 22 08:53 gen-word-1290-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.9M Jan 22 08:53 gen-word-1295-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.9M Jan 22 08:53 gen-word-1300-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.9M Jan 22 08:53 gen-word-1305-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  200K Jan 22 08:53 gen-word-130-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.9M Jan 22 08:53 gen-word-1310-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.9M Jan 22 08:53 gen-word-1315-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.9M Jan 22 08:53 gen-word-1320-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1325-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1330-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1335-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1340-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1345-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1350-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1355-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  211K Jan 22 08:53 gen-word-135-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1360-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1365-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1370-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1375-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1380-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1385-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1390-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1395-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1400-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.0M Jan 22 08:53 gen-word-1405-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  219K Jan 22 08:53 gen-word-140-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.1M Jan 22 08:53 gen-word-1410-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.1M Jan 22 08:53 gen-word-1415-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.1M Jan 22 08:53 gen-word-1420-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.1M Jan 22 08:53 gen-word-1425-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.1M Jan 22 08:53 gen-word-1430-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.1M Jan 22 08:53 gen-word-1435-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.1M Jan 22 08:53 gen-word-1440-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.1M Jan 22 08:53 gen-word-1445-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.1M Jan 22 08:53 gen-word-1450-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.1M Jan 22 08:53 gen-word-1455-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  222K Jan 22 08:53 gen-word-145-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.2M Jan 22 08:53 gen-word-1460-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.1M Jan 22 08:53 gen-word-1465-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.2M Jan 22 08:53 gen-word-1470-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.2M Jan 22 08:53 gen-word-1475-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.2M Jan 22 08:53 gen-word-1480-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.2M Jan 22 08:53 gen-word-1485-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.2M Jan 22 08:53 gen-word-1490-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.2M Jan 22 08:53 gen-word-1495-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.2M Jan 22 08:53 gen-word-1500-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.2M Jan 22 08:53 gen-word-1505-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  231K Jan 22 08:53 gen-word-150-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.2M Jan 22 08:53 gen-word-1510-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.2M Jan 22 08:53 gen-word-1515-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.2M Jan 22 08:53 gen-word-1520-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.2M Jan 22 08:53 gen-word-1525-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.2M Jan 22 08:53 gen-word-1530-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.3M Jan 22 08:53 gen-word-1535-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.3M Jan 22 08:53 gen-word-1540-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.3M Jan 22 08:53 gen-word-1545-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.3M Jan 22 08:53 gen-word-1550-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.3M Jan 22 08:53 gen-word-1555-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  240K Jan 22 08:53 gen-word-155-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.3M Jan 22 08:53 gen-word-1560-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.3M Jan 22 08:53 gen-word-1565-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.3M Jan 22 08:53 gen-word-1570-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.3M Jan 22 08:53 gen-word-1575-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.3M Jan 22 08:53 gen-word-1580-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.3M Jan 22 08:53 gen-word-1585-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.3M Jan 22 08:53 gen-word-1590-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.3M Jan 22 08:53 gen-word-1595-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal   37K Jan 22 08:53 gen-word-15-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1600-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1605-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  250K Jan 22 08:53 gen-word-160-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.3M Jan 22 08:53 gen-word-1610-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1615-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1620-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1625-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1630-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1635-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1640-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1645-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1650-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1655-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  254K Jan 22 08:53 gen-word-165-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1660-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1665-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1670-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-1675-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-1680-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-1685-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-1690-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-1695-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-1700-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-1705-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  262K Jan 22 08:53 gen-word-170-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-1710-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-1715-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-1720-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-1725-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-1730-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-1735-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-1740-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-1745-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-1750-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-1755-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  266K Jan 22 08:53 gen-word-175-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-1760-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-1765-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-1770-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-1775-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-1780-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-1785-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-1790-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-1795-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-1800-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-1805-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  279K Jan 22 08:53 gen-word-180-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-1810-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1815-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1820-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1825-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1830-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1835-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1840-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1845-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1850-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1855-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  284K Jan 22 08:53 gen-word-185-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1860-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1865-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1870-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1875-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1880-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-1885-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-1890-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-1895-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-1900-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-1905-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  290K Jan 22 08:53 gen-word-190-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-1910-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-1915-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-1920-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-1925-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-1930-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-1935-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-1940-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-1945-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-1950-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-1955-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  300K Jan 22 08:53 gen-word-195-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-1960-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-1965-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-1970-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-1975-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-1980-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-1985-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-1990-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-1995-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2000-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-2005-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  308K Jan 22 08:53 gen-word-200-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.4M Jan 22 08:53 gen-word-2010-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2015-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2020-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2025-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2030-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2035-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2040-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2045-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2050-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2055-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  311K Jan 22 08:53 gen-word-205-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2060-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2065-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2070-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2075-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2080-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2085-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2090-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.5M Jan 22 08:53 gen-word-2095-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal   44K Jan 22 08:53 gen-word-20-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2100-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2105-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  323K Jan 22 08:53 gen-word-210-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2110-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2115-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2120-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2125-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2130-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2135-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2140-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2145-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2150-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2155-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  330K Jan 22 08:53 gen-word-215-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2160-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2165-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2170-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2175-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 gen-word-2180-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2185-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2190-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2195-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2200-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2205-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  337K Jan 22 08:53 gen-word-220-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2210-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2215-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2220-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2225-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2230-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2235-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2240-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2245-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2250-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2255-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  340K Jan 22 08:53 gen-word-225-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 gen-word-2260-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2265-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2270-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2275-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2280-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2285-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2290-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2295-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2300-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2305-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  353K Jan 22 08:53 gen-word-230-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2310-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2315-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2320-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2325-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2330-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2335-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2340-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2345-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2350-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 gen-word-2355-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  356K Jan 22 08:53 gen-word-235-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2360-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2365-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2370-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2375-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2380-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2385-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2390-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2395-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2400-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2405-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  366K Jan 22 08:53 gen-word-240-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2410-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2415-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2420-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2425-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-2430-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2435-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2440-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2445-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2450-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2455-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  370K Jan 22 08:53 gen-word-245-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2460-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2465-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2470-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2475-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2480-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2485-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2490-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2495-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2500-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2505-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  379K Jan 22 08:53 gen-word-250-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2510-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2515-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-2520-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2525-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2530-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2535-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2540-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2545-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2550-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2555-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  386K Jan 22 08:53 gen-word-255-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2560-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2565-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2570-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2575-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2580-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2585-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2590-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-2595-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal   51K Jan 22 08:53 gen-word-25-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2600-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2605-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  392K Jan 22 08:53 gen-word-260-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2610-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2615-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2620-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2625-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2630-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2635-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2640-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2645-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2650-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2655-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  404K Jan 22 08:53 gen-word-265-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2660-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2665-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2670-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2675-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2680-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2685-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-2690-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2695-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2700-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2705-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  406K Jan 22 08:53 gen-word-270-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2710-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2715-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2720-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2725-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2730-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2735-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2740-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2745-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2750-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2755-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  418K Jan 22 08:53 gen-word-275-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2760-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2765-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-2770-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2775-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2780-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2785-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2790-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2795-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2800-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2805-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  422K Jan 22 08:53 gen-word-280-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2810-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2815-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2820-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2825-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2830-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2835-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2840-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2845-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2850-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-2855-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  426K Jan 22 08:53 gen-word-285-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2860-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2865-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2870-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2875-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2880-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2885-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2890-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2895-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2900-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2905-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  443K Jan 22 08:53 gen-word-290-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2910-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2915-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2920-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2925-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2930-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2935-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2940-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-2945-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-2950-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-2955-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  438K Jan 22 08:53 gen-word-295-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-2960-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-2965-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-2970-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-2975-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-2980-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-2985-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-2990-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-2995-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3000-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-3005-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  452K Jan 22 08:53 gen-word-300-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-3010-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-3015-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-3020-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-3025-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-3030-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-3035-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3040-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-3045-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3050-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.9M Jan 22 08:53 gen-word-3055-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  457K Jan 22 08:53 gen-word-305-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3060-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3065-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3070-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3075-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3080-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3085-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3090-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3095-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal   57K Jan 22 08:53 gen-word-30-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3100-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3105-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  470K Jan 22 08:53 gen-word-310-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3110-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3115-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3120-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3125-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3130-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3135-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3140-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3145-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3150-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3155-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  476K Jan 22 08:53 gen-word-315-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.0M Jan 22 08:53 gen-word-3160-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3165-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3170-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3175-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3180-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3185-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3190-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3195-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3200-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3205-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  478K Jan 22 08:53 gen-word-320-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3210-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3215-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3220-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3225-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3230-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3235-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3240-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3245-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.1M Jan 22 08:53 gen-word-3250-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3255-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  490K Jan 22 08:53 gen-word-325-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3260-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3265-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3270-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3275-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3280-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3285-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3290-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3295-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3300-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3305-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  499K Jan 22 08:53 gen-word-330-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3310-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3315-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3320-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3325-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3330-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3335-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3340-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3345-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3350-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.2M Jan 22 08:53 gen-word-3355-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  501K Jan 22 08:53 gen-word-335-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3360-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3365-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3370-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3375-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3380-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3385-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3390-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3395-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3400-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3405-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  507K Jan 22 08:53 gen-word-340-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3410-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3415-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3420-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3425-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3430-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3435-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3440-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3445-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3450-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.3M Jan 22 08:53 gen-word-3455-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  517K Jan 22 08:53 gen-word-345-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3460-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3465-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3470-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3475-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3480-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3485-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3490-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3495-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3500-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3505-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  521K Jan 22 08:53 gen-word-350-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3510-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3515-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3520-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3525-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3530-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3535-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3540-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3545-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3550-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3555-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  533K Jan 22 08:53 gen-word-355-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3560-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.4M Jan 22 08:53 gen-word-3565-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3570-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3575-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3580-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3585-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3590-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3595-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal   68K Jan 22 08:53 gen-word-35-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3600-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3605-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  544K Jan 22 08:53 gen-word-360-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3610-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3615-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3620-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3625-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3630-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3635-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3640-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3645-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3650-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3655-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  543K Jan 22 08:53 gen-word-365-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3660-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3665-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3670-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3675-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3680-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3685-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.5M Jan 22 08:53 gen-word-3690-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3695-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3700-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3705-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  547K Jan 22 08:53 gen-word-370-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3710-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3715-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3720-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3725-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3730-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3735-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3740-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3745-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3750-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3755-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  563K Jan 22 08:53 gen-word-375-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3760-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3765-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3770-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3775-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3780-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3785-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3790-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3795-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3800-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3805-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  565K Jan 22 08:53 gen-word-380-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.6M Jan 22 08:53 gen-word-3810-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3815-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3820-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3825-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3830-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3835-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3840-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3845-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3850-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3855-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  572K Jan 22 08:53 gen-word-385-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3860-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3865-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3870-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3875-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.7M Jan 22 08:53 gen-word-3880-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3885-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3890-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3895-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3900-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3905-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  584K Jan 22 08:53 gen-word-390-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3910-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3915-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3920-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3925-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3930-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3935-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3940-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3945-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3950-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3955-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  587K Jan 22 08:53 gen-word-395-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3960-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3965-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3970-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3975-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3980-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3985-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-3990-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.9M Jan 22 08:53 gen-word-3995-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  3.8M Jan 22 08:53 gen-word-4000-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  605K Jan 22 08:53 gen-word-400-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  610K Jan 22 08:53 gen-word-405-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal   74K Jan 22 08:53 gen-word-40-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  612K Jan 22 08:53 gen-word-410-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  626K Jan 22 08:53 gen-word-415-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  632K Jan 22 08:53 gen-word-420-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  636K Jan 22 08:53 gen-word-425-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  637K Jan 22 08:53 gen-word-430-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  649K Jan 22 08:53 gen-word-435-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  656K Jan 22 08:53 gen-word-440-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  652K Jan 22 08:53 gen-word-445-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  670K Jan 22 08:53 gen-word-450-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  672K Jan 22 08:53 gen-word-455-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal   80K Jan 22 08:53 gen-word-45-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  694K Jan 22 08:53 gen-word-460-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  698K Jan 22 08:53 gen-word-465-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  697K Jan 22 08:53 gen-word-470-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  713K Jan 22 08:53 gen-word-475-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  710K Jan 22 08:53 gen-word-480-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  729K Jan 22 08:53 gen-word-485-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  734K Jan 22 08:53 gen-word-490-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  733K Jan 22 08:53 gen-word-495-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  739K Jan 22 08:53 gen-word-500-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  752K Jan 22 08:53 gen-word-505-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal   89K Jan 22 08:53 gen-word-50-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  767K Jan 22 08:53 gen-word-510-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  770K Jan 22 08:53 gen-word-515-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  767K Jan 22 08:53 gen-word-520-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  789K Jan 22 08:53 gen-word-525-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  791K Jan 22 08:53 gen-word-530-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  798K Jan 22 08:53 gen-word-535-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  803K Jan 22 08:53 gen-word-540-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  811K Jan 22 08:53 gen-word-545-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  817K Jan 22 08:53 gen-word-550-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  822K Jan 22 08:53 gen-word-555-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal   97K Jan 22 08:53 gen-word-55-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  839K Jan 22 08:53 gen-word-560-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  840K Jan 22 08:53 gen-word-565-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  854K Jan 22 08:53 gen-word-570-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  856K Jan 22 08:53 gen-word-575-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  858K Jan 22 08:53 gen-word-580-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  868K Jan 22 08:53 gen-word-585-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  884K Jan 22 08:53 gen-word-590-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  881K Jan 22 08:53 gen-word-595-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal   23K Jan 22 08:53 gen-word-5-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  885K Jan 22 08:53 gen-word-600-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  891K Jan 22 08:53 gen-word-605-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  103K Jan 22 08:53 gen-word-60-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  908K Jan 22 08:53 gen-word-610-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  908K Jan 22 08:53 gen-word-615-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  926K Jan 22 08:53 gen-word-620-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  927K Jan 22 08:53 gen-word-625-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  941K Jan 22 08:53 gen-word-630-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  950K Jan 22 08:53 gen-word-635-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  955K Jan 22 08:53 gen-word-640-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  954K Jan 22 08:53 gen-word-645-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  952K Jan 22 08:53 gen-word-650-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  966K Jan 22 08:53 gen-word-655-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  111K Jan 22 08:53 gen-word-65-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  972K Jan 22 08:53 gen-word-660-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal 1002K Jan 22 08:53 gen-word-665-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal 1000K Jan 22 08:53 gen-word-670-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal 1004K Jan 22 08:53 gen-word-675-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal 1014K Jan 22 08:53 gen-word-680-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal 1019K Jan 22 08:53 gen-word-685-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-690-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-695-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-700-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-705-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  116K Jan 22 08:53 gen-word-70-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-710-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-715-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-720-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-725-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-730-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-735-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-740-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-745-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-750-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-755-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  123K Jan 22 08:53 gen-word-75-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.1M Jan 22 08:53 gen-word-760-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-765-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-770-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-775-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-780-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-785-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-790-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-795-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-800-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-805-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  136K Jan 22 08:53 gen-word-80-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-810-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-815-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-820-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-825-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-830-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.2M Jan 22 08:53 gen-word-835-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 08:53 gen-word-840-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 08:53 gen-word-845-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 08:53 gen-word-850-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 08:53 gen-word-855-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  136K Jan 22 08:53 gen-word-85-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 08:53 gen-word-860-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 08:53 gen-word-865-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 08:53 gen-word-870-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 08:53 gen-word-875-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 08:53 gen-word-880-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 08:53 gen-word-885-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 08:53 gen-word-890-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 08:53 gen-word-895-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.3M Jan 22 08:53 gen-word-900-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 08:53 gen-word-905-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  147K Jan 22 08:53 gen-word-90-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 08:53 gen-word-910-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 08:53 gen-word-915-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 08:53 gen-word-920-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 08:53 gen-word-925-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 08:53 gen-word-930-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 08:53 gen-word-935-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 08:53 gen-word-940-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 08:53 gen-word-945-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 08:53 gen-word-950-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 08:53 gen-word-955-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  151K Jan 22 08:53 gen-word-95-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 08:53 gen-word-960-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.4M Jan 22 08:53 gen-word-965-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-970-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-975-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-980-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-985-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-990-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  1.5M Jan 22 08:53 gen-word-995-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1000-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1005-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 shuffle-word-100-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1010-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1015-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1020-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1025-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1030-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1035-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1040-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1045-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1050-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1055-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 shuffle-word-105-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1060-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1065-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1070-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1075-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1080-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1085-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1090-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1095-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  5.1M Jan 22 08:53 shuffle-word-10-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1100-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1105-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.8M Jan 22 08:53 shuffle-word-110-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1110-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1115-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1120-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1125-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1130-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1135-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1140-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1145-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1150-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1155-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 shuffle-word-115-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1160-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1165-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1170-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1175-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1180-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1185-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1190-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1195-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1200-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1205-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 shuffle-word-120-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1210-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1215-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1220-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1225-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1230-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1235-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1240-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1245-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1250-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1255-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 shuffle-word-125-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1260-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1265-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1270-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1275-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1280-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1285-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1290-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1295-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1300-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1305-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 shuffle-word-130-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1310-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1315-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1320-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1325-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1330-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1335-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1340-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1345-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1350-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1355-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 shuffle-word-135-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1360-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1365-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1370-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1375-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1380-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1385-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1390-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1395-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1400-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1405-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 shuffle-word-140-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1410-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1415-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1420-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1425-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1430-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1435-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1440-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1445-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1450-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1455-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 shuffle-word-145-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1460-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1465-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1470-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1475-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1480-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1485-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1490-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1495-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1500-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1505-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 shuffle-word-150-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1510-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1515-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1520-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1525-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1530-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1535-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1540-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1545-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1550-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1555-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.7M Jan 22 08:53 shuffle-word-155-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1560-count.jsonl\n",
      "-rw-rw-r-- 1 recursal recursal  2.6M Jan 22 08:53 shuffle-word-1565-count.jsonl\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "########################################\n",
    "# Generate the required jsonl dataset\n",
    "########################################\n",
    "\n",
    "# Reset the dataset dir\n",
    "mkdir -p ./dataset\n",
    "rm -rf ./dataset/*.jsonl\n",
    "\n",
    "# Generate the various datasets\n",
    "echo \"## Generating word reptition dataset ##\"\n",
    "\n",
    "#\n",
    "# Training set for < 2000 words\n",
    "#\n",
    "for i in {5..2000..5} \n",
    "do\n",
    "    python ./memory_script/gen_limited_prompt_completion_jsonl.py ./dataset/gen-word-$i-count.jsonl $i 150 & \n",
    "    python ./memory_script/shuffle_limited_prompt_completion_jsonl.py ./dataset/shuffle-word-$i-count.jsonl $i 100 & \n",
    "done\n",
    "\n",
    "#\n",
    "# Ramping up the 50+ - 400 words dataset\n",
    "# \n",
    "for i in {2005..3000..5} \n",
    "do\n",
    "    python ./memory_script/gen_limited_prompt_completion_jsonl.py ./dataset/gen-word-$i-count.jsonl $i 125 & \n",
    "    python ./memory_script/shuffle_limited_prompt_completion_jsonl.py ./dataset/shuffle-word-$i-count.jsonl $i 100 & \n",
    "done\n",
    "\n",
    "#\n",
    "# Ramping up the 50+ - 400 words dataset\n",
    "# \n",
    "for i in {3005..4000..5} \n",
    "do\n",
    "    python ./memory_script/gen_limited_prompt_completion_jsonl.py ./dataset/gen-word-$i-count.jsonl $i 100 & \n",
    "    python ./memory_script/shuffle_limited_prompt_completion_jsonl.py ./dataset/shuffle-word-$i-count.jsonl $i 100 & \n",
    "done\n",
    "\n",
    "wait\n",
    "echo \"## Done ##\"\n",
    "\n",
    "ls -alh ./dataset/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rwkv-infctx]",
   "language": "python",
   "name": "conda-env-rwkv-infctx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
